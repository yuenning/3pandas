{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMDdQlVT7t+yOaGguLmJe5H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9e1681efd89b4783b788bc02fb08ee6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f61e6ea09283459c979057b8fa28f8eb","IPY_MODEL_3f033f0ab7614485a1e1b9f333f3ebaf","IPY_MODEL_caa77e4df72045ec88c9e8aa4e5026b6"],"layout":"IPY_MODEL_473ac484a5c74b309e15e22897a05be3"}},"f61e6ea09283459c979057b8fa28f8eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a1285838a774160be573f41a3c6d3d0","placeholder":"​","style":"IPY_MODEL_bb6bffa971dc4a589fc1a1e267818619","value":"tokenizer_config.json: 100%"}},"3f033f0ab7614485a1e1b9f333f3ebaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7855e2f531304f87a2bf211e6ec88ab9","max":1156999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a235d52eb2994a77b38eec1af3d95c27","value":1156999}},"caa77e4df72045ec88c9e8aa4e5026b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0d6f0a65f8846d0a660bd3e242c9146","placeholder":"​","style":"IPY_MODEL_c648788445d2409fa38bae4749fe2b90","value":" 1.16M/1.16M [00:00&lt;00:00, 1.35MB/s]"}},"473ac484a5c74b309e15e22897a05be3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1285838a774160be573f41a3c6d3d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb6bffa971dc4a589fc1a1e267818619":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7855e2f531304f87a2bf211e6ec88ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a235d52eb2994a77b38eec1af3d95c27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0d6f0a65f8846d0a660bd3e242c9146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c648788445d2409fa38bae4749fe2b90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfe83dc10607465abb2c498cfb9a807c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_050c81ded7a24edf88b85628a10e3c2c","IPY_MODEL_3176963a4bf34025a811c422ec89e249","IPY_MODEL_37b5d44b91c04cbcba1282ffc3741b28"],"layout":"IPY_MODEL_2c8d09ffe4c34a89975a34445a7de7b3"}},"050c81ded7a24edf88b85628a10e3c2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_135c375b3d334984a3f8682f64358946","placeholder":"​","style":"IPY_MODEL_9e5e939ebc464709b336503545f3a836","value":"tokenizer.model: 100%"}},"3176963a4bf34025a811c422ec89e249":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d32a459c161540b7bcc0b9b6b8651ea0","max":4689074,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74f53cced86b4ffea0a2e75ba3dc88e7","value":4689074}},"37b5d44b91c04cbcba1282ffc3741b28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8422a6034b4ebc8e223aa5241cdc8e","placeholder":"​","style":"IPY_MODEL_10ea68a5d168494da20be42f47f18f00","value":" 4.69M/4.69M [00:01&lt;00:00, 102kB/s]"}},"2c8d09ffe4c34a89975a34445a7de7b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"135c375b3d334984a3f8682f64358946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e5e939ebc464709b336503545f3a836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d32a459c161540b7bcc0b9b6b8651ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74f53cced86b4ffea0a2e75ba3dc88e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f8422a6034b4ebc8e223aa5241cdc8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10ea68a5d168494da20be42f47f18f00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fc47d22ce1e4d5b97065c298bf3a84e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bce2c8b36584ed8a03d19d69825b6ba","IPY_MODEL_f72f4062c699426f9dd945f9c33f9b12","IPY_MODEL_82768c7d6b884aa781bd1efaa3446b2d"],"layout":"IPY_MODEL_cd2d0eb4adc649019e031016b7845f88"}},"7bce2c8b36584ed8a03d19d69825b6ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c5c4858e403455490738c53f508b0a7","placeholder":"​","style":"IPY_MODEL_e80aeb03ac354cb5b01f6db63b77548e","value":"tokenizer.json: 100%"}},"f72f4062c699426f9dd945f9c33f9b12":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_878252aed39d4ad88fb9c6f75d715b3c","max":33384568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77a946fe85e14f689a851db98ab57aa9","value":33384568}},"82768c7d6b884aa781bd1efaa3446b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8b99cf5f8704e6eb6c6f20410f748a6","placeholder":"​","style":"IPY_MODEL_94411ab92b104a71bc41bdc6e9b41e42","value":" 33.4M/33.4M [00:00&lt;00:00, 38.1MB/s]"}},"cd2d0eb4adc649019e031016b7845f88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c5c4858e403455490738c53f508b0a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e80aeb03ac354cb5b01f6db63b77548e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"878252aed39d4ad88fb9c6f75d715b3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77a946fe85e14f689a851db98ab57aa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8b99cf5f8704e6eb6c6f20410f748a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94411ab92b104a71bc41bdc6e9b41e42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d64aa34b65474d198935136dccec7369":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c38cbf5ce974d37811d29c3fb8bc55e","IPY_MODEL_5eff39656f5c4bab9b8fe98425bd19f4","IPY_MODEL_dd026294828c434aa20bb242813d90af"],"layout":"IPY_MODEL_0d823c10360d47ab9d48468b0e71e85f"}},"4c38cbf5ce974d37811d29c3fb8bc55e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec0ff7770d2d44319682ce6c53fe2911","placeholder":"​","style":"IPY_MODEL_0275a4e754aa40bab8cdc21426290d8d","value":"added_tokens.json: 100%"}},"5eff39656f5c4bab9b8fe98425bd19f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b11458fff2f846a29275a9dcc27999d3","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c28382e8f514fa29f6c1874d306f170","value":35}},"dd026294828c434aa20bb242813d90af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6fb5bf1dc5747b1a96317a91f693181","placeholder":"​","style":"IPY_MODEL_78b8ebd57dd546c5b2ab2d0239564b0d","value":" 35.0/35.0 [00:00&lt;00:00, 814B/s]"}},"0d823c10360d47ab9d48468b0e71e85f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0ff7770d2d44319682ce6c53fe2911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0275a4e754aa40bab8cdc21426290d8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b11458fff2f846a29275a9dcc27999d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c28382e8f514fa29f6c1874d306f170":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6fb5bf1dc5747b1a96317a91f693181":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78b8ebd57dd546c5b2ab2d0239564b0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b83abd7026541f6a4d37ebe5c51ee9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f811434828304948929b3eec6f5137c0","IPY_MODEL_d5d212b54b324ce3b7fcc97166e34851","IPY_MODEL_7f562ba6db724af8b88c47cd062a6376"],"layout":"IPY_MODEL_c47c9fbc818141938615dda4daa3c1de"}},"f811434828304948929b3eec6f5137c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ada6a0349c75496596ddda2c41d5dabd","placeholder":"​","style":"IPY_MODEL_051de271e0c14932bafd57e51f883a17","value":"special_tokens_map.json: 100%"}},"d5d212b54b324ce3b7fcc97166e34851":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59731467c462472989dab0611fd978fd","max":662,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65667cea734548418f7dc9fbc33bdbfa","value":662}},"7f562ba6db724af8b88c47cd062a6376":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4774b78983c84442a92613a9909a7ab9","placeholder":"​","style":"IPY_MODEL_4d9363e0817f4e89a0e431c301ee5e48","value":" 662/662 [00:00&lt;00:00, 13.9kB/s]"}},"c47c9fbc818141938615dda4daa3c1de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ada6a0349c75496596ddda2c41d5dabd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"051de271e0c14932bafd57e51f883a17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59731467c462472989dab0611fd978fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65667cea734548418f7dc9fbc33bdbfa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4774b78983c84442a92613a9909a7ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d9363e0817f4e89a0e431c301ee5e48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6be9da034094963b2f9cf73db80c55d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b60a97790a994d4bb2b595ebc418db2b","IPY_MODEL_ccb131ba7044419b9edd0064a543c318","IPY_MODEL_8b2599d12ccf437d8e7346ae8b09ef1c"],"layout":"IPY_MODEL_378cf575a5554bef9e3d01f194bc6ca9"}},"b60a97790a994d4bb2b595ebc418db2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_088361b591f74ca88145389dc420c732","placeholder":"​","style":"IPY_MODEL_4e0192a01e73460593f8f27d90cc42dc","value":"Map: 100%"}},"ccb131ba7044419b9edd0064a543c318":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a645c03697947ba95b40ff9b61696d9","max":10728,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e743f0578384fdeb2a8f5a98607a48a","value":10728}},"8b2599d12ccf437d8e7346ae8b09ef1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06d0a0a248814e529b47bb151cec6406","placeholder":"​","style":"IPY_MODEL_b0a02d66d19e4fc39e86ddb0cec850e2","value":" 10728/10728 [00:04&lt;00:00, 3237.05 examples/s]"}},"378cf575a5554bef9e3d01f194bc6ca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088361b591f74ca88145389dc420c732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e0192a01e73460593f8f27d90cc42dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a645c03697947ba95b40ff9b61696d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e743f0578384fdeb2a8f5a98607a48a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06d0a0a248814e529b47bb151cec6406":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0a02d66d19e4fc39e86ddb0cec850e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb8d3ffbf5b54604bb6f500b8bc80b51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_762bedc2314549e2af5562c02ec5b480","IPY_MODEL_7a867022a9284b74a8dc08f6abbe7556","IPY_MODEL_bf288d9f5f3644c1bd48191dbf7ea842"],"layout":"IPY_MODEL_ec84c9c485dc4c0683cf2d6777f471eb"}},"762bedc2314549e2af5562c02ec5b480":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efa3df2af23d4d308c88435c7e37bad6","placeholder":"​","style":"IPY_MODEL_47029716a4d04a0e9bab6b9ce3bd1110","value":"Map: 100%"}},"7a867022a9284b74a8dc08f6abbe7556":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96a52c708c264b2d9c9aab6c3bc09d73","max":1192,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74562e7576844ac9b73a9052f135308d","value":1192}},"bf288d9f5f3644c1bd48191dbf7ea842":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60a6add23e5745d0ab2b74547a95794c","placeholder":"​","style":"IPY_MODEL_8c44302c38854d1cae51aa0d923ff1d6","value":" 1192/1192 [00:00&lt;00:00, 3408.63 examples/s]"}},"ec84c9c485dc4c0683cf2d6777f471eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efa3df2af23d4d308c88435c7e37bad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47029716a4d04a0e9bab6b9ce3bd1110":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96a52c708c264b2d9c9aab6c3bc09d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74562e7576844ac9b73a9052f135308d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60a6add23e5745d0ab2b74547a95794c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c44302c38854d1cae51aa0d923ff1d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Multi-Label Text CLassification Training Pipeline"],"metadata":{"id":"0Bh-CtxjozPJ"}},{"cell_type":"markdown","source":["This pipeline implements an efficient multi-label text classifier using a pre-trained language model (Gemma3-1b) with LoRA optimization. The goal is to predict multiple binary labels simultaneously for each text input, making it suitable for tasks like sentiment analysis with multiple aspects or document tagging."],"metadata":{"id":"VWqWEGYKo5aW"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"GgsZGizKOq16","executionInfo":{"status":"ok","timestamp":1756567094675,"user_tz":-480,"elapsed":107821,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","\n","from datasets import Dataset, DatasetDict\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModel,\n","    Trainer,\n","    TrainingArguments,\n","    EarlyStoppingCallback,\n",")\n","\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","from peft import LoraConfig, get_peft_model"]},{"cell_type":"code","source":["os.environ[\"HF_TOKEN\"] = \"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\""],"metadata":{"id":"z0_4NwvjOxxi","executionInfo":{"status":"ok","timestamp":1756567094676,"user_tz":-480,"elapsed":5,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Model & columns\n","MODEL_ID  = \"google/gemma-3-1b-it\"\n","TEXT_COL   = \"comprehensive_review\"\n","LABEL_COLS = [\"is_ad\", \"is_rant\", \"is_relevant\"]\n","num_labels = len(LABEL_COLS)\n","\n","# Toggle LoRA (True to enable efficient fine-tuning adapters)\n","USE_LORA = True\n","\n","# Device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", device)\n","\n","# Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=os.environ.get(\"HF_TOKEN\"))\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319,"referenced_widgets":["9e1681efd89b4783b788bc02fb08ee6f","f61e6ea09283459c979057b8fa28f8eb","3f033f0ab7614485a1e1b9f333f3ebaf","caa77e4df72045ec88c9e8aa4e5026b6","473ac484a5c74b309e15e22897a05be3","8a1285838a774160be573f41a3c6d3d0","bb6bffa971dc4a589fc1a1e267818619","7855e2f531304f87a2bf211e6ec88ab9","a235d52eb2994a77b38eec1af3d95c27","d0d6f0a65f8846d0a660bd3e242c9146","c648788445d2409fa38bae4749fe2b90","bfe83dc10607465abb2c498cfb9a807c","050c81ded7a24edf88b85628a10e3c2c","3176963a4bf34025a811c422ec89e249","37b5d44b91c04cbcba1282ffc3741b28","2c8d09ffe4c34a89975a34445a7de7b3","135c375b3d334984a3f8682f64358946","9e5e939ebc464709b336503545f3a836","d32a459c161540b7bcc0b9b6b8651ea0","74f53cced86b4ffea0a2e75ba3dc88e7","4f8422a6034b4ebc8e223aa5241cdc8e","10ea68a5d168494da20be42f47f18f00","1fc47d22ce1e4d5b97065c298bf3a84e","7bce2c8b36584ed8a03d19d69825b6ba","f72f4062c699426f9dd945f9c33f9b12","82768c7d6b884aa781bd1efaa3446b2d","cd2d0eb4adc649019e031016b7845f88","6c5c4858e403455490738c53f508b0a7","e80aeb03ac354cb5b01f6db63b77548e","878252aed39d4ad88fb9c6f75d715b3c","77a946fe85e14f689a851db98ab57aa9","f8b99cf5f8704e6eb6c6f20410f748a6","94411ab92b104a71bc41bdc6e9b41e42","d64aa34b65474d198935136dccec7369","4c38cbf5ce974d37811d29c3fb8bc55e","5eff39656f5c4bab9b8fe98425bd19f4","dd026294828c434aa20bb242813d90af","0d823c10360d47ab9d48468b0e71e85f","ec0ff7770d2d44319682ce6c53fe2911","0275a4e754aa40bab8cdc21426290d8d","b11458fff2f846a29275a9dcc27999d3","6c28382e8f514fa29f6c1874d306f170","d6fb5bf1dc5747b1a96317a91f693181","78b8ebd57dd546c5b2ab2d0239564b0d","5b83abd7026541f6a4d37ebe5c51ee9f","f811434828304948929b3eec6f5137c0","d5d212b54b324ce3b7fcc97166e34851","7f562ba6db724af8b88c47cd062a6376","c47c9fbc818141938615dda4daa3c1de","ada6a0349c75496596ddda2c41d5dabd","051de271e0c14932bafd57e51f883a17","59731467c462472989dab0611fd978fd","65667cea734548418f7dc9fbc33bdbfa","4774b78983c84442a92613a9909a7ab9","4d9363e0817f4e89a0e431c301ee5e48"]},"id":"tZT7hN-aPZsA","executionInfo":{"status":"ok","timestamp":1756567109838,"user_tz":-480,"elapsed":15165,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"d3277a83-e745-4f13-e966-a27392a1c429"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1681efd89b4783b788bc02fb08ee6f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe83dc10607465abb2c498cfb9a807c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc47d22ce1e4d5b97065c298bf3a84e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d64aa34b65474d198935136dccec7369"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b83abd7026541f6a4d37ebe5c51ee9f"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Stage 1: Data Preprocessing and Validation"],"metadata":{"id":"pLvM952IpA0l"}},{"cell_type":"markdown","source":["**Text and Label Cleaning**\n","\n","We start by loading the CSV data and ensuring data quality. The preprocessing converts all label values to consistent binary format (0 or 1), handling various input formats like strings (\"true\", \"yes\") or boolean values. Empty or missing text entries are removed to prevent training issues.\n","\n","**Train-Validation Split**\n","\n","The dataset is randomly shuffled and split into 90% training and 10% validation sets. This ensures the model can be evaluated on unseen data during training to monitor for overfitting and select the best checkpoint.\n","\n","**Tokenization**\n","\n","Text is converted into numerical tokens that the language model can process. We use a maximum sequence length of 256 tokens to balance between capturing sufficient context and maintaining training efficiency. The tokenizer also adds attention masks to handle variable-length sequences properly."],"metadata":{"id":"1cAtqeJppF0b"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnlBTzZ4Pqab","executionInfo":{"status":"ok","timestamp":1756567126993,"user_tz":-480,"elapsed":17153,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"7ddec7af-f13f-47b7-aaeb-9f4a99c03331"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Load your CSV\n","CSV_PATH = \"/content/drive/MyDrive/all_reviews_with_labels_and_features.csv\"\n","df = pd.read_csv(CSV_PATH)\n","\n","# Ensure required columns exist\n","missing = [c for c in [TEXT_COL] + LABEL_COLS if c not in df.columns]\n","if missing:\n","    raise KeyError(f\"Missing columns in CSV: {missing}\")\n","\n","# Coerce labels to {0,1}\n","def to01(x):\n","    if isinstance(x, str):\n","        x = x.strip().lower()\n","        return 1 if x in {\"1\",\"true\",\"t\",\"yes\",\"y\"} else 0\n","    return int(bool(x))\n","\n","for c in LABEL_COLS:\n","    df[c] = df[c].apply(to01).astype(np.int32)\n","\n","# Drop empty / NaN text\n","df = df[df[TEXT_COL].notna()]\n","df = df[df[TEXT_COL].astype(str).str.strip().ne(\"\")].reset_index(drop=True)\n","\n","print(\"Rows after cleaning:\", len(df))\n","display(df[[TEXT_COL] + LABEL_COLS].head(3))\n","\n","# Shuffle & split\n","df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n","split = int(0.9 * len(df))\n","df_train = df.iloc[:split].reset_index(drop=True)\n","df_val   = df.iloc[split:].reset_index(drop=True)\n","\n","# Convert to HF datasets\n","ds_train = Dataset.from_pandas(df_train, preserve_index=False)\n","ds_val   = Dataset.from_pandas(df_val,   preserve_index=False)\n","dataset  = DatasetDict(train=ds_train, validation=ds_val)\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"HMb0Mz1RPbdp","executionInfo":{"status":"ok","timestamp":1756567129865,"user_tz":-480,"elapsed":2877,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"af37765d-ad25-4f30-b6f9-baa2fdf214b0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Rows after cleaning: 11920\n"]},{"output_type":"display_data","data":{"text/plain":["                                comprehensive_review  is_ad  is_rant  \\\n","0  [Business] Auto Spa Speedy Wash - Harvester, M...      0        0   \n","1  [Business] Kmart | [Category] ['Discount store...      1        1   \n","2  [Business] Papa’s Pizza | [Category] ['Pizza r...      0        0   \n","\n","   is_relevant  \n","0            1  \n","1            1  \n","2            1  "],"text/html":["\n","  <div id=\"df-7ed6be94-5e00-46e5-863a-28cafb242b15\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comprehensive_review</th>\n","      <th>is_ad</th>\n","      <th>is_rant</th>\n","      <th>is_relevant</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Business] Auto Spa Speedy Wash - Harvester, M...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[Business] Kmart | [Category] ['Discount store...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[Business] Papa’s Pizza | [Category] ['Pizza r...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ed6be94-5e00-46e5-863a-28cafb242b15')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7ed6be94-5e00-46e5-863a-28cafb242b15 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7ed6be94-5e00-46e5-863a-28cafb242b15');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0402c5fb-e8de-4665-9b8c-82a20f211c84\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0402c5fb-e8de-4665-9b8c-82a20f211c84')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0402c5fb-e8de-4665-9b8c-82a20f211c84 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"dataset\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"comprehensive_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[Business] Auto Spa Speedy Wash - Harvester, MO | [Category] ['Car wash'] | [Rating] 4.0 | [Author] Doug Schmidt | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] Love the convenience of this neighborhood carwash.\",\n          \"[Business] Kmart | [Category] ['Discount store', 'Appliance store', 'Baby store', 'Bedding store', 'Clothing store', 'Department store', 'Electronics store', 'Home goods store', 'Shoe store', 'Toy store'] | [Rating] 2.0 | [Author] Duf Duftopia | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] 2 bathrooms (for a large 2 story building), 1 for each gender. Door in men's room broken, and sleezy (moreso then standard k-marts), Santa definitely gave them Coal this year, dirty, items not priced, electronics was a sub standard \\\"returned tv's\\\" showroom, for 2 workers who remained mobile all the time it was good cause maybe 10 people were shopping. However escalators and elevator ran well. This place will be closed soon k-mart shoppers sale on Isle #2, in Wal-Mart!\",\n          \"[Business] Papa\\u2019s Pizza | [Category] ['Pizza restaurant', 'Chicken wings restaurant', 'Hoagie restaurant', 'Italian restaurant', 'Pizza delivery', 'Pizza Takeout', 'Sandwich shop'] | [Rating] 5.0 | [Author] Andrew Phillips | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] My favorite pizza shop hands down!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_ad\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_rant\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_relevant\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['review_text', 'rating', 'has_photo', 'author_name', 'user_review_count', 'business_name', 'category', 'source', 'review_id', 'comprehensive_review', 'is_ad', 'is_relevant', 'is_rant', 'is_legit', 'average_score', 'has_phone', 'has_link', 'has_email', 'average_rating', 'rating_discrepancy'],\n","        num_rows: 10728\n","    })\n","    validation: Dataset({\n","        features: ['review_text', 'rating', 'has_photo', 'author_name', 'user_review_count', 'business_name', 'category', 'source', 'review_id', 'comprehensive_review', 'is_ad', 'is_relevant', 'is_rant', 'is_legit', 'average_score', 'has_phone', 'has_link', 'has_email', 'average_rating', 'rating_discrepancy'],\n","        num_rows: 1192\n","    })\n","})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["MAX_LEN = 256  # reduce memory use vs 512\n","\n","def preprocess(batch):\n","    enc = tokenizer(batch[TEXT_COL], truncation=True, padding=True, max_length=MAX_LEN)\n","    labels = np.stack([batch[c] for c in LABEL_COLS], axis=1).astype(\"float32\")\n","    enc[\"labels\"] = labels\n","    return enc\n","\n","tokenized = dataset.map(preprocess, batched=True, remove_columns=dataset[\"train\"].column_names)\n","\n","print(\"Tokenized columns (train):\", tokenized[\"train\"].column_names)\n","assert TEXT_COL not in tokenized[\"train\"].column_names\n","\n","# quick type check\n","sample = tokenized[\"train\"][0]\n","for k, v in sample.items():\n","    if k != \"labels\":\n","        assert isinstance(v, list), f\"{k} should be list[int]\"\n","    else:\n","        assert isinstance(v, list) and len(v) == num_labels, f\"labels should be list[float] len={num_labels}\"\n","print(\"✅ Tokenized sample OK\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["f6be9da034094963b2f9cf73db80c55d","b60a97790a994d4bb2b595ebc418db2b","ccb131ba7044419b9edd0064a543c318","8b2599d12ccf437d8e7346ae8b09ef1c","378cf575a5554bef9e3d01f194bc6ca9","088361b591f74ca88145389dc420c732","4e0192a01e73460593f8f27d90cc42dc","6a645c03697947ba95b40ff9b61696d9","4e743f0578384fdeb2a8f5a98607a48a","06d0a0a248814e529b47bb151cec6406","b0a02d66d19e4fc39e86ddb0cec850e2","cb8d3ffbf5b54604bb6f500b8bc80b51","762bedc2314549e2af5562c02ec5b480","7a867022a9284b74a8dc08f6abbe7556","bf288d9f5f3644c1bd48191dbf7ea842","ec84c9c485dc4c0683cf2d6777f471eb","efa3df2af23d4d308c88435c7e37bad6","47029716a4d04a0e9bab6b9ce3bd1110","96a52c708c264b2d9c9aab6c3bc09d73","74562e7576844ac9b73a9052f135308d","60a6add23e5745d0ab2b74547a95794c","8c44302c38854d1cae51aa0d923ff1d6"]},"id":"wLzMTceePkPo","executionInfo":{"status":"ok","timestamp":1756567136231,"user_tz":-480,"elapsed":6364,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"99ba6ada-2445-4576-94fa-aa0989724410"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10728 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6be9da034094963b2f9cf73db80c55d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1192 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8d3ffbf5b54604bb6f500b8bc80b51"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenized columns (train): ['input_ids', 'attention_mask', 'labels']\n","✅ Tokenized sample OK\n"]}]},{"cell_type":"code","source":["# Compute per-label positive rates on TRAIN split only\n","y_train = np.stack(tokenized[\"train\"][\"labels\"])  # shape (N, num_labels)\n","pos_rate = y_train.mean(axis=0)                   # per-label positive rate\n","pos_weight = (1.0 - pos_rate) / (pos_rate + 1e-8)\n","pos_weight_t = torch.tensor(pos_weight, dtype=torch.float32, device=device)\n","\n","print(\"Positive rates per label:\", dict(zip(LABEL_COLS, np.round(pos_rate, 4))))\n","print(\"pos_weight per label:\",     dict(zip(LABEL_COLS, np.round(pos_weight, 4))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GN_zRQ6DP194","executionInfo":{"status":"ok","timestamp":1756567136986,"user_tz":-480,"elapsed":746,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"6e2c095c-e657-4d7c-e6e6-d02c4e305ba3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive rates per label: {'is_ad': np.float64(0.0327), 'is_rant': np.float64(0.0779), 'is_relevant': np.float64(0.9645)}\n","pos_weight per label: {'is_ad': np.float64(29.5641), 'is_rant': np.float64(11.8325), 'is_relevant': np.float64(0.0368)}\n"]}]},{"cell_type":"markdown","source":["## Stage 2: Model Architecture Design"],"metadata":{"id":"hFzHTXw8pSeh"}},{"cell_type":"markdown","source":["**Base Language Model Selection**\n","\n","We use Gemma3-1B as the backbone for this version of model training. It is relatively small but capable models that provide a good balance between performance and training speed. The models come pre-trained on large text corpora, giving us strong linguistic representations.\n","\n","**LoRA (Low-Rank Adaptation) Integration**\n","\n","Instead of fine-tuning all model parameters (which would be slow and memory-intensive), we apply LoRA adapters. This technique freezes the original model weights and only trains small \"adapter\" layers inserted into the attention mechanisms. This reduces trainable parameters by ~90% while maintaining most of the performance.\n","\n","**Classification Head Architecture**\n","\n","The model outputs are processed through several layers:\n","\n","* Mean Pooling: Converts variable-length token sequences into fixed-size vectors by averaging embeddings across the sequence length (respecting attention masks)\n","* Dropout Layer: Provides regularization to prevent overfitting\n","* Linear Classifier: Maps the pooled representation to logits for each label\n"],"metadata":{"id":"mjhrFE0spVKm"}},{"cell_type":"code","source":["class MeanPooler(nn.Module):\n","    def forward(self, last_hidden_state, attention_mask):\n","        mask = attention_mask.unsqueeze(-1)\n","        summed = (last_hidden_state * mask).sum(1)\n","        counts = mask.sum(1).clamp(min=1e-6)\n","        return summed / counts\n","\n","\n","# Multi-label Classifier With LoRA Optimisation\n","# We use LoRA adaptors for efficient fine-tuning of a pre-trained gemma-3-1b model\n","# and we include drop-out layers for regularisation to prevent overfitting\n","class OptimizedClassifier(nn.Module):\n","    def __init__(self, model_id: str, num_labels: int, token=None):\n","        super().__init__()\n","\n","        # Load base model with optimizations\n","        self.base = AutoModel.from_pretrained(\n","            model_id,\n","            token=token,\n","            torch_dtype=torch.float16,  # Memory optimization\n","        )\n","\n","        # Apply LoRA for efficiency as it freezes the base model and only trains\n","        # small adaptor layers, finetuning the model\n","        lora_config = LoraConfig(\n","            r=16,  # Slightly higher rank for better performance\n","            lora_alpha=32,\n","            lora_dropout=0.1,\n","            target_modules=[\"q_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n","            bias=\"none\",\n","            task_type=\"FEATURE_EXTRACTION\",\n","        )\n","        self.base = get_peft_model(self.base, lora_config)\n","\n","        self.config = self.base.config\n","        self.pool = MeanPooler()\n","        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n","        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n","        last_hidden_state = outputs.last_hidden_state\n","\n","        pooled = self.pool(last_hidden_state, attention_mask)\n","        pooled = self.dropout(pooled)\n","        # Generating logits for each label\n","        logits = self.classifier(pooled)\n","\n","        loss = None\n","        if labels is not None:\n","            # Multi-label classification with class balancing\n","            loss_fct = nn.BCEWithLogitsLoss()\n","            loss = loss_fct(logits, labels)\n","\n","        return SequenceClassifierOutput(loss=loss, logits=logits)"],"metadata":{"id":"ULyHLkSscvTl","executionInfo":{"status":"ok","timestamp":1756567225794,"user_tz":-480,"elapsed":21,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Stage 3: Multi-Label Loss Function"],"metadata":{"id":"QhBePWUopuuc"}},{"cell_type":"markdown","source":["**Binary Cross-Entropy with Logits**\n","\n","Unlike multi-class classification (where each sample has exactly one label), multi-label classification treats each label as an independent binary decision. We use `BCEWithLogitsLoss` which:\n","\n","* Applies sigmoid activation internally to convert logits to probabilities\n","* Calculates binary cross-entropy loss for each label independently\n","* Allows each sample to have zero, one, or multiple positive labels\n","\n","**Class Imbalance Considerations**\n","\n","While the current implementation uses standard BCE loss, the framework supports adding `pos_weight` parameters to handle imbalanced labels (where some labels are much rarer than others)."],"metadata":{"id":"yAVWaTmcpw4y"}},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","\n","    # Convert logits into probabilities using sigmoid, then threshold at 0.5\n","    # which can be further tuned in future iterations\n","    probs = 1 / (1 + np.exp(-predictions))  # sigmoid\n","    preds = (probs >= 0.5).astype(int)\n","\n","    metrics = {}\n","\n","    # Per-label metrics\n","    for i in range(labels.shape[1]):\n","        precision, recall, f1, _ = precision_recall_fscore_support(\n","            labels[:, i], preds[:, i], average=\"binary\", zero_division=0\n","        )\n","        metrics[f'eval_precision_label_{i}'] = precision\n","        metrics[f'eval_recall_label_{i}'] = recall\n","        metrics[f'eval_f1_label_{i}'] = f1\n","\n","    # Macro averages across all labels\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n","        labels, preds, average=\"macro\", zero_division=0\n","    )\n","\n","    metrics.update({\n","        'eval_precision_macro': precision_macro,\n","        'eval_recall_macro': recall_macro,\n","        'eval_f1_macro': f1_macro,\n","    })\n","\n","    return metrics\n","\n","def print_final_metrics(trainer, test_dataset, class_names=None):\n","    \"\"\"Print detailed per-label metrics after training for multi-label classification\"\"\"\n","    predictions = trainer.predict(test_dataset)\n","\n","    # Multi-label: sigmoid + threshold\n","    probs = 1 / (1 + np.exp(-predictions.predictions))\n","    preds = (probs >= 0.5).astype(int)\n","    labels = predictions.label_ids\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"FINAL MULTI-LABEL CLASSIFICATION METRICS\")\n","    print(\"=\"*70)\n","\n","    if class_names is None:\n","        class_names = [f\"Label_{i}\" for i in range(labels.shape[1])]\n","\n","    print(f\"{'Label':<20} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n","    print(\"-\" * 70)\n","\n","    # Per-label metrics\n","    all_precision, all_recall, all_f1 = [], [], []\n","\n","    for i, name in enumerate(class_names):\n","        precision, recall, f1, support = precision_recall_fscore_support(\n","            labels[:, i], preds[:, i], average=\"binary\", zero_division=0\n","        )\n","        print(f\"{name:<20} {precision:<10.3f} {recall:<10.3f} {f1:<10.3f} {np.sum(labels[:, i]):<10}\")\n","\n","        all_precision.append(precision)\n","        all_recall.append(recall)\n","        all_f1.append(f1)\n","\n","    # Macro averages\n","    macro_precision = np.mean(all_precision)\n","    macro_recall = np.mean(all_recall)\n","    macro_f1 = np.mean(all_f1)\n","\n","    print(\"-\" * 70)\n","    print(f\"{'Macro Average':<20} {macro_precision:<10.3f} {macro_recall:<10.3f} {macro_f1:<10.3f} {len(labels):<10}\")\n","    print(\"=\"*70)"],"metadata":{"id":"OXtXkRhlc935","executionInfo":{"status":"ok","timestamp":1756567136998,"user_tz":-480,"elapsed":15,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Stage 4: Training Configuration and Optimization"],"metadata":{"id":"2tOoOo9NqD-n"}},{"cell_type":"markdown","source":["**Hyperparameter Selection**\n","\n","The training uses parameters optimised for smaller models with LoRA:\n","* Learning Rate (5e-4): Higher than typical fine-tuning because LoRA adapters can handle more aggressive updates\n","* Batch Size (32/64): Larger batches possible due to smaller model size and LoRA efficiency\n","* Epochs (3): Sufficient for LoRA adaptation without overfitting\n","\n","\n","**Performance Optimizations**\n","\n","Several techniques ensure fast training:\n","\n","* Mixed Precision (FP16): Uses 16-bit floating point to reduce memory usage and increase speed\n","* Efficient Attention: Uses Pytorch's optimised scaled dot-product attention\n","* Parallel Data Loading: Multiple workers load batches in parallel\n","* Length Grouping: Batches similar-length sequences together to minimize padding\n","\n","**Evaluation Strategy**\n","\n","The model is evaluated every 100 training steps, allowing us to:\n","\n","* Monitor training progress in real-time\n","* Detect overfitting early\n","* Save the best-performing checkpoint based on macro F1 score"],"metadata":{"id":"XK4zm8ptqG3h"}},{"cell_type":"code","source":["# Main training pipeline\n","\n","def train_classifier(\n","    model_id: str,\n","    train_dataset,\n","    eval_dataset,\n","    test_dataset,\n","    num_labels: int,\n","    class_names=None,\n","    output_dir=\"./results\"\n","):\n","\n","    # Initialize model with LoRA optimisation\n","    model = OptimizedClassifier(\n","        model_id=model_id,\n","        num_labels=num_labels,\n","        token=os.environ.get(\"HF_TOKEN\")\n","    )\n","\n","    # Print trainable parameters\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"Trainable: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.2f}%)\")\n","\n","    # Optimized training arguments\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        num_train_epochs=2,  # Reduced for speed\n","        per_device_train_batch_size=16,  # Larger batch size\n","        per_device_eval_batch_size=32,\n","        learning_rate=3e-4,  # Higher LR for LoRA\n","        lr_scheduler_type=\"cosine\",\n","        warmup_ratio=0.1,\n","\n","        # # Evaluation\n","        # evaluation_strategy=\"steps\",\n","        # eval_steps=100,\n","        # save_strategy=\"steps\",\n","        # save_steps=100,\n","\n","        # # Best model tracking\n","        # load_best_model_at_end=True,\n","        # metric_for_best_model=\"eval_f1_macro\",\n","        # greater_is_better=True,\n","\n","        # Optimizations\n","        fp16=torch.cuda.is_available(),\n","        dataloader_num_workers=4,\n","        dataloader_pin_memory=True,\n","        group_by_length=True,\n","        remove_unused_columns=False,\n","\n","        # Reduce logging for speed\n","        logging_steps=100,\n","        save_total_limit=2,\n","        report_to=[],\n","    )\n","\n","    # Initialize trainer\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    # Train\n","    print(\"Starting training...\")\n","    trainer.train()\n","\n","    # Print final detailed metrics\n","    print_final_metrics(trainer, test_dataset, class_names)\n","\n","    return trainer, model"],"metadata":{"id":"4WK3xfzbdBND","executionInfo":{"status":"ok","timestamp":1756567292602,"user_tz":-480,"elapsed":46,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["trainer, model = train_classifier(\n","    model_id=MODEL_ID,\n","    train_dataset=tokenized[\"train\"],           # Your tokenized train split\n","    eval_dataset=tokenized[\"validation\"],       # Your tokenized validation split\n","    test_dataset=tokenized[\"validation\"],       # Use validation as test (or create separate test split)\n","    num_labels=len(LABEL_COLS),                # Number of label columns you have\n","    class_names=LABEL_COLS,                    # Your actual label column names\n","    output_dir=\"./classifier_results\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885},"id":"W9jScWpAdJLQ","executionInfo":{"status":"ok","timestamp":1756570056776,"user_tz":-480,"elapsed":2763572,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"dd4ffa43-c7fc-4f24-c0f5-6c168260e9d2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of Gemma3TextModel were not initialized from the model checkpoint at google/gemma-3-1b-it and are newly initialized: ['embed_tokens.weight', 'layers.0.input_layernorm.weight', 'layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.post_attention_layernorm.weight', 'layers.0.post_feedforward_layernorm.weight', 'layers.0.pre_feedforward_layernorm.weight', 'layers.0.self_attn.k_norm.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_norm.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.input_layernorm.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.post_attention_layernorm.weight', 'layers.1.post_feedforward_layernorm.weight', 'layers.1.pre_feedforward_layernorm.weight', 'layers.1.self_attn.k_norm.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_norm.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.input_layernorm.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.post_attention_layernorm.weight', 'layers.10.post_feedforward_layernorm.weight', 'layers.10.pre_feedforward_layernorm.weight', 'layers.10.self_attn.k_norm.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_norm.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.input_layernorm.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.post_attention_layernorm.weight', 'layers.11.post_feedforward_layernorm.weight', 'layers.11.pre_feedforward_layernorm.weight', 'layers.11.self_attn.k_norm.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_norm.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.input_layernorm.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.post_attention_layernorm.weight', 'layers.12.post_feedforward_layernorm.weight', 'layers.12.pre_feedforward_layernorm.weight', 'layers.12.self_attn.k_norm.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_norm.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.input_layernorm.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.post_attention_layernorm.weight', 'layers.13.post_feedforward_layernorm.weight', 'layers.13.pre_feedforward_layernorm.weight', 'layers.13.self_attn.k_norm.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_norm.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.input_layernorm.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.post_attention_layernorm.weight', 'layers.14.post_feedforward_layernorm.weight', 'layers.14.pre_feedforward_layernorm.weight', 'layers.14.self_attn.k_norm.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_norm.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.input_layernorm.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.post_attention_layernorm.weight', 'layers.15.post_feedforward_layernorm.weight', 'layers.15.pre_feedforward_layernorm.weight', 'layers.15.self_attn.k_norm.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_norm.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.input_layernorm.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.post_attention_layernorm.weight', 'layers.16.post_feedforward_layernorm.weight', 'layers.16.pre_feedforward_layernorm.weight', 'layers.16.self_attn.k_norm.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_norm.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.input_layernorm.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.post_attention_layernorm.weight', 'layers.17.post_feedforward_layernorm.weight', 'layers.17.pre_feedforward_layernorm.weight', 'layers.17.self_attn.k_norm.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_norm.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.input_layernorm.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.post_attention_layernorm.weight', 'layers.18.post_feedforward_layernorm.weight', 'layers.18.pre_feedforward_layernorm.weight', 'layers.18.self_attn.k_norm.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_norm.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.input_layernorm.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.post_attention_layernorm.weight', 'layers.19.post_feedforward_layernorm.weight', 'layers.19.pre_feedforward_layernorm.weight', 'layers.19.self_attn.k_norm.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_norm.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.input_layernorm.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.post_attention_layernorm.weight', 'layers.2.post_feedforward_layernorm.weight', 'layers.2.pre_feedforward_layernorm.weight', 'layers.2.self_attn.k_norm.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_norm.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.input_layernorm.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.post_attention_layernorm.weight', 'layers.20.post_feedforward_layernorm.weight', 'layers.20.pre_feedforward_layernorm.weight', 'layers.20.self_attn.k_norm.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_norm.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.input_layernorm.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.post_attention_layernorm.weight', 'layers.21.post_feedforward_layernorm.weight', 'layers.21.pre_feedforward_layernorm.weight', 'layers.21.self_attn.k_norm.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_norm.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.input_layernorm.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.post_attention_layernorm.weight', 'layers.22.post_feedforward_layernorm.weight', 'layers.22.pre_feedforward_layernorm.weight', 'layers.22.self_attn.k_norm.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_norm.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.input_layernorm.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.post_attention_layernorm.weight', 'layers.23.post_feedforward_layernorm.weight', 'layers.23.pre_feedforward_layernorm.weight', 'layers.23.self_attn.k_norm.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_norm.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.input_layernorm.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.post_attention_layernorm.weight', 'layers.24.post_feedforward_layernorm.weight', 'layers.24.pre_feedforward_layernorm.weight', 'layers.24.self_attn.k_norm.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_norm.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.input_layernorm.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.post_attention_layernorm.weight', 'layers.25.post_feedforward_layernorm.weight', 'layers.25.pre_feedforward_layernorm.weight', 'layers.25.self_attn.k_norm.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_norm.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.3.input_layernorm.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.post_attention_layernorm.weight', 'layers.3.post_feedforward_layernorm.weight', 'layers.3.pre_feedforward_layernorm.weight', 'layers.3.self_attn.k_norm.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_norm.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.4.input_layernorm.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.post_attention_layernorm.weight', 'layers.4.post_feedforward_layernorm.weight', 'layers.4.pre_feedforward_layernorm.weight', 'layers.4.self_attn.k_norm.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_norm.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.input_layernorm.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.post_attention_layernorm.weight', 'layers.5.post_feedforward_layernorm.weight', 'layers.5.pre_feedforward_layernorm.weight', 'layers.5.self_attn.k_norm.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_norm.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.input_layernorm.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.post_attention_layernorm.weight', 'layers.6.post_feedforward_layernorm.weight', 'layers.6.pre_feedforward_layernorm.weight', 'layers.6.self_attn.k_norm.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_norm.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.input_layernorm.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.post_attention_layernorm.weight', 'layers.7.post_feedforward_layernorm.weight', 'layers.7.pre_feedforward_layernorm.weight', 'layers.7.self_attn.k_norm.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_norm.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.input_layernorm.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.post_attention_layernorm.weight', 'layers.8.post_feedforward_layernorm.weight', 'layers.8.pre_feedforward_layernorm.weight', 'layers.8.self_attn.k_norm.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_norm.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.input_layernorm.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.post_attention_layernorm.weight', 'layers.9.post_feedforward_layernorm.weight', 'layers.9.pre_feedforward_layernorm.weight', 'layers.9.self_attn.k_norm.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_norm.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight', 'norm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable: 12,463,491 / 1,012,349,443 (1.23%)\n","Starting training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1342' max='1342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1342/1342 44:21, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.261000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.195200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.204500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.204100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.191400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.167300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.173800</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.171100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.151800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.170600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.145700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.141400</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.164400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","FINAL MULTI-LABEL CLASSIFICATION METRICS\n","======================================================================\n","Label                Precision  Recall     F1-Score   Support   \n","----------------------------------------------------------------------\n","is_ad                0.000      0.000      0.000      40.0      \n","is_rant              0.600      0.300      0.400      80.0      \n","is_relevant          0.960      1.000      0.979      1144.0    \n","----------------------------------------------------------------------\n","Macro Average        0.520      0.433      0.460      1192      \n","======================================================================\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# Copy the entire results folder to Google Drive\n","shutil.copytree(\"./classifier_results\", \"/content/drive/MyDrive/classifier_results\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Om8diTQJwFZW","executionInfo":{"status":"ok","timestamp":1756570514244,"user_tz":-480,"elapsed":160118,"user":{"displayName":"Diane Teo","userId":"16441594256273792913"}},"outputId":"752b387b-7b7d-425c-825c-71d0b955feec"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/classifier_results'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Stage 5: Metrics Calculation and Evaluation"],"metadata":{"id":"uKV6HVFMcxtY"}},{"cell_type":"markdown","source":["**Multi-Label Metrics Framework**\n","\n","For each label, we calculate precision, recall and F1-score as independent-binary classification problems. This differs from multi-class metrics where we would use argmax to select a single prediction.\n","\n","**Macro vs Micro Averaging**\n","\n","We focus on macro averaging, which:\n","* Treats each label equally regardless of frequency\n","* Provides better insights for imbalanced datasets\n","* Gives equal weight to rare and common labels\n","\n","**Per-Label Performance Tracking**\n","The system tracks individual metrics for each label, allowing identification of:\n","* Labels the model learns easily vs. struggles with i.e. labels that might need different treatment/more training data\n","* Potential data quality issues in specific labels"],"metadata":{"id":"k8kWt6REqkBQ"}},{"cell_type":"markdown","source":["## Future Improvements"],"metadata":{"id":"exKR1jvzrHYq"}},{"cell_type":"markdown","source":["### 1. Model Scale and Architecture\n","* With more compute, we would be able to use larger models (e.g. Gemma3 models/Qwen3 models with a larger number of parameters) for significantly better language understanding and context modelling.\n","\n","### 2. Enhanced Data Engineering\n","* In the aspect of data engineering, our model performance might be improved through embedding other signals - e.g. sentiment scores, disparity between average ratings and sentiment scores, rating * sentiment scores for internal consistency of reviews etc. These can be appended to the comprehensive review for greater nuance.\n","\n","### 3. Advanced Label Modelling\n","* We could potentially implement hierarchical labels as well, where we model parent-child relationships between labels e.g. is_legit is the child of is_ad, is_rant and is_relevant.\n","\n","### 4. Model Interpretability\n","* In terms of interpretability, which is the limitation of most machine learning models, attention visualisation could be implemented to show which words drive the predictions.\n","\n","### 5. Active Learning and Human-In-The-Loop\n","* With additional resources, we could implement an active learning system that identifiees the most informative unlabeled examples for human annotation. This would maximise the value of limited labeling budget by focusing human effort by focusing human effort on samples that most improve model performance, creating a continuous feedback loop between model predictions and expert knowledge."],"metadata":{"id":"mTbNuAhIrLYj"}},{"cell_type":"code","source":[],"metadata":{"id":"2cwhXEEkslMf"},"execution_count":null,"outputs":[]}]}