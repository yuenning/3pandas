{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9638c6d0",
      "metadata": {
        "id": "9638c6d0"
      },
      "source": [
        "# **Problem Statement 1**  \n",
        "### **Filtering the Noise: ML for Trustworthy Location Reviews**  \n",
        "**Team 3Pandas** *(Tran Ha My, Diane Teo Min Xuan, Ng Yuen Ning)*  \n",
        "\n",
        "---\n",
        "\n",
        "## **Problem Statement**  \n",
        "Design and implement an **ML-based system** to evaluate the **quality** and **relevancy** of Google location reviews. The system should:  \n",
        "\n",
        "- **Gauge review quality:** Detect spam, advertisements, irrelevant content, and rants from users who have likely never visited the location.  \n",
        "- **Assess relevancy:** Determine whether the content of a review is genuinely related to the location being reviewed.  \n",
        "- **Enforce policies:** Automatically flag or filter out reviews that violate the following example policies:  \n",
        "  - No advertisements or promotional content.  \n",
        "  - No irrelevant content (e.g., reviews about unrelated topics).  \n",
        "  - No rants or complaints from users who have not visited the place (can be inferred from content, metadata, or other signals).  \n",
        "\n",
        "---\n",
        "\n",
        "## **Motivation & Impact**  \n",
        "- **For Users:** Increases trust in location-based reviews, leading to better decision-making.  \n",
        "- **For Businesses:** Ensures fair representation and reduces the impact of malicious or irrelevant reviews.  \n",
        "- **For Platforms:** Automates moderation, reduces manual workload, and enhances platform credibility.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Data Sources**  \n",
        "\n",
        "| **Data Sources**       | **Details** |\n",
        "|-------------------------|-------------|\n",
        "| **Public Datasets**    | - **Google Review Data:** Open datasets containing Google location reviews (e.g., [Google Local Reviews on Kaggle](https://www.kaggle.com/datasets/denizbilginn/google-maps-restaurant-reviews))<br>- **Google Local review data:** [UCSD Public Dataset](https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal/)<br>- **Alternative Sources:** Yelp, TripAdvisor, or other open review datasets for supplementary training. |\n",
        "| **Student-Crawled Data** | - Students are encouraged to crawl additional reviews from Google Maps (in compliance with Google's terms of service).<br>- **Example:** [Scraping Google Reviews (YouTube)](https://www.youtube.com/watch?v=LYMdZ7W9bWQ) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1a970a",
      "metadata": {
        "id": "0e1a970a"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tN945_vgCRlz",
      "metadata": {
        "id": "tN945_vgCRlz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "TntPihBO05xl",
      "metadata": {
        "id": "TntPihBO05xl"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate datasets peft torch tensorboard iterative-stratification scikit-learn plotly optuna\n",
        "!pip install --upgrade --quiet nltk textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b1a2762e",
      "metadata": {
        "id": "b1a2762e"
      },
      "outputs": [],
      "source": [
        "# ===== Standard Library =====\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import shutil\n",
        "import psutil\n",
        "import yaml\n",
        "import json\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# ===== Data Processing & Utilities =====\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from datasets import Dataset\n",
        "\n",
        "# ===== PyTorch & CUDA =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# ===== Transformers & NLP Models =====\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    pipeline,\n",
        "    get_scheduler\n",
        ")\n",
        "\n",
        "# ===== Hugging Face PEFT (LoRA) =====\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# ===== Evaluation Metrics =====\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_recall_fscore_support,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "# ===== ML Utilities =====\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45439a3",
      "metadata": {},
      "source": [
        "### For Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "wDJqjMcvM33_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDJqjMcvM33_",
        "outputId": "6f0947cd-0c86-4613-b06f-9499db9e1c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ktcGgrRw0OWM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "ktcGgrRw0OWM",
        "outputId": "e6120913-6002-4b4f-ac5c-1319b4ecc0f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6cf0e9f1-907c-429c-ad7b-836dc05d2453\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6cf0e9f1-907c-429c-ad7b-836dc05d2453\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all_reviews_with_labels_normalised.csv to all_reviews_with_labels_normalised (1).csv\n",
            "Saving synthetic_combined.csv to synthetic_combined (1).csv\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "351b0a75",
      "metadata": {},
      "source": [
        "### For Local Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec93d31",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Model directory: c:\\Users\\ningy\\Desktop\\NUS\\Personal Projects\\TikTok_TechJam_2025\\3pandas\\yuenning_model\n",
            "Files in yuenning_model folder:\n",
            "  üìÑ multilabel_thresholds.json (0.1 KB)\n",
            "  üìÑ qwen_gemma_multilabel_final_3.zip (6699.7 KB)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_dir = Path(\"yuenning_model\")\n",
        "print(f\"Model directory: {model_dir.absolute()}\")\n",
        "\n",
        "if model_dir.exists():\n",
        "    print(\"Files in yuenning_model folder:\")\n",
        "    for file in model_dir.iterdir():\n",
        "        if file.is_file():\n",
        "            print(f\"  üìÑ {file.name} ({file.stat().st_size / 1024:.1f} KB)\")\n",
        "        else:\n",
        "            print(f\"  üìÅ {file.name}/\")\n",
        "else:\n",
        "    print(\"‚ùå yuenning_model folder not found!\")\n",
        "    print(\"Current directory contents:\")\n",
        "    for item in Path('.').iterdir():\n",
        "        print(f\"  {item.name}{'/' if item.is_dir() else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b426534",
      "metadata": {
        "id": "4b426534"
      },
      "source": [
        "### 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "JgSLDXqZ0nR6",
      "metadata": {
        "id": "JgSLDXqZ0nR6"
      },
      "outputs": [],
      "source": [
        "all_reviews = list(uploaded.keys())[0]\n",
        "synthetic_combined = list(uploaded.keys())[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "95d9dd7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d9dd7a",
        "outputId": "1c4076cb-dcec-4aeb-de1b-ddebc4adb356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded all_reviews_with_labels_normalised (1).csv with 11667 rows\n",
            "review_text             0\n",
            "rating                  0\n",
            "has_photo               0\n",
            "author_name             0\n",
            "user_review_count       0\n",
            "business_name           0\n",
            "category                0\n",
            "source                  0\n",
            "review_id               0\n",
            "comprehensive_review    0\n",
            "is_ad                   0\n",
            "is_relevant             0\n",
            "is_rant                 0\n",
            "is_legit                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "full_df = pd.read_csv(all_reviews)\n",
        "full_df = full_df.dropna(subset=['rating']).reset_index(drop=True)\n",
        "\n",
        "print(f\"Loaded {all_reviews} with {len(full_df)} rows\")\n",
        "print(full_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "l-5FU6p_0dv8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-5FU6p_0dv8",
        "outputId": "bdef36a5-b5a8-46ae-8517-35946e2207f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded synthetic_combined (1).csv with 714 rows\n",
            "review_text             0\n",
            "rating                  0\n",
            "has_photo               0\n",
            "author_name             0\n",
            "user_review_count       0\n",
            "business_name           0\n",
            "category                0\n",
            "source                  0\n",
            "review_id               0\n",
            "is_ad                   0\n",
            "is_rant                 0\n",
            "is_legit                0\n",
            "is_relevant             0\n",
            "comprehensive_review    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "synthetic_df = pd.read_csv(synthetic_combined)\n",
        "\n",
        "def s(col):\n",
        "    return synthetic_df[col].fillna(\"NA\").astype(str).str.strip()\n",
        "\n",
        "has_photo_str = np.where(synthetic_df[\"has_photo\"].fillna(False), \"yes\", \"no\")\n",
        "MAX_REVIEW_CHARS = 2000\n",
        "review_text_clean = s(\"review_text\").str.replace(r\"\\s+\", \" \", regex=True).str[:MAX_REVIEW_CHARS]\n",
        "\n",
        "synthetic_df[\"comprehensive_review\"] = (\n",
        "    \"[Business] \" + s(\"business_name\") +\n",
        "    \" | [Category] \" + s(\"category\") +\n",
        "    \" | [Rating] \" + s(\"rating\") +\n",
        "    \" | [Author] \" + s(\"author_name\") +\n",
        "    \" | [User Review Count] \" + s(\"user_review_count\") +\n",
        "    \" | [Has Photo] \" + pd.Series(has_photo_str, index=synthetic_df.index) +\n",
        "    \" | [Source] \" + s(\"source\") +\n",
        "    \" | [Review] \" + review_text_clean\n",
        ").str.replace(r\"\\s+\\|\\s+\\[Review\\]\\s+NA$\", \"\", regex=True)\n",
        "\n",
        "print(f\"Loaded {synthetic_combined} with {len(synthetic_df)} rows\")\n",
        "print(synthetic_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a08e3016",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a08e3016",
        "outputId": "d28bee4d-cfdc-42f9-a781-78668436c5c9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"to_clean_df\",\n  \"rows\": 11667,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11194,\n        \"samples\": [\n          \"Nice place to go!  One of few places with a merry go round anymore.  Great for anything outside!\",\n          \"Great wings and fries\",\n          \"quick, home-style food with a small and simple menu. Milk shakes are very good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.21894107157901,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.0,\n          3.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_photo\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11401,\n        \"samples\": [\n          \"Richard Jensen\",\n          \"Kelley Byrd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_review_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 120.44379856716289,\n        \"min\": 0.0,\n        \"max\": 3062.0,\n        \"num_unique_values\": 448,\n        \"samples\": [\n          391.0,\n          120.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"business_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6124,\n        \"samples\": [\n          \"Nellis Main Exchange\",\n          \"HoDo Restaurant & Lounge\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3383,\n        \"samples\": [\n          \"['Banquet hall', 'Wedding venue']\",\n          \"['Hardware store', 'Grill store', 'Home improvement store', 'Lawn mower store', 'Paint store', 'Tool store']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"singapore\",\n          \"google\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5790,\n        \"min\": 1001,\n        \"max\": 20614,\n        \"num_unique_values\": 11667,\n        \"samples\": [\n          19717,\n          7835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comprehensive_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11659,\n        \"samples\": [\n          \"[Business] Regal UA Kaufman Astoria & RPX | [Category] ['Movie theater'] | [Rating] 3.0 | [Author] Osbaldo Minchala | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] It was okay. The movie i watched was the only good thing I liked about this place.\",\n          \"[Business] Walmart Supercenter | [Category] ['Department store', 'Clothing store', 'Craft store', 'Discount store', 'Electronics store', 'Grocery store', 'Home goods store', 'Sporting goods store', 'Supermarket', 'Toy store'] | [Rating] 1.0 | [Author] Courtney Widick | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] I do not understand why at 7pm on a Tuesday afternoon these only 2 registers open. This is ridiculous waiting in these long lines for a few items when there could be more then 2 registers going right now.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_ad\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_relevant\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_rant\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_legit\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "to_clean_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c64d2738-10bb-44ea-a5cc-5115d8590dd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>rating</th>\n",
              "      <th>has_photo</th>\n",
              "      <th>author_name</th>\n",
              "      <th>user_review_count</th>\n",
              "      <th>business_name</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "      <th>review_id</th>\n",
              "      <th>comprehensive_review</th>\n",
              "      <th>is_ad</th>\n",
              "      <th>is_relevant</th>\n",
              "      <th>is_rant</th>\n",
              "      <th>is_legit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Love the convenience of this neighborhood carw...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Doug Schmidt</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Auto Spa Speedy Wash - Harvester, MO</td>\n",
              "      <td>['Car wash']</td>\n",
              "      <td>google</td>\n",
              "      <td>1001</td>\n",
              "      <td>[Business] Auto Spa Speedy Wash - Harvester, M...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 bathrooms (for a large 2 story building), 1 ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Duf Duftopia</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Kmart</td>\n",
              "      <td>['Discount store', 'Appliance store', 'Baby st...</td>\n",
              "      <td>google</td>\n",
              "      <td>1002</td>\n",
              "      <td>[Business] Kmart | [Category] ['Discount store...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My favorite pizza shop hands down!</td>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Andrew Phillips</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Papa‚Äôs Pizza</td>\n",
              "      <td>['Pizza restaurant', 'Chicken wings restaurant...</td>\n",
              "      <td>google</td>\n",
              "      <td>1003</td>\n",
              "      <td>[Business] Papa‚Äôs Pizza | [Category] ['Pizza r...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Julie Heiland</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The Music Place</td>\n",
              "      <td>['Musical instrument store']</td>\n",
              "      <td>google</td>\n",
              "      <td>1004</td>\n",
              "      <td>[Business] The Music Place | [Category] ['Musi...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very unprofessional!!!!!</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Alan Khasanov</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Park Motor Cars Inc</td>\n",
              "      <td>['Used car dealer']</td>\n",
              "      <td>google</td>\n",
              "      <td>1005</td>\n",
              "      <td>[Business] Park Motor Cars Inc | [Category] ['...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c64d2738-10bb-44ea-a5cc-5115d8590dd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c64d2738-10bb-44ea-a5cc-5115d8590dd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c64d2738-10bb-44ea-a5cc-5115d8590dd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8969abd3-7440-40fe-98ec-6654e293e998\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8969abd3-7440-40fe-98ec-6654e293e998')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8969abd3-7440-40fe-98ec-6654e293e998 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         review_text  rating  has_photo  \\\n",
              "0  Love the convenience of this neighborhood carw...     4.0      False   \n",
              "1  2 bathrooms (for a large 2 story building), 1 ...     2.0      False   \n",
              "2                 My favorite pizza shop hands down!     5.0      False   \n",
              "3  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...     1.0      False   \n",
              "4                           Very unprofessional!!!!!     1.0      False   \n",
              "\n",
              "       author_name  user_review_count                         business_name  \\\n",
              "0     Doug Schmidt                1.0  Auto Spa Speedy Wash - Harvester, MO   \n",
              "1     Duf Duftopia                1.0                                 Kmart   \n",
              "2  Andrew Phillips                1.0                          Papa‚Äôs Pizza   \n",
              "3    Julie Heiland                1.0                       The Music Place   \n",
              "4    Alan Khasanov                1.0                   Park Motor Cars Inc   \n",
              "\n",
              "                                            category  source  review_id  \\\n",
              "0                                       ['Car wash']  google       1001   \n",
              "1  ['Discount store', 'Appliance store', 'Baby st...  google       1002   \n",
              "2  ['Pizza restaurant', 'Chicken wings restaurant...  google       1003   \n",
              "3                       ['Musical instrument store']  google       1004   \n",
              "4                                ['Used car dealer']  google       1005   \n",
              "\n",
              "                                comprehensive_review  is_ad  is_relevant  \\\n",
              "0  [Business] Auto Spa Speedy Wash - Harvester, M...  False         True   \n",
              "1  [Business] Kmart | [Category] ['Discount store...   True         True   \n",
              "2  [Business] Papa‚Äôs Pizza | [Category] ['Pizza r...  False         True   \n",
              "3  [Business] The Music Place | [Category] ['Musi...  False         True   \n",
              "4  [Business] Park Motor Cars Inc | [Category] ['...  False         True   \n",
              "\n",
              "   is_rant  is_legit  \n",
              "0    False      True  \n",
              "1     True     False  \n",
              "2    False      True  \n",
              "3     True     False  \n",
              "4     True     False  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_clean_df = full_df.dropna(subset=['review_text', 'is_ad', 'is_relevant', 'is_rant', 'is_legit'])\n",
        "\n",
        "to_clean_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb37d5d",
      "metadata": {
        "id": "bfb37d5d"
      },
      "source": [
        "### 2. Pre-Process Datafames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a6b8904",
      "metadata": {
        "id": "7a6b8904"
      },
      "source": [
        "##### 2.1 Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f12b429b",
      "metadata": {
        "id": "f12b429b"
      },
      "outputs": [],
      "source": [
        "def normalize_whitespace(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = normalize_whitespace(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c60b82",
      "metadata": {
        "id": "f1c60b82"
      },
      "source": [
        "##### 2.2 Compute Basic Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e7f4cc3e",
      "metadata": {
        "id": "e7f4cc3e"
      },
      "outputs": [],
      "source": [
        "def compute_basic_signals(text):\n",
        "    url_count = len(re.findall(r'https?://\\S+', text))\n",
        "    phone_count = len(re.findall(r'\\+?\\d[\\d\\s-]{7,}\\d', text))\n",
        "    caps_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
        "    return url_count, phone_count, caps_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8e54ee",
      "metadata": {
        "id": "9c8e54ee"
      },
      "source": [
        "##### 2.3 Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2bf2489e",
      "metadata": {
        "id": "2bf2489e"
      },
      "outputs": [],
      "source": [
        "def add_textblob_sentiment(df, text_col=\"review_text\", positive_threshold=0.9, negative_threshold=-0.9):\n",
        "    def get_sentiment(text):\n",
        "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
        "            return 0.0, 0.0\n",
        "        try:\n",
        "            analysis = TextBlob(text)\n",
        "            return analysis.sentiment.polarity, analysis.sentiment.subjectivity\n",
        "        except Exception:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "    sentiment_results = df[text_col].apply(get_sentiment)\n",
        "    df[\"sentiment_polarity\"], df[\"sentiment_subjectivity\"] = zip(*sentiment_results)\n",
        "\n",
        "    df[\"is_extreme_sentiment\"] = df[\"sentiment_polarity\"].apply(\n",
        "        lambda x: 1 if x >= positive_threshold or x <= negative_threshold else 0\n",
        "    )\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b0298e4",
      "metadata": {
        "id": "8b0298e4"
      },
      "source": [
        "##### Apply to Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7e0173de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e0173de",
        "outputId": "4bd212ca-eaba-4f99-875d-0eac543b89e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         review_text  rating  has_photo  \\\n",
            "0  Love the convenience of this neighborhood carw...     4.0      False   \n",
            "1  2 bathrooms (for a large 2 story building), 1 ...     2.0      False   \n",
            "2                 My favorite pizza shop hands down!     5.0      False   \n",
            "3  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...     1.0      False   \n",
            "4                           Very unprofessional!!!!!     1.0      False   \n",
            "\n",
            "       author_name  user_review_count                         business_name  \\\n",
            "0     Doug Schmidt                1.0  Auto Spa Speedy Wash - Harvester, MO   \n",
            "1     Duf Duftopia                1.0                                 Kmart   \n",
            "2  Andrew Phillips                1.0                          Papa‚Äôs Pizza   \n",
            "3    Julie Heiland                1.0                       The Music Place   \n",
            "4    Alan Khasanov                1.0                   Park Motor Cars Inc   \n",
            "\n",
            "                                            category  source  review_id  \\\n",
            "0                                       ['Car wash']  google       1001   \n",
            "1  ['Discount store', 'Appliance store', 'Baby st...  google       1002   \n",
            "2  ['Pizza restaurant', 'Chicken wings restaurant...  google       1003   \n",
            "3                       ['Musical instrument store']  google       1004   \n",
            "4                                ['Used car dealer']  google       1005   \n",
            "\n",
            "                                comprehensive_review  is_ad  is_relevant  \\\n",
            "0  [Business] Auto Spa Speedy Wash - Harvester, M...  False         True   \n",
            "1  [Business] Kmart | [Category] ['Discount store...   True         True   \n",
            "2  [Business] Papa‚Äôs Pizza | [Category] ['Pizza r...  False         True   \n",
            "3  [Business] The Music Place | [Category] ['Musi...  False         True   \n",
            "4  [Business] Park Motor Cars Inc | [Category] ['...  False         True   \n",
            "\n",
            "   is_rant  is_legit                                         clean_text  \\\n",
            "0    False      True  Love the convenience of this neighborhood carw...   \n",
            "1     True     False  2 bathrooms (for a large 2 story building), 1 ...   \n",
            "2    False      True                 My favorite pizza shop hands down!   \n",
            "3     True     False  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...   \n",
            "4     True     False                           Very unprofessional!!!!!   \n",
            "\n",
            "   url_count  phone_count  caps_ratio  \n",
            "0          0            0    0.020000  \n",
            "1          0            0    0.016949  \n",
            "2          0            0    0.029412  \n",
            "3          0            0    0.042589  \n",
            "4          0            0    0.041667  \n",
            "                                         review_text  rating  has_photo  \\\n",
            "0  Had a fantastic meal at The Gourmet Place! The...       5       True   \n",
            "1  Great experience at FitLife Gym! The equipment...       4      False   \n",
            "2  Staying at Oceanview Hotel was a dream! The vi...       5       True   \n",
            "3  The Family Clinic is amazing! They really take...       4      False   \n",
            "4  I love shopping at Trendy Mall! They have ever...       5       True   \n",
            "\n",
            "      author_name  user_review_count      business_name       category  \\\n",
            "0   Sophia Turner                 23  The Gourmet Place     restaurant   \n",
            "1   Michael Brown                 15        FitLife Gym            gym   \n",
            "2     Emily Davis                 30    Oceanview Hotel          hotel   \n",
            "3     Liam Wilson                 10      Family Clinic         clinic   \n",
            "4  Olivia Johnson                 28        Trendy Mall  shopping mall   \n",
            "\n",
            "   source  review_id  is_ad  is_rant  is_legit  is_relevant  \\\n",
            "0  Google      20615   True    False     False         True   \n",
            "1    Yelp      20616   True    False     False         True   \n",
            "2  Google      20617   True    False     False         True   \n",
            "3    Yelp      20618   True    False     False         True   \n",
            "4  Google      20619   True    False     False         True   \n",
            "\n",
            "                                comprehensive_review  \\\n",
            "0  [Business] The Gourmet Place | [Category] rest...   \n",
            "1  [Business] FitLife Gym | [Category] gym | [Rat...   \n",
            "2  [Business] Oceanview Hotel | [Category] hotel ...   \n",
            "3  [Business] Family Clinic | [Category] clinic |...   \n",
            "4  [Business] Trendy Mall | [Category] shopping m...   \n",
            "\n",
            "                                          clean_text  url_count  phone_count  \\\n",
            "0  Had a fantastic meal at The Gourmet Place! The...          1            0   \n",
            "1  Great experience at FitLife Gym! The equipment...          0            1   \n",
            "2  Staying at Oceanview Hotel was a dream! The vi...          1            0   \n",
            "3  The Family Clinic is amazing! They really take...          1            0   \n",
            "4  I love shopping at Trendy Mall! They have ever...          1            0   \n",
            "\n",
            "   caps_ratio  \n",
            "0    0.042424  \n",
            "1    0.041958  \n",
            "2    0.038168  \n",
            "3    0.034965  \n",
            "4    0.045045  \n"
          ]
        }
      ],
      "source": [
        "def preprocess_reviews(df):\n",
        "    df[\"clean_text\"] = df[\"review_text\"].apply(clean_text)\n",
        "    signals = df[\"clean_text\"].apply(compute_basic_signals)\n",
        "    df[\"url_count\"], df[\"phone_count\"], df[\"caps_ratio\"] = zip(*signals)\n",
        "    return df\n",
        "\n",
        "cleaned_df = preprocess_reviews(to_clean_df)\n",
        "print(cleaned_df.head())\n",
        "\n",
        "cleaned_synthetic_df = preprocess_reviews(synthetic_df)\n",
        "print(cleaned_synthetic_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bab7dfc9",
      "metadata": {
        "id": "bab7dfc9"
      },
      "outputs": [],
      "source": [
        "# # Save as JSON\n",
        "# output_json_path = os.path.join(labeled_input_folder, \"cleaned_df.json\")\n",
        "# cleaned_df.to_json(output_json_path, orient=\"records\", lines=True, force_ascii=False)\n",
        "# print(f\"JSON file saved to: {output_json_path}\")\n",
        "\n",
        "# # Save as Parquet\n",
        "# output_parquet_path = os.path.join(labeled_input_folder, \"cleaned_df.parquet\")\n",
        "# cleaned_df.to_parquet(output_parquet_path, index=False)\n",
        "# print(f\"Parquet file saved to: {output_parquet_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca9f773",
      "metadata": {
        "id": "6ca9f773"
      },
      "source": [
        "### 3. Train-Test Split with Multi-Label Stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "3235d024",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3235d024",
        "outputId": "691db3a2-b915-4a24-da05-63724a5045a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (8181, 18) (includes synthetic data)\n",
            "Validation set size: (1867, 18)\n",
            "Test set size: (2333, 18)\n",
            "Synthetic data in validation set: False\n",
            "Synthetic data in test set: False\n"
          ]
        }
      ],
      "source": [
        "meta_cols = [\"clean_text\", \"url_count\",\"phone_count\",\"caps_ratio\",\"rating\",\"has_photo\",\"user_review_count\"]\n",
        "label_cols = [\"is_ad\", \"is_relevant\", \"is_rant\", \"is_legit\"]\n",
        "\n",
        "X = cleaned_df.drop(columns=label_cols)\n",
        "y = cleaned_df[label_cols].values\n",
        "\n",
        "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "train_val_idx, test_idx = next(mskf.split(X, y))\n",
        "\n",
        "train_val_df = cleaned_df.iloc[train_val_idx].reset_index(drop=True)\n",
        "test_df = cleaned_df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "y_train_val = y[train_val_idx]\n",
        "train_idx, val_idx = next(mskf.split(train_val_df.drop(columns=label_cols), y_train_val))\n",
        "\n",
        "train_df_original = train_val_df.iloc[train_idx].reset_index(drop=True)\n",
        "val_df = train_val_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "train_df = pd.concat([train_df_original, cleaned_synthetic_df], ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "print(f\"Training set size: {train_df.shape} (includes synthetic data)\")\n",
        "print(f\"Validation set size: {val_df.shape}\")\n",
        "print(f\"Test set size: {test_df.shape}\")\n",
        "\n",
        "print(f\"Synthetic data in validation set: {val_df['review_id'].isin(cleaned_synthetic_df['review_id']).any()}\")\n",
        "print(f\"Synthetic data in test set: {test_df['review_id'].isin(cleaned_synthetic_df['review_id']).any()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ff6b75",
      "metadata": {
        "id": "03ff6b75"
      },
      "source": [
        "### 4. Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2dc6aa88",
      "metadata": {
        "id": "2dc6aa88"
      },
      "outputs": [],
      "source": [
        "def simple_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    tokens = re.findall(r'\\b[a-z]+\\b', text)\n",
        "    return tokens\n",
        "\n",
        "train_df['tokens'] = train_df['clean_text'].apply(simple_tokenize)\n",
        "test_df['tokens'] = test_df['clean_text'].apply(simple_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c44b1329",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c44b1329",
        "outputId": "46207f5b-3374-4ef1-f71e-cb7229cdc113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8181, 19)\n",
            "(1867, 18)\n",
            "(2333, 19)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66de5f2d",
      "metadata": {
        "id": "66de5f2d"
      },
      "source": [
        "### Yuen Ning's model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65zatjSIU9OG",
      "metadata": {
        "id": "65zatjSIU9OG"
      },
      "source": [
        "### previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "r36ZQQT1O0j_",
      "metadata": {
        "id": "r36ZQQT1O0j_"
      },
      "outputs": [],
      "source": [
        "model_name = \"Qwen/Qwen1.5-0.5B\"  # or \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "B7nZHonMZxy5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7nZHonMZxy5",
        "outputId": "c9623f99-ef71-4a02-86d1-6027eb570143"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4, torch_dtype=\"auto\")\n",
        "config = LoraConfig(r=8, lora_alpha=32, lora_dropout=0.1)\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "JcxJvxOTZ9BM",
      "metadata": {
        "id": "JcxJvxOTZ9BM"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qwen_gemma_multilabel\",\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=3,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "XxlaHks7WGen",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxlaHks7WGen",
        "outputId": "a7de590a-3cd6-499c-fe18-9a63f7eca56e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights (pos_weight): tensor([13.4032,  0.0972,  9.0135,  0.2771])\n"
          ]
        }
      ],
      "source": [
        "label_cols = [\"is_ad\", \"is_relevant\", \"is_rant\", \"is_legit\"]\n",
        "\n",
        "# Convert train_dataset to numpy array of labels\n",
        "labels_array = np.array(train_df[label_cols])\n",
        "pos_counts = labels_array.sum(axis=0)\n",
        "neg_counts = len(labels_array) - pos_counts\n",
        "pos_weight = torch.tensor(neg_counts / (pos_counts + 1e-8), dtype=torch.float)  # avoid divide by zero\n",
        "print(\"Class weights (pos_weight):\", pos_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "koxpmBR_bLy-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "3919752d4d4044ebbebf4f10d8e81188",
            "61da288494334b2cb1c25acdc125ff2e",
            "18074f850e43488dbc0a36a97ad37097",
            "f0dbba45e7da4fb2b93984db6b20b133",
            "0ebe217df7ff43ba908a9abedf6f7d69",
            "d9376cfb19614b679dc133cd7029fa7a",
            "4c71ddb5e7a543e992ffe572fc579f44",
            "a9cdaab9cff5401d8357203f7b5a68f0",
            "d6fe934bea164bbe8d51e69504a39765",
            "e3903458f2f64da682fd28bc7eb20768",
            "b9dfb59e21d54df1aa609752ee4b4170",
            "011f304769ae45789d785e0fc145636c",
            "44ea94ba52b341ac81a608443ffc5870",
            "43d4b9a27f37469b85529ea37daee34e",
            "6a7f43d67fc04c3aa1e360060f41ec54",
            "9ec3cf0871264cdaac74e238bba4a105",
            "380b10ca3de14e8e9ad8ee880cbf45d4",
            "155f66caaaa14951aa0924df75566fca",
            "6a2f6e7b66e145e6a3a3f26d15a0ad6c",
            "ffac5a1a925947148c1d690c19d1766b",
            "3aba02f93ebe4e7fb21914dbe5c87999",
            "a8e14f50e933472497819d05ec3924d9"
          ]
        },
        "id": "koxpmBR_bLy-",
        "outputId": "73051e4b-1532-4e5a-9f97-0ac433f4bfad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3919752d4d4044ebbebf4f10d8e81188",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8180 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "011f304769ae45789d785e0fc145636c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1867 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def preprocess(batch):\n",
        "    return tokenizer(batch[\"clean_text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "def prepare_dataset(df):\n",
        "    # Apply filtering to the DataFrame directly\n",
        "    df = df.reset_index(drop=True)\n",
        "    return Dataset.from_pandas(df[[\"clean_text\"] + label_cols])\n",
        "\n",
        "# Filter train_df before creating the dataset\n",
        "train_df_filtered = train_df.drop(index=7026).reset_index(drop=True)\n",
        "\n",
        "train_dataset = prepare_dataset(train_df_filtered)\n",
        "val_dataset = prepare_dataset(val_df)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess, batched=True)\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"] + label_cols)\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"is_ad\", \"is_relevant\", \"is_rant\", \"is_legit\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "o0S0LuooaTn0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0S0LuooaTn0",
        "outputId": "f889f35c-ab00-4507-e8fc-2b5540b994d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-869084998.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MultiLabelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = MultiLabelTrainer(\n"
          ]
        }
      ],
      "source": [
        "def data_collator(batch):\n",
        "    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
        "    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
        "    labels = torch.stack([\n",
        "        torch.tensor([item[\"is_ad\"], item[\"is_relevant\"], item[\"is_rant\"], item[\"is_legit\"]], dtype=torch.float)\n",
        "        for item in batch\n",
        "    ])\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "\n",
        "class MultiLabelTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = MultiLabelTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "Bd6YlCjNfiWS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Bd6YlCjNfiWS",
        "outputId": "852dccaf-62e7-4652-ba98-b5a081e3b550"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1536' max='1536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1536/1536 32:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.040300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.495100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.284500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1536, training_loss=0.5968945575878024, metrics={'train_runtime': 1977.0227, 'train_samples_per_second': 12.413, 'train_steps_per_second': 0.777, 'total_flos': 2.330930486181888e+16, 'train_loss': 0.5968945575878024, 'epoch': 3.0})"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "lvYXo2HUooHJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvYXo2HUooHJ",
        "outputId": "e54beeec-c38c-4935-e426-42b72312c2c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./qwen_gemma_multilabel_final_3/tokenizer_config.json',\n",
              " './qwen_gemma_multilabel_final_3/special_tokens_map.json',\n",
              " './qwen_gemma_multilabel_final_3/chat_template.jinja',\n",
              " './qwen_gemma_multilabel_final_3/vocab.json',\n",
              " './qwen_gemma_multilabel_final_3/merges.txt',\n",
              " './qwen_gemma_multilabel_final_3/added_tokens.json',\n",
              " './qwen_gemma_multilabel_final_3/tokenizer.json')"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"./qwen_gemma_multilabel_final_3\")\n",
        "tokenizer.save_pretrained(\"./qwen_gemma_multilabel_final_3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "poHEa-qmow_u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "poHEa-qmow_u",
        "outputId": "3d197f36-c5e6-430f-fce3-1ddc9bd3e4c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [234/234 01:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4419700801372528, 'eval_precision': 0.7407957440067051, 'eval_recall': 0.7859766918655908, 'eval_f1': 0.7593047443425293, 'eval_runtime': 63.8983, 'eval_samples_per_second': 29.218, 'eval_steps_per_second': 3.662, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "MpxiNr4FqViQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MpxiNr4FqViQ",
        "outputId": "a06f0af2-5849-4ed9-9f1d-fc861ee599d0"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3ec23c62-1744-4362-abe1-1159c004681b\", \"qwen_gemma_multilabel_final_3.zip\", 6860529)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "shutil.make_archive(\"qwen_gemma_multilabel_final_3\", 'zip', \"./qwen_gemma_multilabel_final_3\")\n",
        "files.download(\"qwen_gemma_multilabel_final_3.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VSGpNyCqgcc9",
      "metadata": {
        "id": "VSGpNyCqgcc9"
      },
      "source": [
        "### 5. Threshold Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "M_o6xKGhf3Vd",
      "metadata": {
        "id": "M_o6xKGhf3Vd"
      },
      "outputs": [],
      "source": [
        "def safe_get_predictions_proba(model, tokenizer, texts, device='cuda', batch_size=16):\n",
        "    \"\"\"Safe prediction function with proper device and type handling\"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Getting predictions\"):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                batch_texts,\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=512,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Explicitly move to device\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.sigmoid(outputs.logits)\n",
        "\n",
        "            # Convert to float32 before moving to CPU for numpy compatibility\n",
        "            probs_float32 = probs.float().cpu().numpy()\n",
        "            all_probs.extend(probs_float32)\n",
        "\n",
        "    return np.array(all_probs)\n",
        "class MultilabelThresholdTuner:\n",
        "    def __init__(self, model, tokenizer, label_cols, device='cuda'):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_cols = label_cols\n",
        "        self.device = device\n",
        "        self.best_thresholds = None\n",
        "        self.best_metrics = None\n",
        "\n",
        "        def safe_get_predictions_proba(model, tokenizer, texts, device='cuda', batch_size=16):\n",
        "            \"\"\"Safe prediction function with proper device and type handling\"\"\"\n",
        "            model.eval()\n",
        "            model.to(device)\n",
        "            all_probs = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for i in tqdm(range(0, len(texts), batch_size), desc=\"Getting predictions\"):\n",
        "                    batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "                    # Tokenize\n",
        "                    inputs = tokenizer(\n",
        "                        batch_texts,\n",
        "                        truncation=True,\n",
        "                        padding=True,\n",
        "                        max_length=512,\n",
        "                        return_tensors='pt'\n",
        "                    )\n",
        "\n",
        "                    # Explicitly move to device\n",
        "                    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "                    outputs = model(**inputs)\n",
        "                    probs = torch.sigmoid(outputs.logits)\n",
        "\n",
        "                    # Convert to float32 before moving to CPU for numpy compatibility\n",
        "                    probs_float32 = probs.float().cpu().numpy()\n",
        "                    all_probs.extend(probs_float32)\n",
        "\n",
        "            return np.array(all_probs)\n",
        "    def get_true_labels_from_df(self, df):\n",
        "        \"\"\"Extract true labels from DataFrame\"\"\"\n",
        "        true_labels = []\n",
        "        for label_col in self.label_cols:\n",
        "            true_labels.append(df[label_col].values)\n",
        "        return np.array(true_labels).T\n",
        "\n",
        "    def optimize_thresholds_per_class(self, y_true, y_probs):\n",
        "        \"\"\"Optimize thresholds for each class using F1 maximization\"\"\"\n",
        "        n_classes = len(self.label_cols)\n",
        "        optimal_thresholds = np.zeros(n_classes)\n",
        "\n",
        "        for class_idx in range(n_classes):\n",
        "            precision, recall, thresholds = precision_recall_curve(\n",
        "                y_true[:, class_idx], y_probs[:, class_idx]\n",
        "            )\n",
        "\n",
        "            # Calculate F1 scores\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "            # Find threshold with maximum F1 score\n",
        "            if len(thresholds) > 0:\n",
        "                best_idx = np.nanargmax(f1_scores[:len(thresholds)])\n",
        "                optimal_thresholds[class_idx] = thresholds[best_idx]\n",
        "\n",
        "                print(f\"{self.label_cols[class_idx]}: Optimal threshold = {thresholds[best_idx]:.3f}, \"\n",
        "                      f\"Max F1 = {f1_scores[best_idx]:.3f}\")\n",
        "            else:\n",
        "                optimal_thresholds[class_idx] = 0.5\n",
        "                print(f\"{self.label_cols[class_idx]}: No thresholds found, using default 0.5\")\n",
        "\n",
        "        return optimal_thresholds\n",
        "\n",
        "    def evaluate_thresholds(self, y_true, y_probs, thresholds):\n",
        "        \"\"\"Evaluate performance with given thresholds\"\"\"\n",
        "        y_pred = (y_probs >= thresholds).astype(int)\n",
        "\n",
        "        from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "        metrics = {\n",
        "            'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
        "            'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
        "            'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
        "            'precision_weighted': precision_score(y_true, y_pred, average='weighted'),\n",
        "            'recall_weighted': recall_score(y_true, y_pred, average='weighted'),\n",
        "        }\n",
        "\n",
        "        # Class-wise metrics\n",
        "        class_metrics = {}\n",
        "        for i, label in enumerate(self.label_cols):\n",
        "            class_metrics[f'{label}_f1'] = f1_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
        "            class_metrics[f'{label}_precision'] = precision_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
        "            class_metrics[f'{label}_recall'] = recall_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
        "\n",
        "        metrics.update(class_metrics)\n",
        "        return metrics, y_pred\n",
        "\n",
        "    def tune_thresholds_from_df(self, df, text_column='clean_text'):\n",
        "        \"\"\"Tune thresholds using DataFrame\"\"\"\n",
        "        print(\"Extracting texts and true labels...\")\n",
        "        texts = df[text_column].tolist()\n",
        "        y_true = self.get_true_labels_from_df(df)\n",
        "\n",
        "        print(\"Getting prediction probabilities...\")\n",
        "        y_probs = self.get_predictions_proba(texts)\n",
        "\n",
        "        print(f\"True labels shape: {y_true.shape}\")\n",
        "        print(f\"Predicted probabilities shape: {y_probs.shape}\")\n",
        "\n",
        "        print(\"\\nOptimizing thresholds...\")\n",
        "        self.best_thresholds = self.optimize_thresholds_per_class(y_true, y_probs)\n",
        "\n",
        "        # Evaluate with optimized thresholds\n",
        "        self.best_metrics, y_pred = self.evaluate_thresholds(y_true, y_probs, self.best_thresholds)\n",
        "\n",
        "        # Compare with default threshold\n",
        "        default_metrics, _ = self.evaluate_thresholds(y_true, y_probs, 0.5)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"THRESHOLD TUNING RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"\\nOptimal thresholds:\")\n",
        "        for label, threshold in zip(self.label_cols, self.best_thresholds):\n",
        "            print(f\"  {label}: {threshold:.3f}\")\n",
        "\n",
        "        print(\"\\nPerformance comparison:\")\n",
        "        print(f\"{'Metric':<20} {'Default (0.5)':<12} {'Optimized':<12} {'Improvement':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "        for metric in ['f1_weighted', 'f1_macro', 'f1_micro']:\n",
        "            improvement = self.best_metrics[metric] - default_metrics[metric]\n",
        "            print(f\"{metric:<20} {default_metrics[metric]:<12.4f} {self.best_metrics[metric]:<12.4f} {improvement:+.4f}\")\n",
        "\n",
        "        print(\"\\nClass-wise F1 scores:\")\n",
        "        for label in self.label_cols:\n",
        "            default_f1 = default_metrics[f'{label}_f1']\n",
        "            optimized_f1 = self.best_metrics[f'{label}_f1']\n",
        "            improvement = optimized_f1 - default_f1\n",
        "            print(f\"  {label:<15} Default: {default_f1:.3f}, Optimized: {optimized_f1:.3f}, Œî: {improvement:+.3f}\")\n",
        "\n",
        "        return self.best_thresholds, self.best_metrics, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "nlUQRtlFgXUS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlUQRtlFgXUS",
        "outputId": "c3ffa99c-c074-4e71-ae42-25498be5439a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Getting predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 117/117 [00:21<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation predictions shape: (1867, 4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "texts_val = val_df['clean_text'].tolist()\n",
        "y_true_val = val_df[label_cols].values  # shape: (num_samples, num_labels)\n",
        "y_probs_val = safe_get_predictions_proba(model, tokenizer, texts_val, batch_size=16, device='cuda')\n",
        "print(\"Validation predictions shape:\", y_probs_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "ZR6EkSI9gjmc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR6EkSI9gjmc",
        "outputId": "5bb3be81-a76b-4124-fec4-6682696c260f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_ad: Optimal threshold = 0.627, Max F1 = 0.582\n",
            "is_relevant: Optimal threshold = 0.001, Max F1 = 0.981\n",
            "is_rant: Optimal threshold = 0.232, Max F1 = 0.618\n",
            "is_legit: Optimal threshold = 0.080, Max F1 = 0.940\n"
          ]
        }
      ],
      "source": [
        "tuner = MultilabelThresholdTuner(model, tokenizer, label_cols, device='cuda')\n",
        "tuner.best_thresholds = tuner.optimize_thresholds_per_class(y_true_val, y_probs_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "jxSrH3UFgpLY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxSrH3UFgpLY",
        "outputId": "9a1297cb-81a4-4bf9-b061-0c3599e31622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1 Weighted Improvement over default 0.5 threshold: 0.02246704466831384\n"
          ]
        }
      ],
      "source": [
        "best_metrics, y_pred_optimized = tuner.evaluate_thresholds(y_true_val, y_probs_val, tuner.best_thresholds)\n",
        "default_metrics, _ = tuner.evaluate_thresholds(y_true_val, y_probs_val, 0.5)\n",
        "\n",
        "print(\"\\nF1 Weighted Improvement over default 0.5 threshold:\",\n",
        "      best_metrics['f1_weighted'] - default_metrics['f1_weighted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "t9pEbzCXgtw8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9pEbzCXgtw8",
        "outputId": "54cba344-ca0f-4f61-c638-eea2ff3a58b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_ad: Default F1 = 0.556, Optimized F1 = 0.582\n",
            "is_relevant: Default F1 = 0.951, Optimized F1 = 0.981\n",
            "is_rant: Default F1 = 0.605, Optimized F1 = 0.618\n",
            "is_legit: Default F1 = 0.926, Optimized F1 = 0.940\n"
          ]
        }
      ],
      "source": [
        "for label in label_cols:\n",
        "    default_f1 = default_metrics[f'{label}_f1']\n",
        "    optimized_f1 = best_metrics[f'{label}_f1']\n",
        "    print(f\"{label}: Default F1 = {default_f1:.3f}, Optimized F1 = {optimized_f1:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "5taSiKJ3gyRB",
      "metadata": {
        "id": "5taSiKJ3gyRB"
      },
      "outputs": [],
      "source": [
        "y_pred_final = (y_probs_val >= tuner.best_thresholds).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "JC2YRQM9g7Ih",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JC2YRQM9g7Ih",
        "outputId": "eac7d14b-26f2-400e-ef38-53195e1789f8"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7e51e8f8-df15-4294-ba13-e943f018f5f9\", \"multilabel_thresholds.json\", 132)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized thresholds saved to multilabel_thresholds.json\n"
          ]
        }
      ],
      "source": [
        "thresholds_to_save = dict(zip(label_cols, tuner.best_thresholds))\n",
        "with open(\"multilabel_thresholds.json\", \"w\") as f:\n",
        "    json.dump(thresholds_to_save, f)\n",
        "files.download(\"multilabel_thresholds.json\")\n",
        "\n",
        "print(\"Optimized thresholds saved to multilabel_thresholds.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cKH75BoK9LXv",
      "metadata": {
        "id": "cKH75BoK9LXv"
      },
      "source": [
        "### 6. Import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3imWQ0hcRL",
      "metadata": {
        "id": "2e3imWQ0hcRL"
      },
      "outputs": [],
      "source": [
        "# Load model & tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./qwen_gemma_multilabel_final\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./qwen_gemma_multilabel_final\")\n",
        "\n",
        "# Load thresholds\n",
        "with open(\"multilabel_thresholds.json\", \"r\") as f:\n",
        "    thresholds = json.load(f)\n",
        "\n",
        "# Safe prediction function\n",
        "def predict_labels(texts, model, tokenizer, thresholds, batch_size=16, device='cuda'):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            inputs = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt').to(device)\n",
        "            logits = model(**inputs).logits\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    all_probs = np.array(all_probs)\n",
        "    y_pred = (all_probs >= np.array(list(thresholds.values()))).astype(int)\n",
        "    return y_pred"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4b426534",
        "bfb37d5d",
        "03ff6b75"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "011f304769ae45789d785e0fc145636c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44ea94ba52b341ac81a608443ffc5870",
              "IPY_MODEL_43d4b9a27f37469b85529ea37daee34e",
              "IPY_MODEL_6a7f43d67fc04c3aa1e360060f41ec54"
            ],
            "layout": "IPY_MODEL_9ec3cf0871264cdaac74e238bba4a105"
          }
        },
        "0ebe217df7ff43ba908a9abedf6f7d69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155f66caaaa14951aa0924df75566fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18074f850e43488dbc0a36a97ad37097": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9cdaab9cff5401d8357203f7b5a68f0",
            "max": 8180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6fe934bea164bbe8d51e69504a39765",
            "value": 8180
          }
        },
        "380b10ca3de14e8e9ad8ee880cbf45d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3919752d4d4044ebbebf4f10d8e81188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61da288494334b2cb1c25acdc125ff2e",
              "IPY_MODEL_18074f850e43488dbc0a36a97ad37097",
              "IPY_MODEL_f0dbba45e7da4fb2b93984db6b20b133"
            ],
            "layout": "IPY_MODEL_0ebe217df7ff43ba908a9abedf6f7d69"
          }
        },
        "3aba02f93ebe4e7fb21914dbe5c87999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d4b9a27f37469b85529ea37daee34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a2f6e7b66e145e6a3a3f26d15a0ad6c",
            "max": 1867,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffac5a1a925947148c1d690c19d1766b",
            "value": 1867
          }
        },
        "44ea94ba52b341ac81a608443ffc5870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380b10ca3de14e8e9ad8ee880cbf45d4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_155f66caaaa14951aa0924df75566fca",
            "value": "Map:‚Äá100%"
          }
        },
        "4c71ddb5e7a543e992ffe572fc579f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61da288494334b2cb1c25acdc125ff2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9376cfb19614b679dc133cd7029fa7a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4c71ddb5e7a543e992ffe572fc579f44",
            "value": "Map:‚Äá100%"
          }
        },
        "6a2f6e7b66e145e6a3a3f26d15a0ad6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7f43d67fc04c3aa1e360060f41ec54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aba02f93ebe4e7fb21914dbe5c87999",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a8e14f50e933472497819d05ec3924d9",
            "value": "‚Äá1867/1867‚Äá[00:00&lt;00:00,‚Äá3266.21‚Äáexamples/s]"
          }
        },
        "9ec3cf0871264cdaac74e238bba4a105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e14f50e933472497819d05ec3924d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9cdaab9cff5401d8357203f7b5a68f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9dfb59e21d54df1aa609752ee4b4170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6fe934bea164bbe8d51e69504a39765": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9376cfb19614b679dc133cd7029fa7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3903458f2f64da682fd28bc7eb20768": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dbba45e7da4fb2b93984db6b20b133": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3903458f2f64da682fd28bc7eb20768",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9dfb59e21d54df1aa609752ee4b4170",
            "value": "‚Äá8180/8180‚Äá[00:02&lt;00:00,‚Äá2990.24‚Äáexamples/s]"
          }
        },
        "ffac5a1a925947148c1d690c19d1766b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
