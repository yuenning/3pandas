{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7068df39",
   "metadata": {},
   "source": [
    "# Multi-Label Neural Network Classifier for Reviews\n",
    "\n",
    "We trained a multi-label neural network to predict whether a review is:\n",
    "\n",
    "* is_ad (advertisement)\n",
    "\n",
    "* is_relevant (relevant content)\n",
    "\n",
    "* is_rant (rant/complaint)\n",
    "\n",
    "using text embeddings, category embeddings, sentiment scores, and tabular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8836607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "# Import your API key from config\n",
    "from config.config import OPENAI_API_KEY\n",
    "\n",
    "from typing import List, Tuple, Iterable, Union\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4bb74",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "Embeddings Generation:\n",
    "\n",
    "* Used Qwen3-0.8B to generate dense vector embeddings for both:\n",
    "\n",
    "* `category` (stored in categories_embeddings_all.parquet)\n",
    "\n",
    "* `review_text` (stored in review_text_embeddings_all.parquet)\n",
    "\n",
    "These embeddings capture semantic meaning of reviews and categories for downstream classification.\n",
    "\n",
    "Combined parquet shards into unified datasets:\n",
    "\n",
    "* `categories_embeddings_all.parquet`\n",
    "\n",
    "* `review_text_embeddings_all.parquet`\n",
    "\n",
    "* `review_sentiment_scores_all.parquet`\n",
    "\n",
    "Merged these with `all_reviews_with_labels_and_features.parquet` on `review_id`.\n",
    "\n",
    "Features used:\n",
    "\n",
    "* Tabular: `rating`, `has_photo`, `category`, `average_score`, `average_rating`, `rating_discrepancy`, `sentiment_score`\n",
    "\n",
    "* Embeddings: `category` + `review_text`\n",
    "\n",
    "* Standardized numeric features (but not embeddings).\n",
    "\n",
    "Sentiment Score Generation (ChatGPT):\n",
    "\n",
    "* Used gpt-4o-mini to assign a numeric sentiment score in the range [-1.0, 1.0].\n",
    "\n",
    "* Prompted the model with review text, enforcing strict JSON-only output (e.g., {\"sentiment_score\": -0.42})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_labeled_df = pd.read_csv('all_reviews_with_labels_normalised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49292ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>has_photo</th>\n",
       "      <th>author_name</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>business_name</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>review_id</th>\n",
       "      <th>comprehensive_review</th>\n",
       "      <th>is_ad</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>is_rant</th>\n",
       "      <th>is_legit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love the convenience of this neighborhood carw...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Doug Schmidt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Auto Spa Speedy Wash - Harvester, MO</td>\n",
       "      <td>['Car wash']</td>\n",
       "      <td>google</td>\n",
       "      <td>1001</td>\n",
       "      <td>[Business] Auto Spa Speedy Wash - Harvester, M...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 bathrooms (for a large 2 story building), 1 ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Duf Duftopia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kmart</td>\n",
       "      <td>['Discount store', 'Appliance store', 'Baby st...</td>\n",
       "      <td>google</td>\n",
       "      <td>1002</td>\n",
       "      <td>[Business] Kmart | [Category] ['Discount store...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My favorite pizza shop hands down!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Andrew Phillips</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Papa’s Pizza</td>\n",
       "      <td>['Pizza restaurant', 'Chicken wings restaurant...</td>\n",
       "      <td>google</td>\n",
       "      <td>1003</td>\n",
       "      <td>[Business] Papa’s Pizza | [Category] ['Pizza r...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Julie Heiland</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Music Place</td>\n",
       "      <td>['Musical instrument store']</td>\n",
       "      <td>google</td>\n",
       "      <td>1004</td>\n",
       "      <td>[Business] The Music Place | [Category] ['Musi...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very unprofessional!!!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Alan Khasanov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Park Motor Cars Inc</td>\n",
       "      <td>['Used car dealer']</td>\n",
       "      <td>google</td>\n",
       "      <td>1005</td>\n",
       "      <td>[Business] Park Motor Cars Inc | [Category] ['...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating  has_photo  \\\n",
       "0  Love the convenience of this neighborhood carw...     4.0      False   \n",
       "1  2 bathrooms (for a large 2 story building), 1 ...     2.0      False   \n",
       "2                 My favorite pizza shop hands down!     5.0      False   \n",
       "3  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...     1.0      False   \n",
       "4                           Very unprofessional!!!!!     1.0      False   \n",
       "\n",
       "       author_name  user_review_count                         business_name  \\\n",
       "0     Doug Schmidt                1.0  Auto Spa Speedy Wash - Harvester, MO   \n",
       "1     Duf Duftopia                1.0                                 Kmart   \n",
       "2  Andrew Phillips                1.0                          Papa’s Pizza   \n",
       "3    Julie Heiland                1.0                       The Music Place   \n",
       "4    Alan Khasanov                1.0                   Park Motor Cars Inc   \n",
       "\n",
       "                                            category  source  review_id  \\\n",
       "0                                       ['Car wash']  google       1001   \n",
       "1  ['Discount store', 'Appliance store', 'Baby st...  google       1002   \n",
       "2  ['Pizza restaurant', 'Chicken wings restaurant...  google       1003   \n",
       "3                       ['Musical instrument store']  google       1004   \n",
       "4                                ['Used car dealer']  google       1005   \n",
       "\n",
       "                                comprehensive_review  is_ad  is_relevant  \\\n",
       "0  [Business] Auto Spa Speedy Wash - Harvester, M...  False         True   \n",
       "1  [Business] Kmart | [Category] ['Discount store...   True         True   \n",
       "2  [Business] Papa’s Pizza | [Category] ['Pizza r...  False         True   \n",
       "3  [Business] The Music Place | [Category] ['Musi...  False         True   \n",
       "4  [Business] Park Motor Cars Inc | [Category] ['...  False         True   \n",
       "\n",
       "   is_rant  is_legit  \n",
       "0    False      True  \n",
       "1     True     False  \n",
       "2    False      True  \n",
       "3     True     False  \n",
       "4     True     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reviews_labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8006277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of reviews tagged as advertisements: 391\n",
      "No. of reviews tagged as irrelevant: 429\n",
      "No. of reviews tagged as rants: 916\n",
      "No. of flagged reviews: 1713\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of reviews tagged as advertisements:\", len(all_reviews_labeled_df[all_reviews_labeled_df['is_ad'] == True]))\n",
    "print(\"No. of reviews tagged as irrelevant:\", len(all_reviews_labeled_df[all_reviews_labeled_df['is_relevant'] == False]))\n",
    "print(\"No. of reviews tagged as rants:\", len(all_reviews_labeled_df[all_reviews_labeled_df['is_rant'] == True]))\n",
    "print(\"No. of flagged reviews:\", len(all_reviews_labeled_df[all_reviews_labeled_df['is_legit'] == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Business] Auto Spa Speedy Wash - Harvester, MO | [Category] ['Car wash'] | [Rating] 4.0 | [Author] Doug Schmidt | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] Love the convenience of this neighborhood carwash.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reviews_labeled_df['comprehensive_review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4646b8",
   "metadata": {},
   "source": [
    "### Embedding `review_text` and `categories`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60d4e2",
   "metadata": {},
   "source": [
    "We choose to embed `review_text` instead of `comprehensive_review` because `comprehensive_review` contains other fields from the dataset e.g. `categories`, `has_photo` etc. which might result in autocorrelation when we use these embeddings as predictors together with the other predictors. Embedding `review_text` by itself will ensure that we use pure semantic signals from the review as predictors, before combining them with the other predictors of the dataset. \n",
    "\n",
    "Given that many categories are sparse categories e.g. ['Discount store', 'Appliance store', 'Baby store', 'Bedding store', 'Clothing store', 'Department store', 'Electronics store', 'Home goods store', 'Shoe store', 'Toy store'] and others are hierarchical e.g. ['Bakery', 'Breakfast restaurant'], we want the model to be able to learn semantics between similar categories instead of as sprase binary predictors. Hence, we choose to embed `categories` as well, and use them as predictors for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7746f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map=\"auto\" if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db100e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (embed_tokens): Embedding(151669, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x Qwen3DecoderLayer(\n",
       "      (self_attn): Qwen3Attention(\n",
       "        (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "      )\n",
       "      (mlp): Qwen3MLP(\n",
       "        (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "  (rotary_emb): Qwen3RotaryEmbedding()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using Qwen3-0.6B for embeddings for higher dimensionality\n",
    "MODEL_ID = \"Qwen/Qwen3-Embedding-0.6B\"  # tiny, fast\n",
    "MAX_LEN  = 256\n",
    "BATCH    = 64                            # 0.6B can handle larger batches\n",
    "SAVE_DIR = \"./qwen3_embed_cache\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ---- load tokenizer/model on GPU if available ----\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    major_cc = torch.cuda.get_device_capability()[0]\n",
    "    dtype = torch.bfloat16 if major_cc >= 8 else torch.float16\n",
    "    device_map = \"auto\"\n",
    "else:\n",
    "    dtype = torch.float32\n",
    "    device_map = None\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device_map,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b196ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def _mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)        # [B,T,1]\n",
    "    summed = (last_hidden_state * mask).sum(dim=1)                         # [B,H]\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-6)                               # [B,1]\n",
    "    return summed / counts\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_texts(texts, max_len=MAX_LEN, batch_size=BATCH, normalize=True) -> np.ndarray:\n",
    "    \"\"\"Return np.ndarray [N, H] float32 (L2-normalized if normalize=True).\"\"\"\n",
    "    embs = []\n",
    "    N = len(texts)\n",
    "    for i in trange(0, N, batch_size, desc=\"Embedding (Qwen3-Emb-0.6B)\"):\n",
    "        batch = [t if isinstance(t, str) and t.strip() else \"\" for t in texts[i:i+batch_size]]\n",
    "        enc = tokenizer(batch, truncation=True, max_length=max_len, padding=True, return_tensors=\"pt\")\n",
    "        if torch.cuda.is_available():\n",
    "            enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "        out = model(**enc)\n",
    "        pooled = _mean_pool(out.last_hidden_state, enc[\"attention_mask\"])  # [B,H]\n",
    "        pooled = pooled.float().cpu().numpy()\n",
    "        if normalize:\n",
    "            norms = np.linalg.norm(pooled, axis=1, keepdims=True) + 1e-12\n",
    "            pooled = pooled / norms\n",
    "        embs.append(pooled)\n",
    "    return np.vstack(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoke_test(df, n=256):\n",
    "    n = min(n, len(df))\n",
    "    sample = df[\"review_text\"].fillna(\"\").iloc[:n].tolist()\n",
    "    embs = embed_texts(sample, max_len=MAX_LEN, batch_size=BATCH, normalize=True)\n",
    "    print(\"Smoke test OK — embeddings shape:\", embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd93fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 4/4 [03:47<00:00, 56.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke test OK — embeddings shape: (256, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "smoke_test(all_reviews_labeled_df, n=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b79985",
   "metadata": {},
   "source": [
    "We decided to use `Qwen3-Embedding-0.6B` for embedding after experimenting with `miniLM-L12-v2` and `Qwen-3-8B` because we wanted to balance high dimensionality of embeddings with a computationally efficient embedding process. `miniLM-L12-v2` produces embeddings with low dimensionality (384), while `Qwen-3-8B` produces high dimensionality (4096) but is computationally inefficient due to the high number of parameters. Hence, we decided on a light-weight model, `Qwen-3-Embedding-0.6B`, to improve efficiency and achieve higher dimensionality of 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd243838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def embed_review_texts_batch(\n",
    "    df: pd.DataFrame,\n",
    "    out_parquet_path: str,\n",
    "    batch_idx: int,\n",
    "    chunk_rows: int = 2000,\n",
    "    max_len: int = MAX_LEN,\n",
    "    batch_size: int = BATCH,\n",
    "    normalize: bool = True,\n",
    "    store_dtype: str = \"float32\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Embed ONE batch of reviews and append results to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame with 'review_id' and 'review_text'\n",
    "        out_parquet_path : Path to Parquet file\n",
    "        batch_idx : Which batch index to embed (0-based)\n",
    "        chunk_rows : How many rows per batch\n",
    "    \"\"\"\n",
    "    assert \"review_id\" in df.columns and \"review_text\" in df.columns, \\\n",
    "        \"DataFrame must have 'review_id' and 'review_text' columns.\"\n",
    "\n",
    "    N = len(df)\n",
    "    start = batch_idx * chunk_rows\n",
    "    end = min(start + chunk_rows, N)\n",
    "    if start >= N:\n",
    "        raise IndexError(f\"Batch {batch_idx} out of range. Max = {(N-1)//chunk_rows}\")\n",
    "\n",
    "    # Slice IN ORDER\n",
    "    sl = df.iloc[start:end]\n",
    "    texts = sl[\"review_text\"].fillna(\"\").tolist()\n",
    "    ids   = sl[\"review_id\"].tolist()\n",
    "\n",
    "    # Embed\n",
    "    embs = embed_texts(texts, max_len=max_len, batch_size=batch_size, normalize=normalize)\n",
    "    embs = embs.astype(np.float32) if store_dtype == \"float32\" else embs.astype(np.float16)\n",
    "\n",
    "    # Build DataFrame\n",
    "    chunk_df = pd.DataFrame({\n",
    "        \"review_id\": ids,\n",
    "        \"review_text_embeddings\": [row.tolist() for row in embs]\n",
    "    })\n",
    "\n",
    "    # Append to Parquet\n",
    "    if not os.path.exists(out_parquet_path):\n",
    "        # Write new file\n",
    "        chunk_df.to_parquet(out_parquet_path, engine=\"pyarrow\", index=False, compression=\"zstd\")\n",
    "    else:\n",
    "        # Append\n",
    "        existing = pq.read_table(out_parquet_path).to_pandas()\n",
    "        combined = pd.concat([existing, chunk_df], ignore_index=True)\n",
    "        combined.to_parquet(out_parquet_path, engine=\"pyarrow\", index=False, compression=\"zstd\")\n",
    "\n",
    "    print(f\"✅ Batch {batch_idx} [{start}:{end}] saved to {out_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb54098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 32/32 [28:04<00:00, 52.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 0 [0:2000] saved to ./review_text_embeddings_0.parquet\n"
     ]
    }
   ],
   "source": [
    "# Total number of batches\n",
    "num_batches = math.ceil(len(all_reviews_labeled_df) / 2000)\n",
    "\n",
    "# Run batch 0\n",
    "embed_review_texts_batch(all_reviews_labeled_df, \"./review_text_embeddings_0.parquet\", batch_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725c97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 32/32 [26:52<00:00, 50.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 1 [2000:4000] saved to ./review_text_embeddings.parquet\n"
     ]
    }
   ],
   "source": [
    "embed_review_texts_batch(all_reviews_labeled_df, \"./review_text_embeddings_1.parquet\", batch_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328635bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 32/32 [2:21:33<00:00, 265.42s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 2 [4000:6000] saved to ./review_text_embeddings_2.parquet\n"
     ]
    }
   ],
   "source": [
    "embed_review_texts_batch(all_reviews_labeled_df, \"./review_text_embeddings_2.parquet\", batch_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ead0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN  = 256\n",
    "BATCH    = 64\n",
    "\n",
    "def embed_categories_batch(\n",
    "    df: pd.DataFrame,\n",
    "    out_parquet_path: str,\n",
    "    batch_idx: int,\n",
    "    chunk_rows: int = 2000,\n",
    "    max_len: int = MAX_LEN,\n",
    "    batch_size: int = BATCH,\n",
    "    normalize: bool = True,\n",
    "    store_dtype: str = \"float32\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Embed ONE batch of category lists and save to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame with 'review_id' and 'categories' (list[str])\n",
    "        out_parquet_path : Path to Parquet file\n",
    "        batch_idx : Which batch index to embed (0-based)\n",
    "        chunk_rows : Number of rows per batch\n",
    "    \"\"\"\n",
    "    assert \"review_id\" in df.columns and \"category\" in df.columns, \\\n",
    "        \"DataFrame must have 'review_id' and 'category' columns.\"\n",
    "\n",
    "    N = len(df)\n",
    "    start = batch_idx * chunk_rows\n",
    "    end = min(start + chunk_rows, N)\n",
    "    if start >= N:\n",
    "        raise IndexError(f\"Batch {batch_idx} out of range. Max = {(N-1)//chunk_rows}\")\n",
    "\n",
    "    # Slice in order\n",
    "    sl = df.iloc[start:end]\n",
    "    cat_texts = sl[\"category\"].apply(lambda x: \", \".join(x) if isinstance(x, (list, tuple)) else str(x)).tolist()\n",
    "    ids = sl[\"review_id\"].tolist()\n",
    "\n",
    "    # Embed category text\n",
    "    embs = embed_texts(cat_texts, max_len=max_len, batch_size=batch_size, normalize=normalize)\n",
    "    embs = embs.astype(np.float32) if store_dtype == \"float32\" else embs.astype(np.float16)\n",
    "\n",
    "    # Build DataFrame\n",
    "    chunk_df = pd.DataFrame({\n",
    "        \"review_id\": ids,\n",
    "        \"categories_embeddings\": [row.tolist() for row in embs]\n",
    "    })\n",
    "\n",
    "    # Append or write new Parquet\n",
    "    if not os.path.exists(out_parquet_path):\n",
    "        chunk_df.to_parquet(out_parquet_path, engine=\"pyarrow\", index=False, compression=\"zstd\")\n",
    "    else:\n",
    "        existing = pq.read_table(out_parquet_path).to_pandas()\n",
    "        combined = pd.concat([existing, chunk_df], ignore_index=True)\n",
    "        combined.to_parquet(out_parquet_path, engine=\"pyarrow\", index=False, compression=\"zstd\")\n",
    "\n",
    "    print(f\"✅ Categories batch {batch_idx} [{start}:{end}] saved to {out_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75226b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 32/32 [05:02<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categories batch 0 [0:2000] saved to ./categories_embeddings_0.parquet\n"
     ]
    }
   ],
   "source": [
    "embed_categories_batch(\n",
    "    all_reviews_labeled_df,\n",
    "    out_parquet_path=\"./categories_embeddings_0.parquet\",\n",
    "    batch_idx=0,\n",
    "    chunk_rows=2000,\n",
    "    max_len=MAX_LEN,\n",
    "    batch_size=BATCH,\n",
    "    normalize=True,\n",
    "    store_dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd60b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 32/32 [07:15<00:00, 13.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categories batch 3 [6000:8000] saved to ./categories_embeddings_3.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 32/32 [03:54<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categories batch 4 [8000:10000] saved to ./categories_embeddings_4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (Qwen3-Emb-0.6B): 100%|██████████| 30/30 [00:48<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categories batch 5 [10000:11920] saved to ./categories_embeddings_5.parquet\n"
     ]
    }
   ],
   "source": [
    "# Batch 1\n",
    "# embed_categories_batch(\n",
    "#     all_reviews_labeled_df,\n",
    "#     out_parquet_path=\"./categories_embeddings_1.parquet\",\n",
    "#     batch_idx=1,\n",
    "#     chunk_rows=2000,\n",
    "#     max_len=MAX_LEN,\n",
    "#     batch_size=BATCH,\n",
    "#     normalize=True,\n",
    "#     store_dtype=\"float32\"\n",
    "# )\n",
    "\n",
    "# # Batch 2\n",
    "# embed_categories_batch(\n",
    "#     all_reviews_labeled_df,\n",
    "#     out_parquet_path=\"./categories_embeddings_2.parquet\",\n",
    "#     batch_idx=2,\n",
    "#     chunk_rows=2000,\n",
    "#     max_len=MAX_LEN,\n",
    "#     batch_size=BATCH,\n",
    "#     normalize=True,\n",
    "#     store_dtype=\"float32\"\n",
    "# )\n",
    "\n",
    "# Batch 3\n",
    "embed_categories_batch(\n",
    "    all_reviews_labeled_df,\n",
    "    out_parquet_path=\"./categories_embeddings_3.parquet\",\n",
    "    batch_idx=3,\n",
    "    chunk_rows=2000,\n",
    "    max_len=MAX_LEN,\n",
    "    batch_size=BATCH,\n",
    "    normalize=True,\n",
    "    store_dtype=\"float32\"\n",
    ")\n",
    "\n",
    "# Batch 4\n",
    "embed_categories_batch(\n",
    "    all_reviews_labeled_df,\n",
    "    out_parquet_path=\"./categories_embeddings_4.parquet\",\n",
    "    batch_idx=4,\n",
    "    chunk_rows=2000,\n",
    "    max_len=MAX_LEN,\n",
    "    batch_size=BATCH,\n",
    "    normalize=True,\n",
    "    store_dtype=\"float32\"\n",
    ")\n",
    "\n",
    "# Batch 5\n",
    "embed_categories_batch(\n",
    "    all_reviews_labeled_df,\n",
    "    out_parquet_path=\"./categories_embeddings_5.parquet\",\n",
    "    batch_idx=5,\n",
    "    chunk_rows=2000,\n",
    "    max_len=MAX_LEN,\n",
    "    batch_size=BATCH,\n",
    "    normalize=True,\n",
    "    store_dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f07516",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_labeled_df = pd.read_csv('all_reviews_with_labels_normalised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc60436",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ed979",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "SENTIMENT_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are a strict sentiment rater for short customer reviews.\n",
    "\n",
    "TASK:\n",
    "- Read the review text.\n",
    "- Output a single numeric sentiment score in the range [-1.0, 1.0]:\n",
    "  -1.0 = extremely negative\n",
    "   0.0 = neutral/mixed/unclear\n",
    "  +1.0 = extremely positive\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY compact JSON with a single key 'sentiment_score'.\n",
    "- No markdown, no extra text, no explanations.\n",
    "- Example valid output: {{\"sentiment_score\": -0.42}}\n",
    "\n",
    "REVIEW:\n",
    "{review_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "def classify_sentiment(review_text: str) -> dict:\n",
    "    \"\"\"Return {\"sentiment_score\": float in [-1,1]} with JSON-only response.\"\"\"\n",
    "    if not isinstance(review_text, str) or len(review_text.strip()) == 0:\n",
    "        return {\"sentiment_score\": 0.0}\n",
    "\n",
    "    prompt = SENTIMENT_PROMPT_TEMPLATE.format(review_text=review_text.strip())\n",
    "\n",
    "    # basic retry with exponential backoff\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            content = resp.choices[0].message.content\n",
    "            data = json.loads(content)\n",
    "\n",
    "            # validate / clamp\n",
    "            score = float(data.get(\"sentiment_score\", 0.0))\n",
    "            score = max(-1.0, min(1.0, score))\n",
    "            return {\"sentiment_score\": score}\n",
    "\n",
    "        except Exception as e:\n",
    "            # backoff\n",
    "            sleep_s = 2 ** attempt\n",
    "            time.sleep(sleep_s)\n",
    "            last_err = e\n",
    "\n",
    "    # fallback on persistent failure\n",
    "    return {\"sentiment_score\": 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0302fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_sentiment_batch(\n",
    "    df: pd.DataFrame,\n",
    "    batch_idx: int,\n",
    "    text_col: str = \"review_text\",\n",
    "    id_col: str = \"review_id\",\n",
    "    out_prefix: str = \"review_sentiment_scores\",\n",
    "    chunk_size: int = 2000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run GPT sentiment analysis for ONE batch only (batch_idx).\n",
    "    Saves results to: {out_prefix}_{batch_idx}.parquet\n",
    "\n",
    "    Each file has two columns: review_id, sentiment_score\n",
    "    \"\"\"\n",
    "    assert id_col in df.columns and text_col in df.columns, \"Missing required columns.\"\n",
    "\n",
    "    N = len(df)\n",
    "    start = batch_idx * chunk_size\n",
    "    end = min(start + chunk_size, N)\n",
    "\n",
    "    if start >= N:\n",
    "        raise IndexError(f\"Batch {batch_idx} out of range. Max batch index = {(N-1)//chunk_size}\")\n",
    "\n",
    "    sub = df.iloc[start:end]\n",
    "    ids = sub[id_col].tolist()\n",
    "    texts = sub[text_col].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    rows = []\n",
    "    for i in tqdm(range(len(texts)), desc=f\"Batch {batch_idx} (reviews)\"):\n",
    "        result = classify_sentiment(texts[i])  # your GPT call\n",
    "        rows.append((ids[i], result[\"sentiment_score\"]))\n",
    "\n",
    "    out_df = pd.DataFrame(rows, columns=[id_col, \"sentiment_score\"])\n",
    "    out_path = f\"{out_prefix}_{batch_idx}.parquet\"\n",
    "    out_df.to_parquet(out_path, index=False)\n",
    "    print(f\"✅ Saved batch {batch_idx} [{start}:{end}] → {out_path}\")\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52dc7fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 0 (reviews): 100%|██████████| 2000/2000 [24:41<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batch 0 [0:2000] → review_sentiment_scores_0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>-0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2996</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2997</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2998</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2999</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_id  sentiment_score\n",
       "0          1001             0.80\n",
       "1          1002            -0.85\n",
       "2          1003             1.00\n",
       "3          1004            -1.00\n",
       "4          1005            -1.00\n",
       "...         ...              ...\n",
       "1995       2996             0.80\n",
       "1996       2997             0.90\n",
       "1997       2998             0.60\n",
       "1998       2999             1.00\n",
       "1999       3000             0.80\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_sentiment_batch(all_reviews_labeled_df, batch_idx=0, text_col=\"review_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa87e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1 (reviews): 100%|██████████| 2000/2000 [25:11<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batch 1 [2000:4000] → review_sentiment_scores_1.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2 (reviews): 100%|██████████| 2000/2000 [22:28<00:00,  1.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batch 2 [4000:6000] → review_sentiment_scores_2.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3 (reviews): 100%|██████████| 2000/2000 [23:14<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batch 3 [6000:8000] → review_sentiment_scores_3.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4 (reviews): 100%|██████████| 2000/2000 [22:42<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batch 4 [8000:10000] → review_sentiment_scores_4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5 (reviews): 100%|██████████| 1920/1920 [3:24:49<00:00,  6.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batch 5 [10000:11920] → review_sentiment_scores_5.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17458</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17459</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17461</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17463</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17464</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>20600</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>20601</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>20609</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>20610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>20614</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_id  sentiment_score\n",
       "0         17458              0.9\n",
       "1         17459              0.9\n",
       "2         17461              1.0\n",
       "3         17463              0.9\n",
       "4         17464              1.0\n",
       "...         ...              ...\n",
       "1915      20600             -0.5\n",
       "1916      20601              0.8\n",
       "1917      20609              0.0\n",
       "1918      20610              0.0\n",
       "1919      20614              0.5\n",
       "\n",
       "[1920 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Batch 1\n",
    "# gpt_sentiment_batch(all_reviews_labeled_df, batch_idx=1, text_col=\"review_text\")\n",
    "\n",
    "# # Batch 2\n",
    "# gpt_sentiment_batch(all_reviews_labeled_df, batch_idx=2, text_col=\"review_text\")\n",
    "\n",
    "# # Batch 3\n",
    "# gpt_sentiment_batch(all_reviews_labeled_df, batch_idx=3, text_col=\"review_text\")\n",
    "\n",
    "# # Batch 4\n",
    "# gpt_sentiment_batch(all_reviews_labeled_df, batch_idx=4, text_col=\"review_text\")\n",
    "\n",
    "# # Batch 5\n",
    "# gpt_sentiment_batch(all_reviews_labeled_df, batch_idx=5, text_col=\"review_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4156e",
   "metadata": {},
   "source": [
    "### Generating `average_score`, `has_phone`, `has_link` and `has_email` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32036e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute average_score per business\n",
    "business_avg = all_reviews_labeled_df.groupby(\"business_name\")[\"rating\"].mean().rename(\"average_rating\")\n",
    "\n",
    "# Merge into main df\n",
    "all_reviews_labeled_df = all_reviews_labeled_df.merge(business_avg, on=\"business_name\", how=\"left\")\n",
    "\n",
    "# 2. Regex helpers for features\n",
    "def has_phone(text: str) -> int:\n",
    "    # simple phone detection: (123) 456-7890 or 123-456-7890 or +65 1234 5678\n",
    "    return int(bool(re.search(r\"(\\+?\\d{1,3}[\\s-]?)?\\(?\\d{2,4}\\)?[\\s-]?\\d{3,4}[\\s-]?\\d{3,4}\", str(text))))\n",
    "\n",
    "def has_link(text: str) -> int:\n",
    "    return int(bool(re.search(r\"http[s]?://|www\\.\", str(text).lower())))\n",
    "\n",
    "def has_email(text: str) -> int:\n",
    "    return int(bool(re.search(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", str(text))))\n",
    "\n",
    "# 3. Apply to create new columns\n",
    "all_reviews_labeled_df[\"has_phone\"] = all_reviews_labeled_df[\"review_text\"].apply(has_phone)\n",
    "all_reviews_labeled_df[\"has_link\"]  = all_reviews_labeled_df[\"review_text\"].apply(has_link)\n",
    "all_reviews_labeled_df[\"has_email\"] = all_reviews_labeled_df[\"review_text\"].apply(has_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa341678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_phone\n",
       "0    11918\n",
       "1        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reviews_labeled_df[\"has_phone\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_link\n",
       "0    11920\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reviews_labeled_df[\"has_link\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_email\n",
       "0    11920\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reviews_labeled_df[\"has_email\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934a7ef",
   "metadata": {},
   "source": [
    "The `has_phone`, `has_link` and `has_email` features are not useful in predicting the class of the review given that most values do not have phone numbers, links or emails. The little variance will mean that the model will ignore the feature or treat it as noise i.e. the feature will not be helpful in predicting the class of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfcfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_labeled_df[\"rating_discrepancy\"] = abs(all_reviews_labeled_df[\"rating\"] - all_reviews_labeled_df[\"average_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_labeled_df.to_csv(\"all_reviews_with_labels_and_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75172de8",
   "metadata": {},
   "source": [
    "## Combining parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "430f143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: combined/categories_embeddings_all.parquet  | shape=(11920, 2)\n",
      "✅ Saved: combined/review_sentiment_scores_all.parquet  | shape=(11920, 2)\n",
      "✅ Saved: combined/review_text_embeddings_all.parquet  | shape=(11920, 2)\n"
     ]
    }
   ],
   "source": [
    "def combine_parquet_shards(prefix: str, start: int, end: int, id_col: str, out_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine parquet shards like f'{prefix}_{i}.parquet' for i in [start, end],\n",
    "    de-duplicate on `id_col`, sort by `id_col`, and save to `out_path`.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for i in range(start, end + 1):\n",
    "        fp = Path(f\"{prefix}_{i}.parquet\")\n",
    "        if fp.exists():\n",
    "            dfs.append(pd.read_parquet(fp))\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping missing file: {fp}\")\n",
    "\n",
    "    if not dfs:\n",
    "        raise FileNotFoundError(f\"No shards found for prefix '{prefix}' in range [{start}, {end}]\")\n",
    "\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Ensure the id column exists\n",
    "    if id_col not in combined.columns:\n",
    "        raise KeyError(f\"'{id_col}' not found in combined DataFrame columns: {combined.columns.tolist()}\")\n",
    "\n",
    "    # Drop duplicate ids (keep the last occurrence) and sort\n",
    "    combined = (\n",
    "        combined\n",
    "        .drop_duplicates(subset=[id_col], keep=\"last\")\n",
    "        .sort_values(by=id_col)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Save combined file\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined.to_parquet(out_path, index=False)\n",
    "    print(f\"✅ Saved: {out_path}  | shape={combined.shape}\")\n",
    "    return combined\n",
    "\n",
    "\n",
    "# --- Combine category embeddings shards (0..5) ---\n",
    "categories_embeddings_all = combine_parquet_shards(\n",
    "    prefix=\"categories_embeddings\",\n",
    "    start=0,\n",
    "    end=5,\n",
    "    id_col=\"review_id\",\n",
    "    out_path=\"combined/categories_embeddings_all.parquet\",\n",
    ")\n",
    "\n",
    "# --- Combine review sentiment score shards (0..5) ---\n",
    "review_sentiment_scores_all = combine_parquet_shards(\n",
    "    prefix=\"review_sentiment_scores\",\n",
    "    start=0,\n",
    "    end=5,\n",
    "    id_col=\"review_id\",\n",
    "    out_path=\"combined/review_sentiment_scores_all.parquet\",\n",
    ")\n",
    "\n",
    "# --- Combine review text embeddings shards (0..5) ---\n",
    "review_text_embeddings_all = combine_parquet_shards(\n",
    "    prefix=\"review_text_embeddings\",\n",
    "    start=0,\n",
    "    end=5,\n",
    "    id_col=\"review_id\",\n",
    "    out_path=\"combined/review_text_embeddings_all.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a09943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataframe shape: (11920, 21)\n",
      "✅ Saved: combined/all_reviews_with_labels_and_features.parquet\n"
     ]
    }
   ],
   "source": [
    "all_reviews_with_labels_and_features = pd.read_csv(\"all_reviews_with_labels_and_features.csv\")\n",
    "\n",
    "# Load the combined sentiment scores\n",
    "review_sentiment_scores_all = pd.read_parquet(\"combined/review_sentiment_scores_all.parquet\")\n",
    "\n",
    "# Merge on 'review_id'\n",
    "all_with_sentiment = all_reviews_with_labels_and_features.merge(\n",
    "    review_sentiment_scores_all,\n",
    "    on=\"review_id\",\n",
    "    how=\"left\"   # keep all rows from main df, even if sentiment is missing\n",
    ")\n",
    "\n",
    "# Save the enriched dataframe\n",
    "all_with_sentiment.to_parquet(\"combined/all_reviews_with_labels_and_features.parquet\", index=False)\n",
    "\n",
    "print(\"✅ Final dataframe shape:\", all_with_sentiment.shape)\n",
    "print(\"✅ Saved: combined/all_reviews_with_labels_and_features.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ca431",
   "metadata": {},
   "source": [
    "# 2. Model Architecture and Training\n",
    "\n",
    "* Input = embeddings + numeric features\n",
    "\n",
    "* Hidden Layers: Dense(256) → ReLU → Dropout(0.3) → Dense(128) → ReLU\n",
    "\n",
    "* Output Layer: 3 logits (is_ad, is_relevant, is_rant)\n",
    "\n",
    "Loss & optimization:\n",
    "\n",
    "* Focal Loss (multi-label)\n",
    "\n",
    "* Adam optimizer (lr=1e-3) with weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0ce2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Load and prepare dataset\n",
    "# ---------------------------\n",
    "df = pd.read_parquet(\"combined/all_reviews_with_labels_and_features.parquet\")\n",
    "cat_emb = pd.read_parquet(\"combined/categories_embeddings_all.parquet\")\n",
    "text_emb = pd.read_parquet(\"combined/review_text_embeddings_all.parquet\")\n",
    "\n",
    "# Merge embeddings into main df\n",
    "df = df.merge(cat_emb, on=\"review_id\", how=\"left\").merge(text_emb, on=\"review_id\", how=\"left\")\n",
    "\n",
    "# Features to use\n",
    "feature_cols = [\n",
    "    \"rating\", \"has_photo\", \"average_score\", \"average_rating\", \"rating_discrepancy\", \"sentiment_score\"\n",
    "]\n",
    "# Embedding cols\n",
    "embedding_cols = [c for c in df.columns if c.startswith(\"embedding_\")]\n",
    "\n",
    "X = df[feature_cols + embedding_cols].fillna(0).values.astype(np.float32)\n",
    "y = df[[\"is_ad\", \"is_relevant\", \"is_rant\"]].values.astype(np.float32)\n",
    "\n",
    "# Standardize numeric features (not embeddings)\n",
    "scaler = StandardScaler()\n",
    "X[:, :len(feature_cols)] = scaler.fit_transform(X[:, :len(feature_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5c4bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 2) Multi-label stratified split (if available)\n",
    "# -----------------------------------------------\n",
    "def multilabel_train_val_split(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Try iterative multi-label stratification. If the package isn't available\n",
    "    or labels are too sparse, fall back to a plain random split.\n",
    "    \"\"\"\n",
    "    # Check sparsity: we need at least 2 positives AND 2 negatives per label\n",
    "    pos_counts = y.sum(axis=0)\n",
    "    neg_counts = y.shape[0] - pos_counts\n",
    "    ok_per_label = (pos_counts >= 2) & (neg_counts >= 2)\n",
    "\n",
    "    try:\n",
    "        from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "        if ok_per_label.all():\n",
    "            msss = MultilabelStratifiedShuffleSplit(\n",
    "                n_splits=1, test_size=test_size, random_state=random_state\n",
    "            )\n",
    "            train_idx, val_idx = next(msss.split(X, y))\n",
    "            return X[train_idx], X[val_idx], y[train_idx], y[val_idx], True\n",
    "        else:\n",
    "            print(\"⚠️ Some labels too sparse for stratification \"\n",
    "                  f\"(pos={pos_counts.tolist()}, neg={neg_counts.tolist()}). Using random split.\")\n",
    "            raise RuntimeError(\"sparse_labels\")\n",
    "    except Exception:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, shuffle=True\n",
    "        )\n",
    "        return X_train, X_val, y_train, y_val, False\n",
    "\n",
    "X_train, X_val, y_train, y_val, used_strat = multilabel_train_val_split(X, y)\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train).float())\n",
    "val_ds   = TensorDataset(torch.tensor(X_val),   torch.tensor(y_val).float())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7163dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3) Define neural net model\n",
    "# ---------------------------\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, output_dim=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)  # logits\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLPClassifier(input_dim=X.shape[1], hidden_dim=256, output_dim=y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d501c",
   "metadata": {},
   "source": [
    "# 3. Handling Class Imbalance\n",
    "\n",
    "* Computed positive weights for rare labels.\n",
    "\n",
    "* Applied WeightedRandomSampler to oversample minority classes.\n",
    "\n",
    "* Used focal Loss to focus learning on hard/rare cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "418d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4) Handle class imbalance\n",
    "# ---------------------------\n",
    "# Weighted BCE per-output using inverse prevalence on the TRAIN SET\n",
    "pos = y_train.sum(axis=0).astype(np.float32)\n",
    "neg = y_train.shape[0] - pos\n",
    "pos_weight = torch.tensor(neg / (pos + 1e-6), dtype=torch.float32)  # shape [n_labels]\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777fd95",
   "metadata": {},
   "source": [
    "# 4. Threshold Tuning\n",
    "\n",
    "Per-label threshold tuning using validation precision-recall curves. Prevented “over-positive” bias (e.g., is_ad → high recall but low precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d6c4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "\n",
    "def tune_thresholds(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Per-label threshold search maximizing F1 on the validation set.\n",
    "    Returns array of best thresholds per label.\n",
    "    \"\"\"\n",
    "    n_labels = y_true.shape[1]\n",
    "    best = np.zeros(n_labels)\n",
    "    for j in range(n_labels):\n",
    "        prec, rec, thr = precision_recall_curve(y_true[:, j], y_prob[:, j])\n",
    "        # Map PR points to F1; thr length = len(prec)-1; use those\n",
    "        f1s = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "        if len(f1s) == 0:\n",
    "            best[j] = 0.5\n",
    "        else:\n",
    "            best[j] = max(0.05, min(0.95, thr[np.argmax(f1s)]))  # clamp to reasonable range\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6149cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossMultiLabel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-label focal loss with per-label alpha (class balance) and gamma.\n",
    "    y_pred: logits (before sigmoid), y_true: {0,1}\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # torch.tensor shape [n_labels] or None\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce = self.bce(logits, targets)\n",
    "        p = torch.sigmoid(logits)\n",
    "        pt = p*targets + (1-p)*(1-targets)       # p_t\n",
    "        focal = (1-pt).pow(self.gamma) * bce\n",
    "        if self.alpha is not None:\n",
    "            focal = focal * self.alpha  # broadcasts per-label alpha\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal.sum()\n",
    "        return focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "542d0fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.2374 | macroF1@0.5=0.527\n",
      "Epoch 02 | train_loss=0.2151 | macroF1@0.5=0.528\n",
      "Epoch 03 | train_loss=0.2146 | macroF1@0.5=0.524\n",
      "Epoch 04 | train_loss=0.2099 | macroF1@0.5=0.528\n",
      "Epoch 05 | train_loss=0.2088 | macroF1@0.5=0.529\n",
      "Epoch 06 | train_loss=0.2066 | macroF1@0.5=0.524\n",
      "Epoch 07 | train_loss=0.2026 | macroF1@0.5=0.528\n",
      "Epoch 08 | train_loss=0.2016 | macroF1@0.5=0.528\n",
      "Early stopping.\n",
      "Best thresholds per label: [0.27438629 0.58857948 0.52259874]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       is_ad       0.04      0.74      0.07        66\n",
      " is_relevant       0.96      1.00      0.98      2288\n",
      "     is_rant       0.51      0.75      0.61       167\n",
      "\n",
      "   micro avg       0.62      0.98      0.76      2521\n",
      "   macro avg       0.50      0.83      0.55      2521\n",
      "weighted avg       0.91      0.98      0.93      2521\n",
      " samples avg       0.67      0.95      0.76      2521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teomi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 5) Train\n",
    "# ---------------------------\n",
    "# y_train, y_val from your split (0/1 floats)\n",
    "n_labels = y_train.shape[1]\n",
    "\n",
    "# ---- Balanced sampler (sample minority positives more often) ----\n",
    "# weight per sample = mean over labels of (y*pos_w + (1-y)*neg_w)\n",
    "pos_counts = y_train.sum(axis=0)\n",
    "neg_counts = y_train.shape[0] - pos_counts\n",
    "pos_w = (neg_counts / (pos_counts + 1e-6)).astype(np.float32)\n",
    "pos_w = np.clip(pos_w, 1.0, 5.0)   # cap to avoid over-correction\n",
    "neg_w = np.ones_like(pos_w, dtype=np.float32)\n",
    "\n",
    "sample_w = (y_train * pos_w + (1 - y_train) * neg_w).mean(axis=1)\n",
    "sampler = WeightedRandomSampler(weights=torch.tensor(sample_w), num_samples=len(sample_w), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, sampler=sampler)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)\n",
    "\n",
    "# ---- Focal loss with alpha per-label (class balance) ----\n",
    "alpha = torch.tensor(pos_w, dtype=torch.float32)  # larger alpha for rare labels\n",
    "criterion = FocalLossMultiLabel(alpha=alpha, gamma=2.0)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # add L2\n",
    "best_macro_f1, patience, bad = 0.0, 3, 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, 30 + 1):\n",
    "    # train\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item() * xb.size(0)\n",
    "    train_loss = total / len(train_ds)\n",
    "\n",
    "    # validate (use 0.5 thresholds first to guide early stopping)\n",
    "    model.eval()\n",
    "    probs_list, true_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            probs_list.append(probs); true_list.append(yb.numpy())\n",
    "    val_probs = np.vstack(probs_list)\n",
    "    val_true  = np.vstack(true_list)\n",
    "    val_pred05 = (val_probs >= 0.5).astype(int)\n",
    "    macro_f1 = f1_score(val_true, val_pred05, average=\"macro\")\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | macroF1@0.5={macro_f1:.3f}\")\n",
    "\n",
    "    # early stopping on macro-F1\n",
    "    if macro_f1 > best_macro_f1 + 1e-4:\n",
    "        best_macro_f1 = macro_f1\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "\n",
    "# ---- Per-label threshold tuning on validation set ----\n",
    "model.eval()\n",
    "probs_list, true_list = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs_list.append(torch.sigmoid(logits).cpu().numpy())\n",
    "        true_list.append(yb.numpy())\n",
    "val_probs = np.vstack(probs_list)\n",
    "val_true  = np.vstack(true_list)\n",
    "\n",
    "best_thr = tune_thresholds(val_true, val_probs)\n",
    "print(\"Best thresholds per label:\", best_thr)\n",
    "\n",
    "val_pred = (val_probs >= best_thr).astype(int)\n",
    "print(classification_report(val_true, val_pred, target_names=[\"is_ad\",\"is_relevant\",\"is_rant\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
