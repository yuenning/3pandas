{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21078b7",
   "metadata": {},
   "source": [
    "# 1. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b48539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee89be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Kaggle Dataset\n",
    "reviews_df = pd.read_csv('./data/kaggle_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779bcdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>author_name</th>\n",
       "      <th>text</th>\n",
       "      <th>photo</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Gulsum Akar</td>\n",
       "      <td>We went to Marmaris with my wife for a holiday...</td>\n",
       "      <td>dataset/taste/hacinin_yeri_gulsum_akar.png</td>\n",
       "      <td>5</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Oguzhan Cetin</td>\n",
       "      <td>During my holiday in Marmaris we ate here to f...</td>\n",
       "      <td>dataset/menu/hacinin_yeri_oguzhan_cetin.png</td>\n",
       "      <td>4</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Yasin Kuyu</td>\n",
       "      <td>Prices are very affordable. The menu in the ph...</td>\n",
       "      <td>dataset/outdoor_atmosphere/hacinin_yeri_yasin_...</td>\n",
       "      <td>3</td>\n",
       "      <td>outdoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Orhan Kapu</td>\n",
       "      <td>Turkey's cheapest artisan restaurant and its f...</td>\n",
       "      <td>dataset/indoor_atmosphere/hacinin_yeri_orhan_k...</td>\n",
       "      <td>5</td>\n",
       "      <td>indoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Ozgur Sati</td>\n",
       "      <td>I don't know what you will look for in terms o...</td>\n",
       "      <td>dataset/menu/hacinin_yeri_ozgur_sati.png</td>\n",
       "      <td>3</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     business_name    author_name  \\\n",
       "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
       "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
       "2  Haci'nin Yeri - Yigit Lokantasi     Yasin Kuyu   \n",
       "3  Haci'nin Yeri - Yigit Lokantasi     Orhan Kapu   \n",
       "4  Haci'nin Yeri - Yigit Lokantasi     Ozgur Sati   \n",
       "\n",
       "                                                text  \\\n",
       "0  We went to Marmaris with my wife for a holiday...   \n",
       "1  During my holiday in Marmaris we ate here to f...   \n",
       "2  Prices are very affordable. The menu in the ph...   \n",
       "3  Turkey's cheapest artisan restaurant and its f...   \n",
       "4  I don't know what you will look for in terms o...   \n",
       "\n",
       "                                               photo  rating  \\\n",
       "0         dataset/taste/hacinin_yeri_gulsum_akar.png       5   \n",
       "1        dataset/menu/hacinin_yeri_oguzhan_cetin.png       4   \n",
       "2  dataset/outdoor_atmosphere/hacinin_yeri_yasin_...       3   \n",
       "3  dataset/indoor_atmosphere/hacinin_yeri_orhan_k...       5   \n",
       "4           dataset/menu/hacinin_yeri_ozgur_sati.png       3   \n",
       "\n",
       "      rating_category  \n",
       "0               taste  \n",
       "1                menu  \n",
       "2  outdoor_atmosphere  \n",
       "3   indoor_atmosphere  \n",
       "4                menu  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "923b9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 states: ['Missouri', 'North Dakota', 'New Jersey', 'New York', 'Rhode Island', 'Oregon', 'Iowa', 'Georgia', 'Virginia', 'Nevada']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "STATES = [\n",
    "    \"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\n",
    "    \"District of Columbia\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\"Iowa\",\n",
    "    \"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\n",
    "    \"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\n",
    "    \"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\n",
    "    \"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "    \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"\n",
    "]\n",
    "\n",
    "REGION = {\n",
    "    \"Northeast\": {\"Maine\",\"New Hampshire\",\"Vermont\",\"Massachusetts\",\"Rhode Island\",\"Connecticut\",\n",
    "                  \"New York\",\"New Jersey\",\"Pennsylvania\"},\n",
    "    \"Midwest\": {\"Ohio\",\"Michigan\",\"Indiana\",\"Wisconsin\",\"Illinois\",\"Minnesota\",\"Iowa\",\"Missouri\",\n",
    "                \"North Dakota\",\"South Dakota\",\"Nebraska\",\"Kansas\"},\n",
    "    \"South\": {\"Delaware\",\"Maryland\",\"District of Columbia\",\"Virginia\",\"West Virginia\",\"North Carolina\",\n",
    "              \"South Carolina\",\"Georgia\",\"Florida\",\"Kentucky\",\"Tennessee\",\"Mississippi\",\"Alabama\",\n",
    "              \"Oklahoma\",\"Texas\",\"Arkansas\",\"Louisiana\"},\n",
    "    \"West\": {\"Idaho\",\"Montana\",\"Wyoming\",\"Nevada\",\"Utah\",\"Colorado\",\"Arizona\",\"New Mexico\",\n",
    "             \"Alaska\",\"Washington\",\"Oregon\",\"California\",\"Hawaii\"}\n",
    "}\n",
    "\n",
    "random.seed(500)\n",
    "\n",
    "# Step 1: pick 3 states per region (12 total)\n",
    "per_region_picks = {}\n",
    "for rgn, pool in REGION.items():\n",
    "    pool_list = list(pool & set(STATES))\n",
    "    per_region_picks[rgn] = random.sample(pool_list, 3)\n",
    "\n",
    "# Flatten to list of 12\n",
    "all_12 = [st for r in per_region_picks.values() for st in r]\n",
    "\n",
    "# Step 2: randomly drop 2 to make 10\n",
    "all_10 = random.sample(all_12, 10)\n",
    "\n",
    "# Step 3: shuffle and split into 3 groups\n",
    "random.shuffle(all_10)\n",
    "groups = [all_10[i*4:(i+1)*4] for i in range(3)]  # first 2 groups of 4, last group may be shorter\n",
    "\n",
    "print(\"Selected 10 states:\", all_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411f2a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 'text': 18,661,975 -> 9,974,803 rows\n",
      "✅ Loaded 9,974,803 usable rows, sampled 1,000 → saved to google_reviews_sample_new_york.json\n"
     ]
    }
   ],
   "source": [
    "# Change folder and input file individually because \n",
    "# running all of them at once hits memory limits\n",
    "\n",
    "# ---- config ----\n",
    "FOLDER = \"./data/google_reviews_US/review-New_York_10.json\"   # path to the folder\n",
    "INPUT_FILE = os.path.join(FOLDER, \"review-New_York_10.json\")  # the actual file inside\n",
    "OUTPUT_FILE = \"google_reviews_sample_new_york.json\"\n",
    "SAMPLE_SIZE = 1000  # sample about 1000 per state\n",
    "# ----------------\n",
    "\n",
    "def read_json_any(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read JSON Lines first, fall back to normal JSON.\"\"\"\n",
    "    try:\n",
    "        return pd.read_json(path, lines=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    if isinstance(obj, list):\n",
    "        return pd.json_normalize(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return pd.json_normalize(obj)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# 1) Load\n",
    "df = read_json_any(INPUT_FILE)\n",
    "\n",
    "# 2) Keep only rows with non-null, non-empty \"text\"\n",
    "if \"text\" in df.columns:\n",
    "    before = len(df)\n",
    "    df = df[df[\"text\"].notna()]                                 # drop NaNs\n",
    "    df = df[df[\"text\"].astype(str).str.strip().ne(\"\")]          # drop empty/whitespace\n",
    "    after = len(df)\n",
    "    print(f\"Filtered 'text': {before:,} -> {after:,} rows\")\n",
    "else:\n",
    "    print(\"⚠️ Warning: 'text' column not found; proceeding without filter.\")\n",
    "\n",
    "# 3) Sample (up to SAMPLE_SIZE)\n",
    "n = min(SAMPLE_SIZE, len(df))\n",
    "if n < SAMPLE_SIZE:\n",
    "    print(f\"⚠️ Only {len(df):,} rows available after filtering; sampling {n}.\")\n",
    "df_sample = df.sample(n=n, random_state=42)\n",
    "\n",
    "# 4) Save as JSON Lines\n",
    "df_sample.to_json(OUTPUT_FILE, orient=\"records\", lines=True, force_ascii=False)\n",
    "print(f\"✅ Loaded {len(df):,} usable rows, sampled {len(df_sample):,} → saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f5a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "                review_id                 user_id             business_id  \\\n",
      "0  -BMXekpibxnJU7UVlNDVLQ  Z57PG6be2-CPNOUJ_BOQGw  QRotJ0k3qj4ecdqNprStxQ   \n",
      "1  wqUFsDcCZ0r3DryheIUCvg  pOz8G2ezXNRx-yCyRi-0Dg  UiALq7G2d9w1S7fvZEv6TA   \n",
      "2  cb-Td9FaGSpqE96lOnVeSQ  S9izJAfdGsgBI_AHiw3PHA  l331_6tXs8PSryWql2cOrQ   \n",
      "3  LQ9AQ-G25duVtv5gy7zDTA  rfDqKDpd1_B-VlkPDfHsqQ  pVwMHUYFMuwmRe6M--ZzwA   \n",
      "4  MqBca9E0uUA-DOXeL8JvBg  JlnvSC3c6t0gOLizuLs2Bw  mSrXEXee3PX8qjwSuSWlSg   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0      3       0      0     0   \n",
      "1      4       2      0     0   \n",
      "2      1       1      0     0   \n",
      "3      3      10      0     2   \n",
      "4      1       0      0     0   \n",
      "\n",
      "                                                text                date  \n",
      "0  First time going here. The swirl margarita was... 2013-07-14 03:11:55  \n",
      "1  I have drove past this restaurant many times a... 2020-02-26 17:12:57  \n",
      "2  STAY AWAY! My friends and I stayed here and we... 2019-02-21 07:12:10  \n",
      "3  Ok my rating is due to what you get for the pr... 2019-08-04 13:22:04  \n",
      "4  They are very, very nice, overly friendly (the... 2020-06-30 23:00:12  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teomi\\AppData\\Local\\Temp\\ipykernel_6316\\617470528.py:17: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  yelp_sample = pd.read_json('\\n'.join(sample), lines=True)\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/Yelp-JSON/Yelp JSON/yelp_dataset/yelp_academic_dataset_review.json'\n",
    "\n",
    "N = 10000  # how many reviews you want\n",
    "sample = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if i <= N:\n",
    "            sample.append(line)\n",
    "        else:\n",
    "            # Replace elements with decreasing probability\n",
    "            j = random.randint(1, i)\n",
    "            if j <= N:\n",
    "                sample[j-1] = line\n",
    "\n",
    "# Parse just the sampled JSON lines\n",
    "yelp_sample = pd.read_json('\\n'.join(sample), lines=True)\n",
    "\n",
    "print(yelp_sample.shape)\n",
    "print(yelp_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64caca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_sample.to_json('./data/yelp_sample.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
