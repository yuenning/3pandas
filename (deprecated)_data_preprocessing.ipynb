{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21078b7",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b48539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import yaml\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24729424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configuration from YAML file\n",
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Kaggle Dataset\n",
    "kaggle_reviews_df = pd.read_csv(config[\"kaggle_reviews_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee89be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Kaggle Dataset (DEPRECATED - to be deleted)\n",
    "kaggle_reviews_df = pd.read_csv('./data/kaggle_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "779bcdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>author_name</th>\n",
       "      <th>text</th>\n",
       "      <th>photo</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Gulsum Akar</td>\n",
       "      <td>We went to Marmaris with my wife for a holiday...</td>\n",
       "      <td>dataset/taste/hacinin_yeri_gulsum_akar.png</td>\n",
       "      <td>5</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Oguzhan Cetin</td>\n",
       "      <td>During my holiday in Marmaris we ate here to f...</td>\n",
       "      <td>dataset/menu/hacinin_yeri_oguzhan_cetin.png</td>\n",
       "      <td>4</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Yasin Kuyu</td>\n",
       "      <td>Prices are very affordable. The menu in the ph...</td>\n",
       "      <td>dataset/outdoor_atmosphere/hacinin_yeri_yasin_...</td>\n",
       "      <td>3</td>\n",
       "      <td>outdoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Orhan Kapu</td>\n",
       "      <td>Turkey's cheapest artisan restaurant and its f...</td>\n",
       "      <td>dataset/indoor_atmosphere/hacinin_yeri_orhan_k...</td>\n",
       "      <td>5</td>\n",
       "      <td>indoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Ozgur Sati</td>\n",
       "      <td>I don't know what you will look for in terms o...</td>\n",
       "      <td>dataset/menu/hacinin_yeri_ozgur_sati.png</td>\n",
       "      <td>3</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     business_name    author_name  \\\n",
       "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
       "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
       "2  Haci'nin Yeri - Yigit Lokantasi     Yasin Kuyu   \n",
       "3  Haci'nin Yeri - Yigit Lokantasi     Orhan Kapu   \n",
       "4  Haci'nin Yeri - Yigit Lokantasi     Ozgur Sati   \n",
       "\n",
       "                                                text  \\\n",
       "0  We went to Marmaris with my wife for a holiday...   \n",
       "1  During my holiday in Marmaris we ate here to f...   \n",
       "2  Prices are very affordable. The menu in the ph...   \n",
       "3  Turkey's cheapest artisan restaurant and its f...   \n",
       "4  I don't know what you will look for in terms o...   \n",
       "\n",
       "                                               photo  rating  \\\n",
       "0         dataset/taste/hacinin_yeri_gulsum_akar.png       5   \n",
       "1        dataset/menu/hacinin_yeri_oguzhan_cetin.png       4   \n",
       "2  dataset/outdoor_atmosphere/hacinin_yeri_yasin_...       3   \n",
       "3  dataset/indoor_atmosphere/hacinin_yeri_orhan_k...       5   \n",
       "4           dataset/menu/hacinin_yeri_ozgur_sati.png       3   \n",
       "\n",
       "      rating_category  \n",
       "0               taste  \n",
       "1                menu  \n",
       "2  outdoor_atmosphere  \n",
       "3   indoor_atmosphere  \n",
       "4                menu  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3350a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_name', 'author_name', 'text', 'photo', 'rating',\n",
      "       'rating_category'],\n",
      "      dtype='object')\n",
      "(1100, 6)\n"
     ]
    }
   ],
   "source": [
    "print(kaggle_reviews_df.columns)\n",
    "print(kaggle_reviews_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ddc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "apify_scraper_df1 = pd.read_csv(config[\"apify_scraper_path1\"])\n",
    "apify_scraper_df2 = pd.read_csv(config[\"apify_scraper_path2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "923b9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 states: ['Indiana', 'Wisconsin', 'Massachusetts', 'Vermont', 'New Hampshire', 'Nevada', 'Illinois', 'Arkansas', 'Virginia', 'Idaho']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "STATES = [\n",
    "    \"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\n",
    "    \"District of Columbia\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\"Iowa\",\n",
    "    \"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\n",
    "    \"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\n",
    "    \"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\n",
    "    \"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "    \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"\n",
    "]\n",
    "\n",
    "REGION = {\n",
    "    \"Northeast\": {\"Maine\",\"New Hampshire\",\"Vermont\",\"Massachusetts\",\"Rhode Island\",\"Connecticut\",\n",
    "                  \"New York\",\"New Jersey\",\"Pennsylvania\"},\n",
    "    \"Midwest\": {\"Ohio\",\"Michigan\",\"Indiana\",\"Wisconsin\",\"Illinois\",\"Minnesota\",\"Iowa\",\"Missouri\",\n",
    "                \"North Dakota\",\"South Dakota\",\"Nebraska\",\"Kansas\"},\n",
    "    \"South\": {\"Delaware\",\"Maryland\",\"District of Columbia\",\"Virginia\",\"West Virginia\",\"North Carolina\",\n",
    "              \"South Carolina\",\"Georgia\",\"Florida\",\"Kentucky\",\"Tennessee\",\"Mississippi\",\"Alabama\",\n",
    "              \"Oklahoma\",\"Texas\",\"Arkansas\",\"Louisiana\"},\n",
    "    \"West\": {\"Idaho\",\"Montana\",\"Wyoming\",\"Nevada\",\"Utah\",\"Colorado\",\"Arizona\",\"New Mexico\",\n",
    "             \"Alaska\",\"Washington\",\"Oregon\",\"California\",\"Hawaii\"}\n",
    "}\n",
    "\n",
    "random.seed(500)\n",
    "\n",
    "# Step 1: pick 3 states per region (12 total)\n",
    "per_region_picks = {}\n",
    "for rgn, pool in REGION.items():\n",
    "    pool_list = list(pool & set(STATES))\n",
    "    per_region_picks[rgn] = random.sample(pool_list, 3)\n",
    "\n",
    "# Flatten to list of 12\n",
    "all_12 = [st for r in per_region_picks.values() for st in r]\n",
    "\n",
    "# Step 2: randomly drop 2 to make 10\n",
    "all_10 = random.sample(all_12, 10)\n",
    "\n",
    "# Step 3: shuffle and split into 3 groups\n",
    "random.shuffle(all_10)\n",
    "groups = [all_10[i*4:(i+1)*4] for i in range(3)]  # first 2 groups of 4, last group may be shorter\n",
    "\n",
    "print(\"Selected 10 states:\", all_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f2a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 'text': 2,677,684 -> 1,382,508 rows\n",
      "✅ Loaded 1,382,508 usable rows, sampled 1,000 → saved to ./data/us_reviews/output/google_reviews_sample_iowa.json\n"
     ]
    }
   ],
   "source": [
    "# Change folder and input file individually because \n",
    "# running all of them at once hits memory limits\n",
    "\n",
    "# ---- config ---- (MOVE TO config.yaml)\n",
    "FOLDER = \"./data/google_reviews_US/review-New_York_10.json\"   # path to the folder\n",
    "INPUT_FILE = os.path.join(FOLDER, \"review-New_York_10.json\")  # the actual file inside\n",
    "OUTPUT_FILE = \"google_reviews_sample_new_york.json\"\n",
    "SAMPLE_SIZE = 1000  # sample about 1000 per state\n",
    "# ----------------\n",
    "\n",
    "def read_json_any(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read JSON Lines first, fall back to normal JSON.\"\"\"\n",
    "    try:\n",
    "        return pd.read_json(path, lines=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    if isinstance(obj, list):\n",
    "        return pd.json_normalize(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return pd.json_normalize(obj)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# 1) Load\n",
    "df = read_json_any(config[\"US_input_file\"])\n",
    "\n",
    "# 2) Keep only rows with non-null, non-empty \"text\"\n",
    "if \"text\" in df.columns:\n",
    "    before = len(df)\n",
    "    df = df[df[\"text\"].notna()]                                 # drop NaNs\n",
    "    df = df[df[\"text\"].astype(str).str.strip().ne(\"\")]          # drop empty/whitespace\n",
    "    after = len(df)\n",
    "    print(f\"Filtered 'text': {before:,} -> {after:,} rows\")\n",
    "else:\n",
    "    print(\"⚠️ Warning: 'text' column not found; proceeding without filter.\")\n",
    "\n",
    "# 3) Sample (up to SAMPLE_SIZE)\n",
    "n = min(SAMPLE_SIZE, len(df))\n",
    "if n < SAMPLE_SIZE:\n",
    "    print(f\"⚠️ Only {len(df):,} rows available after filtering; sampling {n}.\")\n",
    "df_sample = df.sample(n=n, random_state=42)\n",
    "\n",
    "# 4) Save as JSON Lines\n",
    "df_sample.to_json(config[\"US_output_file\"], orient=\"records\", lines=True, force_ascii=False)\n",
    "print(f\"✅ Loaded {len(df):,} usable rows, sampled {len(df_sample):,} → saved to {config[\"US_output_file\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f5a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "                review_id                 user_id             business_id  \\\n",
      "0  -BMXekpibxnJU7UVlNDVLQ  Z57PG6be2-CPNOUJ_BOQGw  QRotJ0k3qj4ecdqNprStxQ   \n",
      "1  wqUFsDcCZ0r3DryheIUCvg  pOz8G2ezXNRx-yCyRi-0Dg  UiALq7G2d9w1S7fvZEv6TA   \n",
      "2  cb-Td9FaGSpqE96lOnVeSQ  S9izJAfdGsgBI_AHiw3PHA  l331_6tXs8PSryWql2cOrQ   \n",
      "3  LQ9AQ-G25duVtv5gy7zDTA  rfDqKDpd1_B-VlkPDfHsqQ  pVwMHUYFMuwmRe6M--ZzwA   \n",
      "4  MqBca9E0uUA-DOXeL8JvBg  JlnvSC3c6t0gOLizuLs2Bw  mSrXEXee3PX8qjwSuSWlSg   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0      3       0      0     0   \n",
      "1      4       2      0     0   \n",
      "2      1       1      0     0   \n",
      "3      3      10      0     2   \n",
      "4      1       0      0     0   \n",
      "\n",
      "                                                text                date  \n",
      "0  First time going here. The swirl margarita was... 2013-07-14 03:11:55  \n",
      "1  I have drove past this restaurant many times a... 2020-02-26 17:12:57  \n",
      "2  STAY AWAY! My friends and I stayed here and we... 2019-02-21 07:12:10  \n",
      "3  Ok my rating is due to what you get for the pr... 2019-08-04 13:22:04  \n",
      "4  They are very, very nice, overly friendly (the... 2020-06-30 23:00:12  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teomi\\AppData\\Local\\Temp\\ipykernel_6316\\617470528.py:17: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  yelp_sample = pd.read_json('\\n'.join(sample), lines=True)\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/Yelp-JSON/Yelp JSON/yelp_dataset/yelp_academic_dataset_review.json'\n",
    "\n",
    "N = 10000  # how many reviews you want\n",
    "sample = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if i <= N:\n",
    "            sample.append(line)\n",
    "        else:\n",
    "            # Replace elements with decreasing probability\n",
    "            j = random.randint(1, i)\n",
    "            if j <= N:\n",
    "                sample[j-1] = line\n",
    "\n",
    "# Parse just the sampled JSON lines\n",
    "yelp_sample = pd.read_json('\\n'.join(sample), lines=True)\n",
    "\n",
    "print(yelp_sample.shape)\n",
    "print(yelp_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64caca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_sample.to_json('./data/yelp_sample.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc66ebb",
   "metadata": {},
   "source": [
    "# 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5e95829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_text_rows(df, text_col=None):\n",
    "    \"\"\"\n",
    "    Remove rows from DataFrame where the specified text column is NaN or empty/whitespace.\n",
    "    If text_col is None, drop any rows with any null values.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        text_col (str or None): Name of the text column to check, or None to drop any row with nulls.\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    if text_col is None:\n",
    "        return df.dropna()\n",
    "    df = df[df[text_col].notna()]  # drop NaNs in text_col\n",
    "    df = df[df[text_col].astype(str).str.strip().ne(\"\")]  # drop empty/whitespace in text_col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959f064",
   "metadata": {},
   "source": [
    "## 2.1. Kaggle Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce9ab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'rating_category' column\n",
    "if 'rating_category' in kaggle_reviews_df.columns:\n",
    "    kaggle_reviews_df = kaggle_reviews_df.drop(columns=['rating_category'])\n",
    "\n",
    "kaggle_reviews_df = drop_empty_text_rows(kaggle_reviews_df, text_col=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45958786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d177f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_count_df = kaggle_reviews_df['author_name'].value_counts().reset_index()\n",
    "author_count_df.columns = ['author_name', 'frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e251f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        author_name  frequency\n",
      "0   Nihat Karabiber          3\n",
      "1        Ece Oztunc          3\n",
      "2        Mustafa Ay          3\n",
      "3  Saliha Senyildiz          3\n",
      "4        Seda Seven          2\n",
      "(1074, 2)\n"
     ]
    }
   ],
   "source": [
    "print(author_count_df.head())\n",
    "print(author_count_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a85005d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save kaggle_reviews_df to a CSV file\n",
    "kaggle_reviews_df.to_csv(config[\"kaggle_reviews_cleaned_path\"], index=False)\n",
    "author_count_df.to_csv(config[\"kaggle_reviews_per_author\"], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741430d",
   "metadata": {},
   "source": [
    "## 2.2. US Reviews (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a99d8",
   "metadata": {},
   "source": [
    "## 2.3. Apify Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff531d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apify_scraper_df1 = drop_empty_text_rows(apify_scraper_df1, text_col=\"text\")\n",
    "apify_scraper_df2 = drop_empty_text_rows(apify_scraper_df2, text_col=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6afa8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 6)\n",
      "(377, 100)\n"
     ]
    }
   ],
   "source": [
    "print(apify_scraper_df1.shape)\n",
    "print(apify_scraper_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apify_scraper_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64e8f850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>categories/0</th>\n",
       "      <th>categories/1</th>\n",
       "      <th>categories/2</th>\n",
       "      <th>categoryName</th>\n",
       "      <th>cid</th>\n",
       "      <th>city</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>error</th>\n",
       "      <th>fid</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>street</th>\n",
       "      <th>temporarilyClosed</th>\n",
       "      <th>text</th>\n",
       "      <th>textTranslated</th>\n",
       "      <th>title</th>\n",
       "      <th>totalScore</th>\n",
       "      <th>translatedLanguage</th>\n",
       "      <th>url</th>\n",
       "      <th>visitedIn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135, Singapore ...</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>Grocery store</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>3888765206883078885</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135</td>\n",
       "      <td>False</td>\n",
       "      <td>Buy food lah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold Storage</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135, Singapore ...</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>Grocery store</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>3888765206883078885</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135</td>\n",
       "      <td>False</td>\n",
       "      <td>Aunty Joe and fat Auntie is serving me good an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold Storage</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135, Singapore ...</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>Grocery store</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>3888765206883078885</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135</td>\n",
       "      <td>False</td>\n",
       "      <td>Nothing much.. Very small only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold Storage</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135, Singapore ...</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>Grocery store</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>3888765206883078885</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135</td>\n",
       "      <td>False</td>\n",
       "      <td>Not big, most stuff are there</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold Storage</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135, Singapore ...</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>Grocery store</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>Cold storage facility</td>\n",
       "      <td>3888765206883078885</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 Hougang St 21, #01 - 133 / 135</td>\n",
       "      <td>False</td>\n",
       "      <td>Freshness level totally low. Strawberry at $10...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold Storage</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              address           categories/0  \\\n",
       "3   205 Hougang St 21, #01 - 133 / 135, Singapore ...  Cold storage facility   \n",
       "6   205 Hougang St 21, #01 - 133 / 135, Singapore ...  Cold storage facility   \n",
       "7   205 Hougang St 21, #01 - 133 / 135, Singapore ...  Cold storage facility   \n",
       "9   205 Hougang St 21, #01 - 133 / 135, Singapore ...  Cold storage facility   \n",
       "10  205 Hougang St 21, #01 - 133 / 135, Singapore ...  Cold storage facility   \n",
       "\n",
       "     categories/1 categories/2           categoryName                  cid  \\\n",
       "3   Grocery store  Supermarket  Cold storage facility  3888765206883078885   \n",
       "6   Grocery store  Supermarket  Cold storage facility  3888765206883078885   \n",
       "7   Grocery store  Supermarket  Cold storage facility  3888765206883078885   \n",
       "9   Grocery store  Supermarket  Cold storage facility  3888765206883078885   \n",
       "10  Grocery store  Supermarket  Cold storage facility  3888765206883078885   \n",
       "\n",
       "         city countryCode error                                    fid  ...  \\\n",
       "3   Singapore          SG   NaN  0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5  ...   \n",
       "6   Singapore          SG   NaN  0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5  ...   \n",
       "7   Singapore          SG   NaN  0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5  ...   \n",
       "9   Singapore          SG   NaN  0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5  ...   \n",
       "10  Singapore          SG   NaN  0x31da17b3f9b9dfb9:0x35f7ab5a232a12e5  ...   \n",
       "\n",
       "   state                              street temporarilyClosed  \\\n",
       "3    NaN  205 Hougang St 21, #01 - 133 / 135             False   \n",
       "6    NaN  205 Hougang St 21, #01 - 133 / 135             False   \n",
       "7    NaN  205 Hougang St 21, #01 - 133 / 135             False   \n",
       "9    NaN  205 Hougang St 21, #01 - 133 / 135             False   \n",
       "10   NaN  205 Hougang St 21, #01 - 133 / 135             False   \n",
       "\n",
       "                                                 text  textTranslated  \\\n",
       "3                                        Buy food lah             NaN   \n",
       "6   Aunty Joe and fat Auntie is serving me good an...             NaN   \n",
       "7                      Nothing much.. Very small only             NaN   \n",
       "9                       Not big, most stuff are there             NaN   \n",
       "10  Freshness level totally low. Strawberry at $10...             NaN   \n",
       "\n",
       "           title  totalScore translatedLanguage  \\\n",
       "3   Cold Storage         4.1                NaN   \n",
       "6   Cold Storage         4.1                NaN   \n",
       "7   Cold Storage         4.1                NaN   \n",
       "9   Cold Storage         4.1                NaN   \n",
       "10  Cold Storage         4.1                NaN   \n",
       "\n",
       "                                                  url visitedIn  \n",
       "3   https://www.google.com/maps/search/?api=1&quer...       NaN  \n",
       "6   https://www.google.com/maps/search/?api=1&quer...       NaN  \n",
       "7   https://www.google.com/maps/search/?api=1&quer...       NaN  \n",
       "9   https://www.google.com/maps/search/?api=1&quer...       NaN  \n",
       "10  https://www.google.com/maps/search/?api=1&quer...       NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apify_scraper_df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
