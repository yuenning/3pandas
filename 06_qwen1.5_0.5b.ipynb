{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9638c6d0",
      "metadata": {
        "id": "9638c6d0"
      },
      "source": [
        "# [06] Multi-Label Text Classification with Qwen-1.5-0.5B\n",
        "**Objective:** To train and optimize a multi-label transformer model for simultaneously detecting advertisement, relevance, and rant violations in reviews, using a combination of text features and metadata.\n",
        "**Input:**\n",
        "- `../data/processed/all_reviews_with_labels.parquet` (from Notebook 04)\n",
        "- `../data/processed/synthetic_reviews.json` (from Notebook 05)\n",
        "**Output:** \n",
        "- Trained Qwen-1.5-0.5B model weights\n",
        "- Optimal threshold values for each class\n",
        "- Performance metrics and evaluation results\n",
        "\n",
        "## Introduction\n",
        "This notebook implements the core machine learning component of our content moderation system. We face a complex multi-label classification problem with severe class imbalance, requiring specialized handling of both text and metadata features.\n",
        "\n",
        "The process involves several key stages:\n",
        "\n",
        "1.  **Data Integration & Feature Engineering:** We combine our original labeled data with synthetically generated examples to balance the classes. We then engineer crucial meta-features from the raw text (URL counts, phone numbers, capitalization ratios, etc.) that provide strong signals for certain violation types.\n",
        "\n",
        "2.  **Stratified Train-Test Split:** We employ multi-label stratification to ensure that all combinations of our three target labels (`is_ad`, `is_relevant`, `is_rant`) are proportionally represented in both training and testing sets, which is critical for reliable evaluation.\n",
        "\n",
        "3.  **Model Architecture:** We implement a hybrid model that combines:\n",
        "    - A **Qwen-1.5-0.5B transformer** for processing review text and extracting deep semantic features.\n",
        "    - A **custom neural network** for processing the engineered meta-features.\n",
        "    - A **fusion layer** that integrates both information streams for final prediction.\n",
        "\n",
        "4.  **Threshold Optimization:** Due to extreme class imbalance, we perform precision-recall analysis to find optimal probability thresholds for each class (0.756 for ads, 0.1 for relevance, and 0.852 for rants) rather than using the default 0.5.\n",
        "\n",
        "The final model provides an automated content moderation solution that balances detection sensitivity with precision constraints through learned business rules."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1a970a",
      "metadata": {
        "id": "0e1a970a"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "TntPihBO05xl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TntPihBO05xl",
        "outputId": "196d749d-f8fd-43cf-8cb8-094d699cacb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate datasets peft torch tensorboard iterative-stratification scikit-learn plotly optuna\n",
        "!pip install --upgrade --quiet nltk textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "b1a2762e",
      "metadata": {
        "id": "b1a2762e"
      },
      "outputs": [],
      "source": [
        "# ===== Standard Library =====\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import shutil\n",
        "import psutil\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "# ===== Data Processing & Utilities =====\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ===== PyTorch & CUDA =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ===== Transformers & NLP Models =====\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    pipeline,\n",
        "    get_scheduler\n",
        ")\n",
        "\n",
        "# ===== Hugging Face PEFT (LoRA) =====\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# ===== Evaluation Metrics =====\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_recall_fscore_support,\n",
        "    average_precision_score,\n",
        "    precision_recall_curve\n",
        ")\n",
        "\n",
        "# ===== ML Utilities =====\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "# ===== Google Colab =====\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ktcGgrRw0OWM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "ktcGgrRw0OWM",
        "outputId": "d09142d1-d6d5-46dc-dc08-e9481f203fd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3947bf91-e559-41bc-8872-5eaca8a4718d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3947bf91-e559-41bc-8872-5eaca8a4718d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all_reviews_with_labels_normalised.csv to all_reviews_with_labels_normalised.csv\n",
            "Saving synthetic_combined.csv to synthetic_combined.csv\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b426534",
      "metadata": {
        "id": "4b426534"
      },
      "source": [
        "### 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "JgSLDXqZ0nR6",
      "metadata": {
        "id": "JgSLDXqZ0nR6"
      },
      "outputs": [],
      "source": [
        "all_reviews = list(uploaded.keys())[0]\n",
        "synthetic_combined = list(uploaded.keys())[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95d9dd7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d9dd7a",
        "outputId": "94ed290d-c28d-457f-8e84-9781add950b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded all_reviews_with_labels_normalised.csv with 11667 rows\n",
            "review_text             0\n",
            "rating                  0\n",
            "has_photo               0\n",
            "author_name             0\n",
            "user_review_count       0\n",
            "business_name           0\n",
            "category                0\n",
            "source                  0\n",
            "review_id               0\n",
            "comprehensive_review    0\n",
            "is_ad                   0\n",
            "is_relevant             0\n",
            "is_rant                 0\n",
            "is_legit                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "full_df = pd.read_csv(all_reviews)\n",
        "full_df = full_df.dropna(subset=['rating']).reset_index(drop=True)\n",
        "\n",
        "print(f\"Loaded {all_reviews} with {len(full_df)} rows\")\n",
        "print(full_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "l-5FU6p_0dv8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-5FU6p_0dv8",
        "outputId": "d7f63e91-3f12-4312-ac90-38a04bfbd1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded synthetic_combined.csv with 714 rows\n",
            "review_text             0\n",
            "rating                  0\n",
            "has_photo               0\n",
            "author_name             0\n",
            "user_review_count       0\n",
            "business_name           0\n",
            "category                0\n",
            "source                  0\n",
            "review_id               0\n",
            "is_ad                   0\n",
            "is_rant                 0\n",
            "is_legit                0\n",
            "is_relevant             0\n",
            "comprehensive_review    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "synthetic_df = pd.read_csv(synthetic_combined)\n",
        "\n",
        "def s(col):\n",
        "    return synthetic_df[col].fillna(\"NA\").astype(str).str.strip()\n",
        "\n",
        "has_photo_str = np.where(synthetic_df[\"has_photo\"].fillna(False), \"yes\", \"no\")\n",
        "MAX_REVIEW_CHARS = 2000\n",
        "review_text_clean = s(\"review_text\").str.replace(r\"\\s+\", \" \", regex=True).str[:MAX_REVIEW_CHARS]\n",
        "\n",
        "synthetic_df[\"comprehensive_review\"] = (\n",
        "    \"[Business] \" + s(\"business_name\") +\n",
        "    \" | [Category] \" + s(\"category\") +\n",
        "    \" | [Rating] \" + s(\"rating\") +\n",
        "    \" | [Author] \" + s(\"author_name\") +\n",
        "    \" | [User Review Count] \" + s(\"user_review_count\") +\n",
        "    \" | [Has Photo] \" + pd.Series(has_photo_str, index=synthetic_df.index) +\n",
        "    \" | [Source] \" + s(\"source\") +\n",
        "    \" | [Review] \" + review_text_clean\n",
        ").str.replace(r\"\\s+\\|\\s+\\[Review\\]\\s+NA$\", \"\", regex=True)\n",
        "\n",
        "print(f\"Loaded {synthetic_combined} with {len(synthetic_df)} rows\")\n",
        "print(synthetic_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a08e3016",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a08e3016",
        "outputId": "d44a36c0-e116-4db8-d647-ff146878c211"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"to_clean_df\",\n  \"rows\": 11667,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11194,\n        \"samples\": [\n          \"Nice place to go!  One of few places with a merry go round anymore.  Great for anything outside!\",\n          \"Great wings and fries\",\n          \"quick, home-style food with a small and simple menu. Milk shakes are very good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.21894107157901,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.0,\n          3.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_photo\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11401,\n        \"samples\": [\n          \"Richard Jensen\",\n          \"Kelley Byrd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_review_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 120.44379856716289,\n        \"min\": 0.0,\n        \"max\": 3062.0,\n        \"num_unique_values\": 448,\n        \"samples\": [\n          391.0,\n          120.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"business_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6124,\n        \"samples\": [\n          \"Nellis Main Exchange\",\n          \"HoDo Restaurant & Lounge\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3383,\n        \"samples\": [\n          \"['Banquet hall', 'Wedding venue']\",\n          \"['Hardware store', 'Grill store', 'Home improvement store', 'Lawn mower store', 'Paint store', 'Tool store']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"singapore\",\n          \"google\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5790,\n        \"min\": 1001,\n        \"max\": 20614,\n        \"num_unique_values\": 11667,\n        \"samples\": [\n          19717,\n          7835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comprehensive_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11659,\n        \"samples\": [\n          \"[Business] Regal UA Kaufman Astoria & RPX | [Category] ['Movie theater'] | [Rating] 3.0 | [Author] Osbaldo Minchala | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] It was okay. The movie i watched was the only good thing I liked about this place.\",\n          \"[Business] Walmart Supercenter | [Category] ['Department store', 'Clothing store', 'Craft store', 'Discount store', 'Electronics store', 'Grocery store', 'Home goods store', 'Sporting goods store', 'Supermarket', 'Toy store'] | [Rating] 1.0 | [Author] Courtney Widick | [User Review Count] 1.0 | [Has Photo] no | [Source] google | [Review] I do not understand why at 7pm on a Tuesday afternoon these only 2 registers open. This is ridiculous waiting in these long lines for a few items when there could be more then 2 registers going right now.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_ad\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_relevant\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_rant\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_legit\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "to_clean_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9db076f4-ce0c-42a9-8690-6aa744087bdd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>rating</th>\n",
              "      <th>has_photo</th>\n",
              "      <th>author_name</th>\n",
              "      <th>user_review_count</th>\n",
              "      <th>business_name</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "      <th>review_id</th>\n",
              "      <th>comprehensive_review</th>\n",
              "      <th>is_ad</th>\n",
              "      <th>is_relevant</th>\n",
              "      <th>is_rant</th>\n",
              "      <th>is_legit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Love the convenience of this neighborhood carw...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Doug Schmidt</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Auto Spa Speedy Wash - Harvester, MO</td>\n",
              "      <td>['Car wash']</td>\n",
              "      <td>google</td>\n",
              "      <td>1001</td>\n",
              "      <td>[Business] Auto Spa Speedy Wash - Harvester, M...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 bathrooms (for a large 2 story building), 1 ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Duf Duftopia</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Kmart</td>\n",
              "      <td>['Discount store', 'Appliance store', 'Baby st...</td>\n",
              "      <td>google</td>\n",
              "      <td>1002</td>\n",
              "      <td>[Business] Kmart | [Category] ['Discount store...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My favorite pizza shop hands down!</td>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Andrew Phillips</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Papa’s Pizza</td>\n",
              "      <td>['Pizza restaurant', 'Chicken wings restaurant...</td>\n",
              "      <td>google</td>\n",
              "      <td>1003</td>\n",
              "      <td>[Business] Papa’s Pizza | [Category] ['Pizza r...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Julie Heiland</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The Music Place</td>\n",
              "      <td>['Musical instrument store']</td>\n",
              "      <td>google</td>\n",
              "      <td>1004</td>\n",
              "      <td>[Business] The Music Place | [Category] ['Musi...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very unprofessional!!!!!</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>Alan Khasanov</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Park Motor Cars Inc</td>\n",
              "      <td>['Used car dealer']</td>\n",
              "      <td>google</td>\n",
              "      <td>1005</td>\n",
              "      <td>[Business] Park Motor Cars Inc | [Category] ['...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9db076f4-ce0c-42a9-8690-6aa744087bdd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9db076f4-ce0c-42a9-8690-6aa744087bdd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9db076f4-ce0c-42a9-8690-6aa744087bdd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aab89030-6c57-41a8-b146-34278c8b81e3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aab89030-6c57-41a8-b146-34278c8b81e3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aab89030-6c57-41a8-b146-34278c8b81e3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         review_text  rating  has_photo  \\\n",
              "0  Love the convenience of this neighborhood carw...     4.0      False   \n",
              "1  2 bathrooms (for a large 2 story building), 1 ...     2.0      False   \n",
              "2                 My favorite pizza shop hands down!     5.0      False   \n",
              "3  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...     1.0      False   \n",
              "4                           Very unprofessional!!!!!     1.0      False   \n",
              "\n",
              "       author_name  user_review_count                         business_name  \\\n",
              "0     Doug Schmidt                1.0  Auto Spa Speedy Wash - Harvester, MO   \n",
              "1     Duf Duftopia                1.0                                 Kmart   \n",
              "2  Andrew Phillips                1.0                          Papa’s Pizza   \n",
              "3    Julie Heiland                1.0                       The Music Place   \n",
              "4    Alan Khasanov                1.0                   Park Motor Cars Inc   \n",
              "\n",
              "                                            category  source  review_id  \\\n",
              "0                                       ['Car wash']  google       1001   \n",
              "1  ['Discount store', 'Appliance store', 'Baby st...  google       1002   \n",
              "2  ['Pizza restaurant', 'Chicken wings restaurant...  google       1003   \n",
              "3                       ['Musical instrument store']  google       1004   \n",
              "4                                ['Used car dealer']  google       1005   \n",
              "\n",
              "                                comprehensive_review  is_ad  is_relevant  \\\n",
              "0  [Business] Auto Spa Speedy Wash - Harvester, M...  False         True   \n",
              "1  [Business] Kmart | [Category] ['Discount store...   True         True   \n",
              "2  [Business] Papa’s Pizza | [Category] ['Pizza r...  False         True   \n",
              "3  [Business] The Music Place | [Category] ['Musi...  False         True   \n",
              "4  [Business] Park Motor Cars Inc | [Category] ['...  False         True   \n",
              "\n",
              "   is_rant  is_legit  \n",
              "0    False      True  \n",
              "1     True     False  \n",
              "2    False      True  \n",
              "3     True     False  \n",
              "4     True     False  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_clean_df = full_df.dropna(subset=['review_text', 'is_ad', 'is_relevant', 'is_rant', 'is_legit'])\n",
        "\n",
        "to_clean_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb37d5d",
      "metadata": {
        "id": "bfb37d5d"
      },
      "source": [
        "### 2. Pre-Process Datafames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a6b8904",
      "metadata": {
        "id": "7a6b8904"
      },
      "source": [
        "##### 2.1 Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f12b429b",
      "metadata": {
        "id": "f12b429b"
      },
      "outputs": [],
      "source": [
        "def normalize_whitespace(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = normalize_whitespace(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c60b82",
      "metadata": {
        "id": "f1c60b82"
      },
      "source": [
        "##### 2.2 Compute Basic Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e7f4cc3e",
      "metadata": {
        "id": "e7f4cc3e"
      },
      "outputs": [],
      "source": [
        "def compute_basic_signals(text):\n",
        "    url_count = len(re.findall(r'https?://\\S+', text))\n",
        "    phone_count = len(re.findall(r'\\+?\\d[\\d\\s-]{7,}\\d', text))\n",
        "    caps_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
        "    return url_count, phone_count, caps_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8e54ee",
      "metadata": {
        "id": "9c8e54ee"
      },
      "source": [
        "##### 2.3 Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2bf2489e",
      "metadata": {
        "id": "2bf2489e"
      },
      "outputs": [],
      "source": [
        "def add_textblob_sentiment(df, text_col=\"review_text\", positive_threshold=0.9, negative_threshold=-0.9):\n",
        "    def get_sentiment(text):\n",
        "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
        "            return 0.0, 0.0\n",
        "        try:\n",
        "            analysis = TextBlob(text)\n",
        "            return analysis.sentiment.polarity, analysis.sentiment.subjectivity\n",
        "        except Exception:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "    sentiment_results = df[text_col].apply(get_sentiment)\n",
        "    df[\"sentiment_polarity\"], df[\"sentiment_subjectivity\"] = zip(*sentiment_results)\n",
        "\n",
        "    df[\"is_extreme_sentiment\"] = df[\"sentiment_polarity\"].apply(\n",
        "        lambda x: 1 if x >= positive_threshold or x <= negative_threshold else 0\n",
        "    )\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b0298e4",
      "metadata": {
        "id": "8b0298e4"
      },
      "source": [
        "##### Apply to Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7e0173de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e0173de",
        "outputId": "fde7bc5d-84db-4188-d62c-09e3a2a44346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         review_text  rating  has_photo  \\\n",
            "0  Love the convenience of this neighborhood carw...     4.0      False   \n",
            "1  2 bathrooms (for a large 2 story building), 1 ...     2.0      False   \n",
            "2                 My favorite pizza shop hands down!     5.0      False   \n",
            "3  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...     1.0      False   \n",
            "4                           Very unprofessional!!!!!     1.0      False   \n",
            "\n",
            "       author_name  user_review_count                         business_name  \\\n",
            "0     Doug Schmidt                1.0  Auto Spa Speedy Wash - Harvester, MO   \n",
            "1     Duf Duftopia                1.0                                 Kmart   \n",
            "2  Andrew Phillips                1.0                          Papa’s Pizza   \n",
            "3    Julie Heiland                1.0                       The Music Place   \n",
            "4    Alan Khasanov                1.0                   Park Motor Cars Inc   \n",
            "\n",
            "                                            category  source  review_id  \\\n",
            "0                                       ['Car wash']  google       1001   \n",
            "1  ['Discount store', 'Appliance store', 'Baby st...  google       1002   \n",
            "2  ['Pizza restaurant', 'Chicken wings restaurant...  google       1003   \n",
            "3                       ['Musical instrument store']  google       1004   \n",
            "4                                ['Used car dealer']  google       1005   \n",
            "\n",
            "                                comprehensive_review  is_ad  is_relevant  \\\n",
            "0  [Business] Auto Spa Speedy Wash - Harvester, M...  False         True   \n",
            "1  [Business] Kmart | [Category] ['Discount store...   True         True   \n",
            "2  [Business] Papa’s Pizza | [Category] ['Pizza r...  False         True   \n",
            "3  [Business] The Music Place | [Category] ['Musi...  False         True   \n",
            "4  [Business] Park Motor Cars Inc | [Category] ['...  False         True   \n",
            "\n",
            "   is_rant  is_legit                                         clean_text  \\\n",
            "0    False      True  Love the convenience of this neighborhood carw...   \n",
            "1     True     False  2 bathrooms (for a large 2 story building), 1 ...   \n",
            "2    False      True                 My favorite pizza shop hands down!   \n",
            "3     True     False  BOTCHED INSTRUMENT REPAIR IS COSTING US HUNDRE...   \n",
            "4     True     False                           Very unprofessional!!!!!   \n",
            "\n",
            "   url_count  phone_count  caps_ratio  \n",
            "0          0            0    0.020000  \n",
            "1          0            0    0.016949  \n",
            "2          0            0    0.029412  \n",
            "3          0            0    0.042589  \n",
            "4          0            0    0.041667  \n",
            "                                         review_text  rating  has_photo  \\\n",
            "0  Had a fantastic meal at The Gourmet Place! The...       5       True   \n",
            "1  Great experience at FitLife Gym! The equipment...       4      False   \n",
            "2  Staying at Oceanview Hotel was a dream! The vi...       5       True   \n",
            "3  The Family Clinic is amazing! They really take...       4      False   \n",
            "4  I love shopping at Trendy Mall! They have ever...       5       True   \n",
            "\n",
            "      author_name  user_review_count      business_name       category  \\\n",
            "0   Sophia Turner                 23  The Gourmet Place     restaurant   \n",
            "1   Michael Brown                 15        FitLife Gym            gym   \n",
            "2     Emily Davis                 30    Oceanview Hotel          hotel   \n",
            "3     Liam Wilson                 10      Family Clinic         clinic   \n",
            "4  Olivia Johnson                 28        Trendy Mall  shopping mall   \n",
            "\n",
            "   source  review_id  is_ad  is_rant  is_legit  is_relevant  \\\n",
            "0  Google      20615   True    False     False         True   \n",
            "1    Yelp      20616   True    False     False         True   \n",
            "2  Google      20617   True    False     False         True   \n",
            "3    Yelp      20618   True    False     False         True   \n",
            "4  Google      20619   True    False     False         True   \n",
            "\n",
            "                                comprehensive_review  \\\n",
            "0  [Business] The Gourmet Place | [Category] rest...   \n",
            "1  [Business] FitLife Gym | [Category] gym | [Rat...   \n",
            "2  [Business] Oceanview Hotel | [Category] hotel ...   \n",
            "3  [Business] Family Clinic | [Category] clinic |...   \n",
            "4  [Business] Trendy Mall | [Category] shopping m...   \n",
            "\n",
            "                                          clean_text  url_count  phone_count  \\\n",
            "0  Had a fantastic meal at The Gourmet Place! The...          1            0   \n",
            "1  Great experience at FitLife Gym! The equipment...          0            1   \n",
            "2  Staying at Oceanview Hotel was a dream! The vi...          1            0   \n",
            "3  The Family Clinic is amazing! They really take...          1            0   \n",
            "4  I love shopping at Trendy Mall! They have ever...          1            0   \n",
            "\n",
            "   caps_ratio  \n",
            "0    0.042424  \n",
            "1    0.041958  \n",
            "2    0.038168  \n",
            "3    0.034965  \n",
            "4    0.045045  \n"
          ]
        }
      ],
      "source": [
        "def preprocess_reviews(df):\n",
        "    df[\"clean_text\"] = df[\"review_text\"].apply(clean_text)\n",
        "    signals = df[\"clean_text\"].apply(compute_basic_signals)\n",
        "    df[\"url_count\"], df[\"phone_count\"], df[\"caps_ratio\"] = zip(*signals)\n",
        "    return df\n",
        "\n",
        "cleaned_df = preprocess_reviews(to_clean_df)\n",
        "print(cleaned_df.head())\n",
        "\n",
        "cleaned_synthetic_df = preprocess_reviews(synthetic_df)\n",
        "print(cleaned_synthetic_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bab7dfc9",
      "metadata": {
        "id": "bab7dfc9"
      },
      "outputs": [],
      "source": [
        "# # Save as JSON\n",
        "# output_json_path = os.path.join(labeled_input_folder, \"cleaned_df.json\")\n",
        "# cleaned_df.to_json(output_json_path, orient=\"records\", lines=True, force_ascii=False)\n",
        "# print(f\"JSON file saved to: {output_json_path}\")\n",
        "\n",
        "# # Save as Parquet\n",
        "# output_parquet_path = os.path.join(labeled_input_folder, \"cleaned_df.parquet\")\n",
        "# cleaned_df.to_parquet(output_parquet_path, index=False)\n",
        "# print(f\"Parquet file saved to: {output_parquet_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca9f773",
      "metadata": {
        "id": "6ca9f773"
      },
      "source": [
        "### 3. Train-Test Split with Multi-Label Stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3235d024",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3235d024",
        "outputId": "02eb61e6-1420-4fe1-848c-83be6e012631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (8181, 18) (includes synthetic data)\n",
            "Validation set size: (1867, 18)\n",
            "Test set size: (2333, 18)\n",
            "Synthetic data in validation set: False\n",
            "Synthetic data in test set: False\n"
          ]
        }
      ],
      "source": [
        "meta_cols = [\"clean_text\", \"url_count\",\"phone_count\",\"caps_ratio\",\"rating\",\"has_photo\",\"user_review_count\"]\n",
        "label_cols = [\"is_ad\", \"is_relevant\", \"is_rant\", \"is_legit\"]\n",
        "\n",
        "X = cleaned_df.drop(columns=label_cols)\n",
        "y = cleaned_df[label_cols].values\n",
        "\n",
        "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "train_val_idx, test_idx = next(mskf.split(X, y))\n",
        "\n",
        "train_val_df = cleaned_df.iloc[train_val_idx].reset_index(drop=True)\n",
        "test_df = cleaned_df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "y_train_val = y[train_val_idx]\n",
        "train_idx, val_idx = next(mskf.split(train_val_df.drop(columns=label_cols), y_train_val))\n",
        "\n",
        "train_df_original = train_val_df.iloc[train_idx].reset_index(drop=True)\n",
        "val_df = train_val_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "train_df = pd.concat([train_df_original, cleaned_synthetic_df], ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "print(f\"Training set size: {train_df.shape} (includes synthetic data)\")\n",
        "print(f\"Validation set size: {val_df.shape}\")\n",
        "print(f\"Test set size: {test_df.shape}\")\n",
        "\n",
        "print(f\"Synthetic data in validation set: {val_df['review_id'].isin(cleaned_synthetic_df['review_id']).any()}\")\n",
        "print(f\"Synthetic data in test set: {test_df['review_id'].isin(cleaned_synthetic_df['review_id']).any()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ff6b75",
      "metadata": {
        "id": "03ff6b75"
      },
      "source": [
        "### 4. Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2dc6aa88",
      "metadata": {
        "id": "2dc6aa88"
      },
      "outputs": [],
      "source": [
        "def simple_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    tokens = re.findall(r'\\b[a-z]+\\b', text)\n",
        "    return tokens\n",
        "\n",
        "train_df['tokens'] = train_df['clean_text'].apply(simple_tokenize)\n",
        "test_df['tokens'] = test_df['clean_text'].apply(simple_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c44b1329",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c44b1329",
        "outputId": "93298580-8d06-4d51-fd53-2c11499a2cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8181, 19)\n",
            "(1867, 18)\n",
            "(2333, 19)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66de5f2d",
      "metadata": {
        "id": "66de5f2d"
      },
      "source": [
        "### Yuen Ning's model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "jIdApG4cN19P",
      "metadata": {
        "id": "jIdApG4cN19P"
      },
      "outputs": [],
      "source": [
        "class QwenWithMeta(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, meta_embedding_size):\n",
        "        super().__init__()\n",
        "        self.text_model = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.text_model.config.hidden_size\n",
        "\n",
        "        # Projection layer to ensure text and meta embeddings have the same size\n",
        "        # (if they don't already)\n",
        "        self.meta_projection = nn.Linear(meta_embedding_size, hidden_size)\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, meta_embedding, **kwargs):\n",
        "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_emb = text_outputs.last_hidden_state[:, 0, :] # [CLS] token\n",
        "\n",
        "        # Project the pre-computed meta embedding to the same space\n",
        "        meta_emb = self.meta_projection(meta_embedding)\n",
        "\n",
        "        combined_emb = text_emb + meta_emb\n",
        "        logits = self.classifier(combined_emb)\n",
        "        return {\"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "Gj7aW40wT_Nz",
      "metadata": {
        "id": "Gj7aW40wT_Nz"
      },
      "outputs": [],
      "source": [
        "class MetaMLP(nn.Module):\n",
        "    def __init__(self, meta_dim, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(meta_dim, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size), # Output a fixed-size embedding\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 1. Initialize the meta embedder and pre-compute embeddings\n",
        "meta_embedder = MetaMLP(meta_dim=len(meta_cols))\n",
        "meta_embedder.eval() # Set to eval mode\n",
        "\n",
        "def precompute_meta_embeddings(df, meta_embedder, meta_cols):\n",
        "    \"\"\"Pre-compute meta embeddings for a DataFrame\"\"\"\n",
        "    with torch.no_grad(): # No need for gradients\n",
        "        meta_tensor = torch.tensor(df[meta_cols].values.astype(np.float32))\n",
        "        meta_embeddings = meta_embedder(meta_tensor)\n",
        "    return meta_embeddings.numpy() # Return as numpy array for the dataset\n",
        "\n",
        "# Pre-compute for train and validation\n",
        "train_meta_emb = precompute_meta_embeddings(train_df_filtered, meta_embedder, meta_cols)\n",
        "val_meta_emb = precompute_meta_embeddings(val_df_filtered, meta_embedder, meta_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "wL_CgH3TMiAG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "89cafb7f97db405599d8df33c0d84113",
            "cdff1fa9d1d34bc892501f12bb0675f7",
            "409ba1587db54d03955fbeab1043b712",
            "688caf4643df4bca8def16f97d10fde0",
            "f10ae2a394654991b70fc2e697bce18a",
            "8b95aa760c7d4991ba35e0837ca30b22",
            "e6b879cf4ff14d208fd2563655f47beb",
            "2f292acf4623411eabfc407b4b7aa327",
            "bf938a0528ae4f87ad78277ae3b8b5fe",
            "7b9c9365a5e648fd8c5b1990a3a30db9",
            "61fd0c62b2b94b779a209cf7fdef1997",
            "25b3e2498bac423cb08b3e008bd5d7a4",
            "b8a44ca61fed44b3998042e0d8647c6d",
            "6cc1893a462c407980afdd9b3a39e0b6",
            "43460540c03a4c7d809a52cab6cc5576",
            "f2d1458f0d684d0081329574e0eec789",
            "2d982422f699463f84e03a993d2fbf4c",
            "e0c20efa136449d1a448806ea12e01cc",
            "74d2af55ce4d449286e9afebe50da15a",
            "afcb704b10ea4008a27a8f2b67ebdf01",
            "8cc8f763bf1342da912b2e8c1f24ce5e",
            "ecb0d9cd646b4e3bba3671731173cba2",
            "77e3291b8f1243cea70b5ef4d4b83697",
            "6386a2190c044ea6b5e0a2f163851e80",
            "47e767593abb492082642bc34254c21a",
            "4fd19a05b1424a9389183cbf9777ebc2",
            "38e401c31b4a42758a2499484bb60e11",
            "c21800e4ce384aa781cc4c001caa33d2",
            "b3ca3912dbc84d0598a0df8b4ac8ec75",
            "468c6a83481d4791b6969de8d308bce4",
            "ee97e4ea66be452c8b615d9f170ca2cb",
            "e1da8c10bf114bc49a7185079fb1db66",
            "8952d5c3db9448ea8aed64a99acb44bb"
          ]
        },
        "id": "wL_CgH3TMiAG",
        "outputId": "926f123d-fbb4-4d2c-e502-97b266f3d57b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89cafb7f97db405599d8df33c0d84113",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8181 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25b3e2498bac423cb08b3e008bd5d7a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1867 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77e3291b8f1243cea70b5ef4d4b83697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1867 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label_cols = [\"is_ad\", \"is_relevant\", \"is_rant\"]\n",
        "meta_cols = [\"url_count\", \"phone_count\", \"caps_ratio\", \"rating\", \"has_photo\", \"user_review_count\"]\n",
        "\n",
        "labels_array = np.array(train_df[label_cols])\n",
        "pos_counts = labels_array.sum(axis=0)\n",
        "neg_counts = len(labels_array) - pos_counts\n",
        "pos_weight = torch.tensor(neg_counts / (pos_counts + 1e-8), dtype=torch.float)\n",
        "\n",
        "train_df_filtered = train_df.drop(columns=[\"is_legit\"])\n",
        "val_df_filtered = val_df.drop(columns=[\"is_legit\"])\n",
        "test_df_filtered = test_df.drop(columns=[\"is_legit\"])\n",
        "\n",
        "def prepare_dataset(df, meta_embeddings):\n",
        "    df = df.reset_index(drop=True).copy()\n",
        "    # Add the pre-computed meta embeddings to the dataframe\n",
        "    df['meta_embedding'] = list(meta_embeddings) # Store as a list of arrays\n",
        "    return Dataset.from_pandas(df[[\"clean_text\"] + label_cols + [\"meta_embedding\"]])\n",
        "\n",
        "train_dataset = prepare_dataset(train_df_filtered, train_meta_emb)\n",
        "val_dataset = prepare_dataset(val_df_filtered, val_meta_emb)\n",
        "\n",
        "def preprocess(batch):\n",
        "    tokenized = tokenizer(batch[\"clean_text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "    # Meta embeddings are already computed, just convert them to tensor\n",
        "    tokenized[\"meta_embedding\"] = torch.tensor(np.array(batch[\"meta_embedding\"]), dtype=torch.float)\n",
        "    return tokenized\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess, batched=True)\n",
        "test_dataset = val_dataset.map(preprocess, batched=True)\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"] + label_cols + [\"meta_embedding\"])\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"] + label_cols + [\"meta_embedding\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"] + label_cols + [\"meta_embedding\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "YHTpgvWbMucA",
      "metadata": {
        "id": "YHTpgvWbMucA"
      },
      "outputs": [],
      "source": [
        "model_name = \"Qwen/Qwen1.5-0.5B\"\n",
        "model = QwenWithMeta(model_name, num_labels=len(label_cols), meta_embedding_size=64)\n",
        "config = LoraConfig(r=8, lora_alpha=32, lora_dropout=0.1)\n",
        "model.text_model = get_peft_model(model.text_model, config)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.text_model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "0jAj2kC-NG9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jAj2kC-NG9b",
        "outputId": "723bc92c-2910-4ebb-9466-f3ac1b4ee184"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-406015554.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MultiLabelTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def data_collator(batch):\n",
        "    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
        "    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
        "    meta_embedding = torch.stack([item[\"meta_embedding\"] for item in batch]) # Now getting the embedding\n",
        "    labels = torch.stack([torch.tensor([item[col] for col in label_cols], dtype=torch.float) for item in batch])\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"meta_embedding\": meta_embedding, \"labels\": labels}\n",
        "\n",
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, *args, pos_weight=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        meta_embedding = inputs.pop(\"meta_embedding\") # Changed from 'meta'\n",
        "        outputs = model(**inputs, meta_embedding=meta_embedding) # Changed here\n",
        "        logits = outputs[\"logits\"]\n",
        "        loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight.to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
        "    print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "batch_size = 8\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qwen_meta_multilabel\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_steps=500,\n",
        "    logging_steps=100,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = MultiLabelTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    pos_weight=pos_weight\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "E27ZgS7SOHW3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "E27ZgS7SOHW3",
        "outputId": "fd81a71c-4346-4619-a96f-2ffbff6d0ddb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1536' max='1536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1536/1536 35:13, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.103400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.891400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.839300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.861200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.749100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.663800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.843800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.718800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.606000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.649300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.580600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.644200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1536, training_loss=0.7464103102684021, metrics={'train_runtime': 2114.8145, 'train_samples_per_second': 11.605, 'train_steps_per_second': 0.726, 'total_flos': 0.0, 'train_loss': 0.7464103102684021, 'epoch': 3.0})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "lvYXo2HUooHJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvYXo2HUooHJ",
        "outputId": "d50f284b-a84b-4f11-ce38-2a649710debc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Create a directory for your model\n",
        "model_dir = Path(\"./qwen_meta_multilabel_final\")\n",
        "model_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# 1. Save the complete model state\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'text_model_config': model.text_model.config,\n",
        "    'meta_embedding_size': 64,\n",
        "    'num_labels': len(label_cols)\n",
        "}, model_dir / \"model_checkpoint.pth\")\n",
        "\n",
        "# 2. Save the tokenizer\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "# 3. Save the label information\n",
        "with open(model_dir / \"label_cols.json\", \"w\") as f:\n",
        "    json.dump(label_cols, f)\n",
        "\n",
        "# 4. Save the model class definition code (important for future loading)\n",
        "with open(model_dir / \"model_definition.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "from peft import PeftModel\n",
        "\n",
        "class QwenWithMeta(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, meta_embedding_size):\n",
        "        super().__init__()\n",
        "        self.text_model = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.text_model.config.hidden_size\n",
        "        self.meta_projection = nn.Linear(meta_embedding_size, hidden_size)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, meta_embedding):\n",
        "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_emb = text_outputs.last_hidden_state[:, 0, :] # [CLS] token\n",
        "        meta_emb = self.meta_projection(meta_embedding)\n",
        "        combined_emb = text_emb + meta_emb\n",
        "        logits = self.classifier(combined_emb)\n",
        "        return {\"logits\": logits}\n",
        "''')\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "YbOVUuf0ffSK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YbOVUuf0ffSK",
        "outputId": "cd864deb-78e5-441d-ab17-98bbad9440dd"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2ea9a212-09d6-4d71-ad4c-e85d16e7878e\", \"qwen_meta_multilabel_final.zip\", 876553439)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "shutil.make_archive('qwen_meta_multilabel_final', 'zip', './qwen_meta_multilabel_final')\n",
        "\n",
        "files.download('qwen_meta_multilabel_final.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "009F6u8CikdV",
      "metadata": {
        "id": "009F6u8CikdV"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"./qwen_meta_multilabel_final/model_checkpoint.pth\", weights_only=False)\n",
        "model_state_dict = checkpoint['model_state_dict']\n",
        "\n",
        "model = QwenWithMeta(\n",
        "    model_name=checkpoint['text_model_config']._name_or_path,\n",
        "    num_labels=checkpoint['num_labels'],\n",
        "    meta_embedding_size=checkpoint['meta_embedding_size']\n",
        ")\n",
        "\n",
        "model.load_state_dict(model_state_dict, strict=False)\n",
        "\n",
        "trainer.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "poHEa-qmow_u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "poHEa-qmow_u",
        "outputId": "0f698712-cd91-42bf-b63c-ba133f7cb32e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [234/234 00:57]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_model_preparation_time': 0.0041, 'eval_runtime': 57.393, 'eval_samples_per_second': 32.53, 'eval_steps_per_second': 4.077}\n"
          ]
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "moGVhlWgncb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moGVhlWgncb8",
        "outputId": "64feef60-3934-4b00-c197-164c442dc92d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manual Evaluation Results:\n",
            "Precision: 0.3628\n",
            "Recall: 0.7638\n",
            "F1: 0.3332\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(len(val_dataset)):\n",
        "        item = val_dataset[i]\n",
        "\n",
        "        # Prepare inputs\n",
        "        inputs = {\n",
        "            \"input_ids\": item[\"input_ids\"].unsqueeze(0).to(device),\n",
        "            \"attention_mask\": item[\"attention_mask\"].unsqueeze(0).to(device),\n",
        "            \"meta_embedding\": item[\"meta_embedding\"].unsqueeze(0).to(device)\n",
        "        }\n",
        "\n",
        "        # Get prediction\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[\"logits\"]\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int().cpu().numpy()\n",
        "        all_preds.append(preds[0])\n",
        "\n",
        "        # Get labels\n",
        "        labels = [item[\"is_ad\"], item[\"is_relevant\"], item[\"is_rant\"]]\n",
        "        all_labels.append(labels)\n",
        "\n",
        "# Convert to arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Compute metrics\n",
        "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Manual Evaluation Results:\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VSGpNyCqgcc9",
      "metadata": {
        "id": "VSGpNyCqgcc9"
      },
      "source": [
        "### 5. Threshold Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "M_o6xKGhf3Vd",
      "metadata": {
        "id": "M_o6xKGhf3Vd"
      },
      "outputs": [],
      "source": [
        "def safe_get_predictions_proba(model, tokenizer, texts, meta_embeddings, device='cuda', batch_size=16):\n",
        "    \"\"\"Safe prediction function with proper device and type handling\"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Getting predictions\"):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            batch_meta_embeddings = meta_embeddings[i:i+batch_size]\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                batch_texts,\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=512,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Convert meta embeddings to tensor\n",
        "            meta_tensor = torch.tensor(batch_meta_embeddings, dtype=torch.float32)\n",
        "\n",
        "            # Explicitly move to device\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "            meta_tensor = meta_tensor.to(device)\n",
        "\n",
        "            outputs = model(**inputs, meta_embedding=meta_tensor)\n",
        "            probs = torch.sigmoid(outputs[\"logits\"])\n",
        "\n",
        "            # Convert to float32 before moving to CPU for numpy compatibility\n",
        "            probs_float32 = probs.float().cpu().numpy()\n",
        "            all_probs.extend(probs_float32)\n",
        "\n",
        "    return np.array(all_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "PIoHsS8xptb-",
      "metadata": {
        "id": "PIoHsS8xptb-"
      },
      "outputs": [],
      "source": [
        "class MultilabelThresholdTuner:\n",
        "    def __init__(self, model, tokenizer, label_cols, meta_embedder, meta_cols, device='cuda'):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_cols = label_cols\n",
        "        self.meta_embedder = meta_embedder\n",
        "        self.meta_cols = meta_cols\n",
        "        self.device = device\n",
        "        self.best_thresholds = None\n",
        "        self.best_metrics = None\n",
        "\n",
        "    def get_predictions_proba(self, texts, meta_embeddings, batch_size=16):\n",
        "        \"\"\"Get prediction probabilities with meta embeddings\"\"\"\n",
        "        return safe_get_predictions_proba(self.model, self.tokenizer, texts, meta_embeddings,\n",
        "                                        self.device, batch_size)\n",
        "\n",
        "    def get_meta_embeddings_from_df(self, df):\n",
        "        \"\"\"Extract meta embeddings from DataFrame\"\"\"\n",
        "        return precompute_meta_embeddings(df, self.meta_embedder, self.meta_cols)\n",
        "\n",
        "    def optimize_thresholds_per_class(self, y_true, y_probs):\n",
        "        \"\"\"Optimize thresholds for each class using F1 maximization\"\"\"\n",
        "        n_classes = len(self.label_cols)\n",
        "        optimal_thresholds = np.zeros(n_classes)\n",
        "\n",
        "        for class_idx in range(n_classes):\n",
        "            precision, recall, thresholds = precision_recall_curve(\n",
        "                y_true[:, class_idx], y_probs[:, class_idx]\n",
        "            )\n",
        "\n",
        "            # Calculate F1 scores\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "            # Find threshold with maximum F1 score\n",
        "            if len(thresholds) > 0:\n",
        "                best_idx = np.nanargmax(f1_scores[:len(thresholds)])\n",
        "                optimal_thresholds[class_idx] = thresholds[best_idx]\n",
        "\n",
        "                print(f\"{self.label_cols[class_idx]}: Optimal threshold = {thresholds[best_idx]:.3f}, \"\n",
        "                      f\"Max F1 = {f1_scores[best_idx]:.3f}\")\n",
        "            else:\n",
        "                optimal_thresholds[class_idx] = 0.5\n",
        "                print(f\"{self.label_cols[class_idx]}: No thresholds found, using default 0.5\")\n",
        "\n",
        "        return optimal_thresholds\n",
        "\n",
        "    def evaluate_thresholds(self, y_true, y_probs, thresholds):\n",
        "        \"\"\"Evaluate performance with given thresholds\"\"\"\n",
        "        y_pred = (y_probs >= thresholds).astype(int)\n",
        "\n",
        "        metrics = {\n",
        "            'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
        "            'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
        "            'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
        "            'precision_weighted': precision_score(y_true, y_pred, average='weighted'),\n",
        "            'recall_weighted': recall_score(y_true, y_pred, average='weighted'),\n",
        "        }\n",
        "\n",
        "        # Class-wise metrics\n",
        "        class_metrics = {}\n",
        "        for i, label in enumerate(self.label_cols):\n",
        "            class_metrics[f'{label}_f1'] = f1_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
        "            class_metrics[f'{label}_precision'] = precision_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
        "            class_metrics[f'{label}_recall'] = recall_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
        "\n",
        "        metrics.update(class_metrics)\n",
        "        return metrics, y_pred\n",
        "\n",
        "    def tune_thresholds_from_df(self, df, text_column='clean_text'):\n",
        "        \"\"\"Tune thresholds using DataFrame\"\"\"\n",
        "        print(\"Extracting texts, meta embeddings, and true labels...\")\n",
        "        texts = df[text_column].tolist()\n",
        "        meta_embeddings = self.get_meta_embeddings_from_df(df)\n",
        "        y_true = df[self.label_cols].values\n",
        "\n",
        "        print(\"Getting prediction probabilities...\")\n",
        "        y_probs = self.get_predictions_proba(texts, meta_embeddings)\n",
        "\n",
        "        print(f\"True labels shape: {y_true.shape}\")\n",
        "        print(f\"Predicted probabilities shape: {y_probs.shape}\")\n",
        "\n",
        "        print(\"\\nOptimizing thresholds...\")\n",
        "        self.best_thresholds = self.optimize_thresholds_per_class(y_true, y_probs)\n",
        "\n",
        "        # Evaluate with optimized thresholds\n",
        "        self.best_metrics, y_pred = self.evaluate_thresholds(y_true, y_probs, self.best_thresholds)\n",
        "\n",
        "        # Compare with default threshold\n",
        "        default_metrics, _ = self.evaluate_thresholds(y_true, y_probs, 0.5)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"THRESHOLD TUNING RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"\\nOptimal thresholds:\")\n",
        "        for label, threshold in zip(self.label_cols, self.best_thresholds):\n",
        "            print(f\"  {label}: {threshold:.3f}\")\n",
        "\n",
        "        print(\"\\nPerformance comparison:\")\n",
        "        print(f\"{'Metric':<20} {'Default (0.5)':<12} {'Optimized':<12} {'Improvement':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "        for metric in ['f1_weighted', 'f1_macro', 'f1_micro']:\n",
        "            improvement = self.best_metrics[metric] - default_metrics[metric]\n",
        "            print(f\"{metric:<20} {default_metrics[metric]:<12.4f} {self.best_metrics[metric]:<12.4f} {improvement:+.4f}\")\n",
        "\n",
        "        print(\"\\nClass-wise F1 scores:\")\n",
        "        for label in self.label_cols:\n",
        "            default_f1 = default_metrics[f'{label}_f1']\n",
        "            optimized_f1 = self.best_metrics[f'{label}_f1']\n",
        "            improvement = optimized_f1 - default_f1\n",
        "            print(f\"  {label:<15} Default: {default_f1:.3f}, Optimized: {optimized_f1:.3f}, Δ: {improvement:+.3f}\")\n",
        "\n",
        "        return self.best_thresholds, self.best_metrics, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "nlUQRtlFgXUS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlUQRtlFgXUS",
        "outputId": "8ceec958-3ba6-4ce9-bc54-dc0839f687bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Getting predictions: 100%|██████████| 117/117 [00:15<00:00,  7.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation predictions shape: (1867, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the pre-computed meta embeddings for validation set\n",
        "val_meta_emb = precompute_meta_embeddings(val_df_filtered, meta_embedder, meta_cols)\n",
        "\n",
        "# Now call the function with meta embeddings\n",
        "texts_val = val_df['clean_text'].tolist()\n",
        "y_true_val = val_df[label_cols].values\n",
        "y_probs_val = safe_get_predictions_proba(model, tokenizer, texts_val, val_meta_emb, batch_size=16, device='cuda')\n",
        "print(\"Validation predictions shape:\", y_probs_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "ZR6EkSI9gjmc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR6EkSI9gjmc",
        "outputId": "604202e9-85ba-4beb-db43-22a2e4e0c0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting texts, meta embeddings, and true labels...\n",
            "Getting prediction probabilities...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Getting predictions: 100%|██████████| 117/117 [00:18<00:00,  6.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True labels shape: (1867, 3)\n",
            "Predicted probabilities shape: (1867, 3)\n",
            "\n",
            "Optimizing thresholds...\n",
            "is_ad: Optimal threshold = 0.756, Max F1 = 0.083\n",
            "is_relevant: Optimal threshold = 0.000, Max F1 = 0.981\n",
            "is_rant: Optimal threshold = 0.852, Max F1 = 0.186\n",
            "\n",
            "============================================================\n",
            "THRESHOLD TUNING RESULTS\n",
            "============================================================\n",
            "\n",
            "Optimal thresholds:\n",
            "  is_ad: 0.756\n",
            "  is_relevant: 0.000\n",
            "  is_rant: 0.852\n",
            "\n",
            "Performance comparison:\n",
            "Metric               Default (0.5) Optimized    Improvement \n",
            "------------------------------------------------------------\n",
            "f1_weighted          0.7206       0.8983       +0.1777\n",
            "f1_macro             0.3332       0.4168       +0.0836\n",
            "f1_micro             0.4469       0.7163       +0.2694\n",
            "\n",
            "Class-wise F1 scores:\n",
            "  is_ad           Default: 0.068, Optimized: 0.083, Δ: +0.015\n",
            "  is_relevant     Default: 0.788, Optimized: 0.981, Δ: +0.194\n",
            "  is_rant         Default: 0.144, Optimized: 0.186, Δ: +0.042\n",
            "\n",
            "F1 Weighted Improvement over default 0.5 threshold: 0.17770235344796392\n"
          ]
        }
      ],
      "source": [
        "tuner = MultilabelThresholdTuner(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    label_cols=label_cols,\n",
        "    meta_embedder=meta_embedder,\n",
        "    meta_cols=meta_cols,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "best_thresholds, best_metrics, y_pred_val = tuner.tune_thresholds_from_df(val_df)\n",
        "default_metrics, _ = tuner.evaluate_thresholds(y_true_val, y_probs_val, 0.5)\n",
        "\n",
        "print(\"\\nF1 Weighted Improvement over default 0.5 threshold:\",\n",
        "      best_metrics['f1_weighted'] - default_metrics['f1_weighted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "t9pEbzCXgtw8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9pEbzCXgtw8",
        "outputId": "a943b283-5f04-4c57-90e9-02494747d079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_ad: Default F1 = 0.068, Optimized F1 = 0.083\n",
            "is_relevant: Default F1 = 0.788, Optimized F1 = 0.981\n",
            "is_rant: Default F1 = 0.144, Optimized F1 = 0.186\n"
          ]
        }
      ],
      "source": [
        "for label in label_cols:\n",
        "    default_f1 = default_metrics[f'{label}_f1']\n",
        "    optimized_f1 = best_metrics[f'{label}_f1']\n",
        "    print(f\"{label}: Default F1 = {default_f1:.3f}, Optimized F1 = {optimized_f1:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "5taSiKJ3gyRB",
      "metadata": {
        "id": "5taSiKJ3gyRB"
      },
      "outputs": [],
      "source": [
        "y_pred_final = (y_probs_val >= tuner.best_thresholds).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "JC2YRQM9g7Ih",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JC2YRQM9g7Ih",
        "outputId": "06772faa-1195-4807-9e76-4d355ebc6155"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_543f6f05-666d-4f1b-abcf-bc9b17f2bb4f\", \"multilabel_thresholds.json\", 79)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized thresholds saved to multilabel_thresholds.json\n"
          ]
        }
      ],
      "source": [
        "thresholds_to_save = dict(zip(label_cols, tuner.best_thresholds))\n",
        "with open(\"multilabel_thresholds.json\", \"w\") as f:\n",
        "    json.dump(thresholds_to_save, f)\n",
        "files.download(\"multilabel_thresholds.json\")\n",
        "\n",
        "print(\"Optimized thresholds saved to multilabel_thresholds.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "Z9Xr8BjYrhOO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Xr8BjYrhOO",
        "outputId": "92334578-bdde-429d-8799-34ec284b2173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class distribution: {'is_ad': np.float64(0.35511515800749865), 'is_relevant': np.float64(1.0), 'is_rant': np.float64(0.44349223352972683)}\n"
          ]
        }
      ],
      "source": [
        "# Monitor class distribution in production\n",
        "class_distribution = {\n",
        "    'is_ad': (y_pred_val[:, 0].sum() / len(y_pred_val)),\n",
        "    'is_relevant': (y_pred_val[:, 1].sum() / len(y_pred_val)),\n",
        "    'is_rant': (y_pred_val[:, 2].sum() / len(y_pred_val))\n",
        "}\n",
        "print(\"Predicted class distribution:\", class_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eJgSonky5-fv",
      "metadata": {
        "id": "eJgSonky5-fv"
      },
      "source": [
        "### Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "6SUthfPYsdrK",
      "metadata": {
        "id": "6SUthfPYsdrK"
      },
      "outputs": [],
      "source": [
        "def predict_is_legit(ad_preds, relevant_preds, rant_preds):\n",
        "    \"\"\"\n",
        "    Predict is_legit based on business rules:\n",
        "    - If is_ad = True → is_legit = False\n",
        "    - If is_relevant = False → is_legit = False\n",
        "    - If is_rant = True → is_legit = False\n",
        "    - Otherwise → is_legit = True\n",
        "    \"\"\"\n",
        "    is_legit = np.ones_like(ad_preds, dtype=bool)  # Start with all True\n",
        "\n",
        "    # Apply business rules\n",
        "    is_legit[ad_preds == 1] = False      # If ad → not legit\n",
        "    is_legit[relevant_preds == 0] = False # If not relevant → not legit\n",
        "    is_legit[rant_preds == 1] = False    # If rant → not legit\n",
        "\n",
        "    return is_legit.astype(int)\n",
        "\n",
        "# Or using vectorized operations:\n",
        "def predict_is_legit_vectorized(ad_preds, relevant_preds, rant_preds):\n",
        "    \"\"\"Vectorized version for better performance\"\"\"\n",
        "    return ((ad_preds == 0) & (relevant_preds == 1) & (rant_preds == 0)).astype(int)\n",
        "\n",
        "def predict_with_business_rules(model, tokenizer, texts, meta_embeddings, thresholds, device='cuda', batch_size=16):\n",
        "    \"\"\"\n",
        "    Complete prediction pipeline with business rules for is_legit\n",
        "    \"\"\"\n",
        "    # Get probability predictions\n",
        "    probs = safe_get_predictions_proba(model, tokenizer, texts, meta_embeddings, device, batch_size)\n",
        "\n",
        "    # Apply individual class thresholds\n",
        "    ad_preds = (probs[:, 0] >= thresholds['is_ad']).astype(int)\n",
        "    relevant_preds = (probs[:, 1] >= thresholds['is_relevant']).astype(int)\n",
        "    rant_preds = (probs[:, 2] >= thresholds['is_rant']).astype(int)\n",
        "\n",
        "    # Apply business rules for is_legit\n",
        "    is_legit_preds = predict_is_legit(ad_preds, relevant_preds, rant_preds)\n",
        "\n",
        "    return {\n",
        "        'is_ad': ad_preds,\n",
        "        'is_relevant': relevant_preds,\n",
        "        'is_rant': rant_preds,\n",
        "        'is_legit': is_legit_preds,\n",
        "        'probabilities': probs\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "10kuef8ls5GR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10kuef8ls5GR",
        "outputId": "b0670589-92fa-4043-df96-80520b32fe2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Getting predictions: 100%|██████████| 117/117 [00:49<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using thresholds: {'is_ad': 0.756177544593811, 'is_relevant': 0.1, 'is_rant': 0.8518295884132385}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def robust_predict_with_business_rules(model, tokenizer, texts, meta_embeddings, thresholds, device='cuda', batch_size=16):\n",
        "    \"\"\"\n",
        "    Robust prediction function that handles both array and dictionary thresholds\n",
        "    \"\"\"\n",
        "    # Get probability predictions\n",
        "    probs = safe_get_predictions_proba(model, tokenizer, texts, meta_embeddings, device, batch_size)\n",
        "\n",
        "    # Handle threshold format\n",
        "    if isinstance(thresholds, np.ndarray):\n",
        "        # Convert array to dictionary\n",
        "        threshold_dict = {\n",
        "            'is_ad': float(thresholds[0]),\n",
        "            'is_relevant': float(max(thresholds[1], 0.01)),  # Apply minimum constraint\n",
        "            'is_rant': float(thresholds[2])\n",
        "        }\n",
        "    elif isinstance(thresholds, dict):\n",
        "        # Use dictionary directly, but apply constraint to is_relevant\n",
        "        threshold_dict = thresholds.copy()\n",
        "        threshold_dict['is_relevant'] = max(threshold_dict.get('is_relevant', 0.5), 0.1)\n",
        "    else:\n",
        "        raise ValueError(\"Thresholds must be numpy array or dictionary\")\n",
        "\n",
        "    print(f\"Using thresholds: {threshold_dict}\")\n",
        "\n",
        "    # Apply individual class thresholds\n",
        "    ad_preds = (probs[:, 0] >= threshold_dict['is_ad']).astype(int)\n",
        "    relevant_preds = (probs[:, 1] >= threshold_dict['is_relevant']).astype(int)\n",
        "    rant_preds = (probs[:, 2] >= threshold_dict['is_rant']).astype(int)\n",
        "\n",
        "    # Apply business rules for is_legit\n",
        "    is_legit_preds = ((ad_preds == 0) & (relevant_preds == 1) & (rant_preds == 0)).astype(int)\n",
        "\n",
        "    return {\n",
        "        'is_ad': ad_preds,\n",
        "        'is_relevant': relevant_preds,\n",
        "        'is_rant': rant_preds,\n",
        "        'is_legit': is_legit_preds,\n",
        "        'probabilities': probs,\n",
        "        'thresholds_used': threshold_dict\n",
        "    }\n",
        "\n",
        "# Test with the array directly\n",
        "val_predictions = robust_predict_with_business_rules(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    texts=val_df['clean_text'].tolist(),\n",
        "    meta_embeddings=val_meta_emb,\n",
        "    thresholds=best_thresholds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "7_RNbOcd242F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_RNbOcd242F",
        "outputId": "073cf62a-9863-40f4-fd51-ed15e1b9f87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction results:\n",
            "is_ad: 656/1867 (35.1%)\n",
            "is_relevant: 1546/1867 (82.8%)\n",
            "is_rant: 826/1867 (44.2%)\n",
            "is_legit: 764/1867 (40.9%)\n",
            "\n",
            "Thresholds used:\n",
            "  is_ad: 0.756\n",
            "  is_relevant: 0.100\n",
            "  is_rant: 0.852\n"
          ]
        }
      ],
      "source": [
        "# Analyze the predictions\n",
        "print(\"Prediction results:\")\n",
        "for label in ['is_ad', 'is_relevant', 'is_rant', 'is_legit']:\n",
        "    preds = val_predictions[label]\n",
        "    percentage = preds.mean() * 100\n",
        "    print(f\"{label}: {preds.sum()}/{len(preds)} ({percentage:.1f}%)\")\n",
        "\n",
        "# Check threshold values used\n",
        "print(\"\\nThresholds used:\")\n",
        "for label, threshold in val_predictions['thresholds_used'].items():\n",
        "    print(f\"  {label}: {threshold:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4b426534",
        "bfb37d5d",
        "6ca9f773",
        "03ff6b75"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25b3e2498bac423cb08b3e008bd5d7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8a44ca61fed44b3998042e0d8647c6d",
              "IPY_MODEL_6cc1893a462c407980afdd9b3a39e0b6",
              "IPY_MODEL_43460540c03a4c7d809a52cab6cc5576"
            ],
            "layout": "IPY_MODEL_f2d1458f0d684d0081329574e0eec789"
          }
        },
        "2d982422f699463f84e03a993d2fbf4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f292acf4623411eabfc407b4b7aa327": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e401c31b4a42758a2499484bb60e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409ba1587db54d03955fbeab1043b712": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f292acf4623411eabfc407b4b7aa327",
            "max": 8181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf938a0528ae4f87ad78277ae3b8b5fe",
            "value": 8181
          }
        },
        "43460540c03a4c7d809a52cab6cc5576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc8f763bf1342da912b2e8c1f24ce5e",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb0d9cd646b4e3bba3671731173cba2",
            "value": " 1867/1867 [00:00&lt;00:00, 2924.99 examples/s]"
          }
        },
        "468c6a83481d4791b6969de8d308bce4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e767593abb492082642bc34254c21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468c6a83481d4791b6969de8d308bce4",
            "max": 1867,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee97e4ea66be452c8b615d9f170ca2cb",
            "value": 1867
          }
        },
        "4fd19a05b1424a9389183cbf9777ebc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1da8c10bf114bc49a7185079fb1db66",
            "placeholder": "​",
            "style": "IPY_MODEL_8952d5c3db9448ea8aed64a99acb44bb",
            "value": " 1867/1867 [00:00&lt;00:00, 2819.69 examples/s]"
          }
        },
        "61fd0c62b2b94b779a209cf7fdef1997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6386a2190c044ea6b5e0a2f163851e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21800e4ce384aa781cc4c001caa33d2",
            "placeholder": "​",
            "style": "IPY_MODEL_b3ca3912dbc84d0598a0df8b4ac8ec75",
            "value": "Map: 100%"
          }
        },
        "688caf4643df4bca8def16f97d10fde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9c9365a5e648fd8c5b1990a3a30db9",
            "placeholder": "​",
            "style": "IPY_MODEL_61fd0c62b2b94b779a209cf7fdef1997",
            "value": " 8181/8181 [00:03&lt;00:00, 2647.34 examples/s]"
          }
        },
        "6cc1893a462c407980afdd9b3a39e0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d2af55ce4d449286e9afebe50da15a",
            "max": 1867,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afcb704b10ea4008a27a8f2b67ebdf01",
            "value": 1867
          }
        },
        "74d2af55ce4d449286e9afebe50da15a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e3291b8f1243cea70b5ef4d4b83697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6386a2190c044ea6b5e0a2f163851e80",
              "IPY_MODEL_47e767593abb492082642bc34254c21a",
              "IPY_MODEL_4fd19a05b1424a9389183cbf9777ebc2"
            ],
            "layout": "IPY_MODEL_38e401c31b4a42758a2499484bb60e11"
          }
        },
        "7b9c9365a5e648fd8c5b1990a3a30db9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8952d5c3db9448ea8aed64a99acb44bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89cafb7f97db405599d8df33c0d84113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdff1fa9d1d34bc892501f12bb0675f7",
              "IPY_MODEL_409ba1587db54d03955fbeab1043b712",
              "IPY_MODEL_688caf4643df4bca8def16f97d10fde0"
            ],
            "layout": "IPY_MODEL_f10ae2a394654991b70fc2e697bce18a"
          }
        },
        "8b95aa760c7d4991ba35e0837ca30b22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc8f763bf1342da912b2e8c1f24ce5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcb704b10ea4008a27a8f2b67ebdf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3ca3912dbc84d0598a0df8b4ac8ec75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8a44ca61fed44b3998042e0d8647c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d982422f699463f84e03a993d2fbf4c",
            "placeholder": "​",
            "style": "IPY_MODEL_e0c20efa136449d1a448806ea12e01cc",
            "value": "Map: 100%"
          }
        },
        "bf938a0528ae4f87ad78277ae3b8b5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21800e4ce384aa781cc4c001caa33d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdff1fa9d1d34bc892501f12bb0675f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b95aa760c7d4991ba35e0837ca30b22",
            "placeholder": "​",
            "style": "IPY_MODEL_e6b879cf4ff14d208fd2563655f47beb",
            "value": "Map: 100%"
          }
        },
        "e0c20efa136449d1a448806ea12e01cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1da8c10bf114bc49a7185079fb1db66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b879cf4ff14d208fd2563655f47beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb0d9cd646b4e3bba3671731173cba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee97e4ea66be452c8b615d9f170ca2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f10ae2a394654991b70fc2e697bce18a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d1458f0d684d0081329574e0eec789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
